#+STARTUP: hideblocks
#+PROPERTY: header-args :eval never-export
#+OPTIONS: ^:{}
#+OPTIONS: broken-links:t

#+SETUPFILE: /home/lucas/org-html-themes-master/org/theme-readtheorg-local.setup
#+HTML_HEAD: <style>pre.src {background-color: #3F3F3F ; color: #e5e5e5;}</style>

#+TITLE:  Integration of different Omics Data
#+AUTHOR: Lucas Michel Tod√≥
#+EMAIL:  lucas.michel@isglobal.org
#+DATE:   15/07/2022

#+LaTeX: \pagebreak
* Microarray Data
** 1.2B, 10G and 3D7B (Old_Arrays)
:PROPERTIES:
:header-args:R: :session old_arrays :tangle ./Paper_Analysis/Scripts/Microarrays/microarray_analysis_12B_10G_3D7B_variantome.R :results none
:END:
*** Import libraries
#+begin_src R
#### Import libraries ####

print("Importing Libraries...")
list.of.packages <- c("reshape2", "ggfortify", "tidyverse", "RColorBrewer", "sp")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(reshape2)
library(ggfortify)
library(tidyverse)
library(RColorBrewer)
library(sp)
library(readxl)

if (!("Biobase" %in% installed.packages()[,"Package"])){
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install()
}

library(Biobase)
#+end_src
*** Experimental Setup (modifiable part)
#+begin_src R
#### Experiment Setup: MODIFY THIS PART #################################
##*********************************************************************##
##*********************************************************************##

wd <- ('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/Old_Arrays/')
setwd(wd)
datadir <- "./Variantome_Original/"
outdir <- "./R_results_OldArrays_Variantome/"
annot <- read.csv("./Files/array_anotation.csv", sep="\t", header = F)
infiles <- "./Files/"

sample_names <- c(
  '12B_tp10', '12B_tp20', '12B_tp30', '12B_tp34', '12B_tp37', '12B_tp40', '12B_tp43',
  '10G_tp10', '10G_tp20', '10G_tp30', '10G_tp34', '10G_tp37', '10G_tp40', '10G_tp43',
  '3D7B_tp10', '3D7B_tp20', '3D7B_tp30', '3D7B_tp34', '3D7B_tp37', '3D7B_tp40', '3D7B_tp43'
)

nsamples <- length(sample_names)

times <- as.integer(sub("^.+_tp", "", sample_names))
types <- sub("_tp.+", "", sample_names)

## Load Annotation
print("Loading Array Annotation...")
gene_list <- readLines(paste0(infiles, "gene_list.txt"))
annot_df <- read_csv(paste0(infiles, 'info_df.csv')) %>%
  select(Gene_id, Name, Variant, Annot) %>%
  dplyr::filter(!is.na(Gene_id))

## Add Annotation
## gene_rosetta <- read_tsv(paste0(infiles, 'gene_ids_rosetta.txt'), col_names = F)
## colnames(gene_rosetta) <- c('Old_id', 'Gene_id')

gene_rosetta <- read_tsv('/mnt/Disc4T/Projects/Miniprojects/Gene_Rosetta/gene_rosetta.tsv')

## Set to NA rows with double ID (to be changed)

blasted <- read_csv('./Blast_Old_Primers/blasted_oligos.csv')
blasted <- blasted %>%
  mutate(Old_id = gsub('a(.*)_[0-9]', '\\1', blasted$Oligo_id))

unique_hit <- blasted %>%
  filter(Score >= 70 & Score_2 <= 70 ) %>%
  select(Old_id, Gene_id) %>%
  group_by(Old_id) %>%
  summarize(N_hits = n_distinct(Gene_id)) %>%
  filter(N_hits == 1) %>%
  select(Old_id) %>% pull()

unique_oligos <- blasted %>%
  filter(Old_id %in% unique_hit) %>%
  select(Old_id, Gene_id) %>%
  distinct()

gene_rosetta_blasted <- gene_rosetta %>%
  full_join(unique_oligos, by = 'Old_id', suffix = c('_aliases', '_blast')) %>%
  mutate(Gene_id = ifelse(is.na(Gene_id_blast), Gene_id_aliases, Gene_id_blast)) %>%
  select(Old_id, Gene_id, everything())

double_new_ids <- gene_rosetta_blasted %>%
   filter(grepl(',', Gene_id))

write_csv(double_new_ids, './genes_with_double_GeneID.csv')

gene_rosetta_blasted <- gene_rosetta_blasted %>%
  mutate(Gene_id = replace(Gene_id, grepl(',', Gene_id), NA))


write_csv(gene_rosetta_blasted, './final_rosseta_with_blasted_genes.csv')

## Load Gene-Level data

gene_level <- read_csv('./Variantome_Original/normalizedData_geneLevel.csv')
gene_level_noratio <- read_csv('./Variantome_Original/normalizedData_geneLevel_noRatio.csv')

gene_level %>%
  select(geneID) %>%
  write_csv('old_gene_ids.txt', , col_names = F)

gene_level <- gene_level %>%
  select(-contains('X3d7a'), -contains('w41')) %>%
  rename(Old_id = geneID, Old_name = Name) %>%
  mutate(Old_id = gsub('-a|-b|-a/b|-a/b/c', '', Old_id)) %>%
  left_join(gene_rosetta_blasted, by='Old_id') %>%
  select(Gene_id, everything())

## Add manually blasted ids
man_blast <- read_csv('./genes_manually_blasted.csv') %>%
  select(Old_id, Manual_Blast_Target) %>%
  filter(!is.na(Manual_Blast_Target))
gene_level[gene_level$Old_id %in% man_blast$Old_id,]$Gene_id <- man_blast$Manual_Blast_Target

gene_level <- gene_level %>% left_join(annot_df, by = 'Gene_id')
gene_level %>%
  left_join(annot_df, by = 'Gene_id') %>%
  write_csv('./raw_gene_level_data.csv')

gene_level %>%
  filter(is.na(Gene_id)) %>%
  write_csv('./raw_gene_level_noGene_id.csv')

## Remove genes without ids
gene_level <- gene_level %>%
  filter(!is.na(Gene_id))

## No Ratio

gene_level_noratio <- gene_level_noratio %>%
  select(-contains('X3d7a'), -contains('w41'))%>%
  rename(Old_id = geneID, Old_name = Name) %>%
  mutate(Old_id = gsub('-a|-b|-a/b|-a/b/c', '', Old_id)) %>%
  left_join(gene_rosetta_blasted, by='Old_id') %>%
  select(Gene_id, everything())

## Add manually blasted ids
gene_level_noratio[gene_level_noratio$Old_id %in% man_blast$Old_id,]$Gene_id <- man_blast$Manual_Blast_Target

gene_level_noratio <- gene_level_noratio %>% left_join(annot_df, by = 'Gene_id')
gene_level_noratio %>%
  left_join(annot_df, by = 'Gene_id') %>%
  write_csv('./raw_gene_level_noratio_data.csv')

gene_level_noratio %>%
  filter(is.na(Gene_id)) %>%
  write_csv('./raw_gene_level_noratio_noGene_id.csv')

## Remove genes without ids
gene_level_noratio <- gene_level_noratio %>%
  filter(!is.na(Gene_id))


## Summarize genes with duplicated new IDs

collapse_ids <- function(df) {
  non_num <- df %>%
    select(Gene_id, Name, Variant, Annot) %>%
    distinct()
  #print(dim(non_num))

  num <- df %>%
    select(Gene_id, contains('X')) %>%
    group_by(Gene_id) %>%
    summarise_each(funs(mean))

  #print(dim(num))
  df <- num %>%
    left_join(non_num, by = 'Gene_id') %>%
    filter(!is.na(Gene_id))


  return(df)
}


gene_level %>% group_by(Gene_id) %>% filter(n() > 1) %>%
  select(Gene_id, Name, Annot) %>%
  print(n = 99)

gene_level <- collapse_ids(gene_level)
gene_level_noratio <- collapse_ids(gene_level_noratio)

## Load Areas
areasDF <- read_csv('Variantome_Original/areas_subclons.csv')
areasDF <- areasDF %>%
  select(-contains('X3d7a'), -contains('w41')) %>%
  rename(Old_id = ...1, Old_name = Name) %>%
  mutate(Old_id = gsub('-a|-b|-a/b|-a/b/c', '', Old_id)) %>%
  left_join(gene_rosetta_blasted, by='Old_id') %>%
  select(Gene_id, everything())

## Add manually blasted ids
areasDF[areasDF$Old_id %in% man_blast$Old_id,]$Gene_id <- man_blast$Manual_Blast_Target

areasDF <- areasDF %>%
  filter(!is.na(Gene_id)) %>%
  select(Gene_id, contains('left'), contains('right'), contains('mid'), contains('sides'), -Old_id, -Old_name) %>%
  select(Gene_id, contains('1.2b'), contains('10g'), contains('3d7b')) %>%
  group_by(Gene_id) %>% filter(n() == 1) %>% ungroup()

colnames(areasDF) <- c("Gene_id",
                       "12B_Left", "12B_Right", "12B_Middle", "12B_Sides",
                       "10G_Left", "10G_Right", "10G_Middle", "10G_Sides",
                       "3D7B_Left","3D7B_Right", "3D7B_Middle", "3D7B_Sides")

areasDF <- as.data.frame(areasDF)
rownames(areasDF) <- areasDF$Gene_id
areasDF <-areasDF %>% select(-Gene_id)


##*********************************************************************##
##********************* END OF MODIFIABLE PART ************************##
##*********************************************************************##
#+end_src
*** Create folders for output
#+begin_src R
#### Create folders for output ####

print("Creating folders for Output...")
dir.create(paste0(outdir))
dir.create(paste0(outdir, "/Plots"))
dir.create(paste0(outdir, "/Plots/Array_Plots"))
dir.create(paste0(outdir, "/Plots/MA_Plots"))
dir.create(paste0(outdir, "/Plots/Time_estim/"))
dir.create(paste0(outdir, "/Plots/Ratio"))
dir.create(paste0(outdir, "/Plots/Ratio/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Ratio/Probe_Level"))
dir.create(paste0(outdir, "/Plots/Red_Signal"))
dir.create(paste0(outdir, "/Plots/Red_Signal/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Red_Signal/Probe_Level"))
figPath <- paste0(outdir, "/Plots/")
#+end_src
*** Create Eset: xgene
#+begin_src R
#### Create Eset: xgene ####

exprsx <- as.matrix(gene_level %>% select(contains('X')))
colnames(exprsx) <- sample_names
rownames(exprsx) <- gene_level$Gene_id
fdata <- new("AnnotatedDataFrame", gene_level %>% select(Gene_id, Name, Variant, Annot))
rownames(fdata) <- gene_level$Gene_id
teor_time <- times
type <- types
pdata <- data.frame(type=type, teor_time=teor_time); rownames(pdata) <- sample_names
pdata <- new("AnnotatedDataFrame", pdata)
xgene <- new("ExpressionSet", exprs=exprsx, featureData=fdata, phenoData=pdata)
save(xgene, file=paste0(outdir, '/geneLevel.RData'))

exprsx <- as.matrix(gene_level_noratio %>% select(contains('X')) %>% select(contains('F635')))
rownames(exprsx) <- gene_level_noratio$Gene_id
colnames(exprsx) <- sample_names
xgene_red <- new("ExpressionSet", exprs=exprsx, featureData=fdata, phenoData=pdata)

write.csv(cbind(fdata@data, exprs(xgene)), paste0(outdir, "/geneLevel_exp.csv"), row.names=F)
write.csv(cbind(fdata@data, exprs(xgene_red)), paste0(outdir, "/geneLevel_redSignalexp.csv"), row.names=F)
#+end_src
*** Estimate times
#+begin_src R
#### Estimate times ####

ascendingTime <- function(x){
  current <- 0
  ncycle <- 0
  for (i in 1:length(x)){
    val  <- x[i]+(48*ncycle)
    if (val < current){
      current <- val
      val <- val+48
      ncycle <- ncycle+1
    }
    current <- val
    x[i] <- val
  }
  return(x)
}

estimatedTimes <- read_excel('Variantome_Original/Estimated_Times_3D7.xls')
estimatedTimes <- estimatedTimes %>%
  rename(Sample = `...1`, HPI = x) %>%
  filter(grepl('X1.2b', fixed = T, Sample) |
           grepl('X10g', fixed = T, Sample) |
           grepl('X3d7b', fixed = T, Sample)) %>%
  select(HPI) %>% pull()

#estimatedTimes <- getTimeEstimation(xgene,bozdechPath,LemieuxFunctionsPath,file.path(figPath),B=100)
estimatedTimes[estimatedTimes < 0] <- 0
hpi <- estimatedTimes

for (type in pData(xgene)$type){
  sel <- pData(xgene)$type == type
  typetime <- estimatedTimes[sel]
  time <- ascendingTime(typetime)
  estimatedTimes[sel] <- time
}

write.csv(estimatedTimes, paste0(outdir, "/Estimated_Times.csv"))
pData(xgene)$time <- estimatedTimes
pData(xgene_red)$time <- estimatedTimes
pData(xgene)$hpi <- hpi
pData(xgene_red)$hpi <- hpi
#+end_src
*** Areas functions
#+begin_src R
#### Areas: Functions ####

# imputePoint <- function(xs, ys, tp){
#
#   ## "xs" and "ys" must be two vectors of equal length
#   ## with the corresponding y(expression) and x(timepoint)
#   ## values that form the expression plot of interest (one gene).
#   ## "tp" must be the timepoint to impute.
#   ## If the timepoint to be imputed is already present, leave it as is.
#   ## Returns NA if missing the previous or next tp
#
#   if (tp %in% xs){
#
#     idx <- which(xs == tp)
#     imputed <- list(x=xs[idx], y=ys[idx])
#
#   } else {
#
#     before <- which(xs == max(xs[xs < tp]))
#     after <- which(xs == min(xs[xs > tp]))
#
#     if (is.na(ys[before]) | is.na(ys[after])){
#
#       imputed <- list(x=tp, y=NA)
#
#     } else {
#
#       x <- c(xs[c(before, after)])
#       y <- c(ys[c(before, after)])
#
#       imputed <- approx(x, y, xout=tp)
#     }
#   }
#   return(imputed)
# }
# computeArea <- function(eset){
#
#   ## Takes an eset and computes areas.
#   ## pData(eset) must contain a field named "time" with the time-points.
#   ## pData(eset) must have a field named "type" with the grouping variable.
#
#   ## Set needed variables
#   types <- unique(phenoData(eset)$type)
#   type <- phenoData(eset)$type
#   times <- phenoData(eset)$time
#
#   maxminTP <- max(sapply(types,function(x) min(times[type==x])))
#   minmaxTP <- min(sapply(types,function(x) max(times[type==x])))
#   mybreaks <- seq(maxminTP, minmaxTP, length.out=5)
#   tp1 <- mybreaks[2]
#   tp2 <- mybreaks[3]
#   tp3 <- mybreaks[4]
#
#   xsList <- c()
#   for (type in types){
#     xsList <- c(xsList, list(pData(eset)$time[phenoData(eset)$type == type]))
#   }
#
#   ## Main loop
#   all_areas <- c()
#   for (i in 1:dim(eset)[1]){
#
#     gene <- fData(eset)$geneID[i]
#
#     ysList <- c()
#     for (type in types){
#       ysList <- c(ysList, list(exprs(eset)[i, phenoData(eset)$type == type]))
#     }
#
#     ## Estimate points where needed
#     dfs <- list()
#     for (i in 1:length(xsList)){
#
#       x <- unlist(xsList[[i]])
#       y <- unlist(ysList[[i]])
#
#       points <- as.data.frame(cbind(x, y))
#       midpoints <- points[points$x > maxminTP &
#                             points$x < minmaxTP, ]
#
#       first <- imputePoint(x, y, maxminTP)
#       last <- imputePoint(x, y, minmaxTP)
#       p1 <- imputePoint(x, y, tp1)
#       p2 <- imputePoint(x, y, tp2)
#       p3 <- imputePoint(x, y, tp3)
#
#       impPoints <- rbind(first, last, p1, p2, p3)
#       allpoints <- rbind(midpoints, impPoints)
#       allpoints$x <- as.numeric(allpoints$x)
#       allpoints$y <- as.numeric(allpoints$y)
#
#       ordered <- arrange(allpoints, allpoints$x)
#
#       dfs[[i]] <- ordered
#     }
#
#     ## Calculate minY on estimated DFs
#     minY <- min(sapply(dfs, function(df) min(df$y, na.rm = T)))
#
#     rowareas <- c()
#     for (df in dfs){
#
#       df$y <- df$y - minY
#
#       ## Whole polygon from expression data
#       polDF <- rbind(df,
#                      c(minmaxTP, 0),
#                      c(maxminTP, 0),
#                      c(df[1,]))
#
#       ## Create Polygons
#       leftHalf <- rbind(df[which(df$x <= tp2),],
#                         c(tp2, 0),
#                         c(maxminTP, 0),
#                         c(df[1,]))
#
#       rightHalf <- rbind(df[which(df$x >= tp2),],
#                          c(minmaxTP, 0),
#                          c(tp2, 0),
#                          c(df[df$x == tp2,]))
#
#       mid <- rbind(df[which(df$x >= tp1 & df$x <= tp3),],
#                    c(tp3, 0),
#                    c(tp1, 0),
#                    c(df[df$x == tp1,]))
#
#       sides <- rbind(df[which(df$x <= tp1),],
#                      c(tp1, 0),
#                      c(tp3, 0),
#                      df[which(df$x >= tp3),],
#                      c(minmaxTP, 0),
#                      c(maxminTP, 0),
#                      df[1,])
#
#       pols <- list(leftHalf, rightHalf, mid, sides)
#
#       calcArea <- function(x) {ifelse(any(is.na(x)), NA, Polygon(x)@area)}
#       areas <- unlist(lapply(pols, function(x) calcArea(x)))
#
#       rowareas <- c(rowareas, areas)
#
#       ## Plot polygons (for debugging purposes)
#       ##pol <- Polygon(polDF)
#       ##ps = Polygons(list(pol),1)
#       ##sps = SpatialPolygons(list(ps))
#       ##plot(sps)
#     }
#     all_areas <- c(all_areas, list(rowareas))
#   }
#
#   ## Set row and col names for output
#   areaDF <- do.call(rbind, all_areas)
#   titles <- c("Left", "Right", "Middle", "Sides")
#
#   cols <- c()
#   for (i in types){
#     for (t in titles){
#       name <- paste0(i, "_", t)
#       cols <- c(cols, name)
#     }
#   }
#   colnames(areaDF)  <- cols
#   rownames(areaDF) <- rownames(exprs(eset))
#   return(areaDF)
# }


#+end_src
*** Calls: Compute areas
#+begin_src R
#### Calls: Compute Areas ####

print("Computing Areas...")
# areasDF <- computeArea(xgene)
# old_areasDF <- areasDF


head(areasDF)

areas_df <- as_tibble(areasDF)
areas_df['Gene_id'] <- rownames(areasDF)
areas_df <- areas_df %>%
  select(Gene_id, everything())

#xout <- cbind(fData(xgene), areasDF)
xout <- full_join(fData(xgene), areas_df)
write.csv(xout, paste0(outdir, "/area_geneLevel.csv"), row.names=F)

#+end_src
*** Calculate aAFC (Average Area Fold-Change)
#+begin_src R
#### Calculate aAFC (average Area Fold-Change) ####

myMax <- function(x){
  y <- abs(x)
  if (all(is.na(y))){
    return(list(NA, NA))
  } else {
    pos <- which.max(y)
    times <- c("Left", "Right", "Mid", "Sides")
    return(list(maxVal = x[pos],
                maxTime = times[pos]))
  }
}

## Get number of categories.
n <- length(levels(pData(xgene)$type))

ns <- list()
i <- 1
while (i < n+1){
  ns[[i]] <- 1:4+(4*(i-1))
  i <- i+1
}

## Convert de areasDF into a list of DFs separated by types.
areas <- list()
for (i in 1:length(ns)) {
  areas[[i]] <- areasDF[,ns[[i]]]
}


## Calculate area differences

types <- unique(phenoData(xgene)$type)
type <- phenoData(xgene)$type
times <- phenoData(xgene)$time

maxminTP <- max(sapply(types,function(x) min(times[type==x])))
minmaxTP <- min(sapply(types,function(x) max(times[type==x])))
mybreaks <- seq(maxminTP, minmaxTP, length.out=5)

sets <- 1:length(areas)
combs <- combn(sets, 2)
span <- mybreaks[3] - mybreaks[1]
titles <- c("Left", "Right", "Middle", "Sides")


areaDifs <- list()
for (i in 1:dim(combs)[2]){

  one <- combs[1,i]
  two <- combs[2,i]

  dif1 <- as.data.frame((areas[[one]] - areas[[two]])/span)
  names  <- paste0(colnames(areas[[one]]),
                   "_minus_",
                   colnames(areas[[two]]))

  prefix <- paste0(strsplit(colnames(areas[[one]])[1], "_")[[1]][1],
                   "-",
                   strsplit(colnames(areas[[two]])[1], "_")[[1]][1])
  names <- sapply(titles, function(x) paste(prefix, x, sep = "_"))

  colnames(dif1) <- names

  maxval <- apply(dif1, 1, function(x) myMax(x)[[1]])
  maxtime <- apply(dif1, 1, function(x) myMax(x)[[2]])

  mv <- paste0(prefix, "_MaxVal")
  mt <- paste0(prefix, "_MaxTime")

  dif1[mv] <- maxval
  dif1[mt] <- maxtime

  #dif2 <- -dif1

  ## prefix <- paste0(strsplit(colnames(areas[[two]])[1], "_")[[1]][1],
  ##                  "-",
  ##                  strsplit(colnames(areas[[one]])[1], "_")[[1]][1])
  ## names <- sapply(titles, function(x) paste(prefix, x, sep = "_"))

  ## colnames(dif2) <- names

  areaDifs <- c(areaDifs, list(dif1))#, list(dif2))
}

allDifs <- do.call(cbind, areaDifs)
head(allDifs)


#+end_
*** Areas: Convert partitions into life-stages
#+begin_src R
#### Areas: Convert Partitions into life stages ####

timetostage <- function(tp){
  while(tp > 48){
    tp = tp-48
  }
  return(tp)
}

getStage <- function(tp) {
  if ((tp >= 0) & (tp < 26)) {stg = "ring"}
  else if ((tp >= 26) & (tp < 38)) {stg = "troph"}
  else if ((tp >= 38) & (tp <= 48)) {stg = "schizont"}
  return(stg)
}

fracToStage <- function(frac, tps){
  if (is.na(frac)){
    return(NA)
  } else if (frac == "Left"){
    tp = tps[2]
    getStage(tp)
  } else if (frac == "Right"){
    tp = tps[4]
    getStage(tp)
  } else if (frac == "Mid"){
    tp = tps[3]
    getStage(tp)
  } else if (frac == "Sides"){
    tp1 = tps[1]+(span/4)
    tp2 = tps[4]+(span/4)
    stg1 <- getStage(tp1)
    stg2 <- getStage(tp2)
    return(paste0(stg1,"-",stg2))
  }
}


ncombs <- dim(combs)[2]

maxValCols <- seq(5, ncombs*6, 6)
maxTimeCols <- seq(6, ncombs*6, 6)

aMAFC <- cbind(allDifs[,c(maxValCols, maxTimeCols)])

timeCols <- (ncombs+1):(ncombs*2)

tps <- sapply(mybreaks, function(x) timetostage(x))

for (i in timeCols){
  aMAFC[,i] <- sapply(aMAFC[,i], function(x) fracToStage(x, tps))
}

write.csv(allDifs, paste0(outdir, "/areaDiferences_geneLevel.csv"))
write.csv(aMAFC, paste0(outdir, "/aMAFC_geneLevel.csv"))
#+end_src
*** Create Max Differences table
#+begin_src R
#### Create Max differences table ####

anot_table <- annot %>%
  select(V2, V4, V5) %>%
  rename(Gene_id=V2, Name=V4, Annot=V5) %>%
  dplyr::filter(!is.na(Gene_id)) %>%
  distinct()

head(anot_table)
head(allDifs)

max_df <- allDifs %>%
  mutate(Gene_id = rownames(allDifs)) %>%
  left_join(anot_table, by='Gene_id') %>%
  mutate(MaxMax = pmax(abs(`12B-10G_MaxVal`), abs(`12B-3D7B_MaxVal`), abs(`10G-3D7B_MaxVal`))) %>%
  arrange(desc(abs(MaxMax))) %>%
  select(Gene_id, Name, Annot, contains('MaxVal'), contains('MaxTime'), contains('-'))

max_df_top <- max_df %>% dplyr::filter(abs(`12B-10G_MaxVal`) > 4 | abs(`12B-3D7B_MaxVal`) > 4 | abs(`10G-3D7B_MaxVal`) > 4)

write.csv(max_df, paste0(outdir, "/all_aMAFC.csv"))
write.csv(max_df_top, paste0(outdir, "/top_aMAFC.csv"))
#+end_src
*** PCA Plots
#+begin_src R
#### PCA Plots ####

print("Plotting PCA..")
noNA <- xgene[complete.cases(exprs(xgene))]
df <- t(exprs(noNA))
df <- as.data.frame(df)

pca <- prcomp(df)
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
df_pca$Type <- noNA@phenoData@data$type
df_pca$Time <- noNA@phenoData@data$time

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Type, group = Type))
p <- p + geom_point(aes(size= Time))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))

p <- p + theme_classic()
p <- p + theme(text = element_text(size=20))
p

ggsave(p, filename = paste0(figPath, "PCA.svg"), device = "svg")
#+end_src
*** Add Gametocyte genes info
#+begin_src R
#### Add gametocyte genes info ####
library(readxl)
gene_lists <- read_excel('../All gene lists_160719.xlsx', sheet = 2)

gam_genes <- gene_lists %>%
  select(`Lopez-Barragan`, Lasonder, Gametocites_Young, contains('gam'))

gam_list <- unique(gam_genes %>% pull())
gam_list[gam_list == 'NA'] <- NA
gam_list <- gam_list[!is.na(gam_list)]

finalDF <- max_df %>%
  select(Gene_id, Name, Annot, contains('MaxVal'), contains('MaxTime'))

finalDF['GamGene'] <- finalDF$Gene_id %in% gam_list

write.csv(finalDF, paste0(outdir, "/final_summary_table.csv"), row.names = F)


fData(xgene)

tibble(finalDF) %>%
  left_join(fData(xgene) %>% select(Gene_id, Variant), by = 'Gene_id') %>%
  filter(abs(`12B-10G_MaxVal`) > 1 |
         abs(`12B-3D7B_MaxVal`) > 1 |
         abs(`10G-3D7B_MaxVal`) > 1) %>%
  filter(is.na(Variant))


#+end_src
*** VAR genes plot
#+begin_src R
#### Var genes plot ####

gene_fam <- read_excel('/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/cvgfamilylist/Supplementary_table_2_CVG_list_161120_ap.xlsx', sheet = 2)
gene_fam <- gene_fam %>%
  rename(Gene_id = `Gene ID`,
         Gene_name = `Gene Name or Symbol`,
         SubFamily = `Family Detail`) %>%
  # mutate(SubFamily = case_when(SubFamily == 'var pseudo,truncated or -like.' ~ 'var-like',
  #                              TRUE ~ SubFamily)) %>%
  select(Gene_id, Gene_name, Family, SubFamily)

red_df <- as.data.frame(exprs(xgene_red))
red_df <- red_df %>%
  mutate(Gene_id = rownames(red_df)) %>%
  left_join(gene_fam, by='Gene_id')

varPlot <- function(strain){

  vals <- red_df %>% select(contains('tp') & contains(strain))
  max_tps <- colnames(vals)[apply(vals,1,which.max)]
  max_tps <- gsub(paste0(strain, '_'), '', max_tps)

  plot_df <- red_df %>%
    mutate(Max = select(., contains(strain)) %>% do.call(pmax, .)) %>%
    mutate(MaxTime = max_tps) %>%
    select(Gene_id, Max, MaxTime, Family, SubFamily) %>%
    dplyr::filter(Family == 'VAR' & SubFamily != 'var pseudo,truncated or -like.')

  write_csv(plot_df, paste0(outdir, 'max_VAR_redsignal_', strain, '.csv'))

  vars_plot <- ggplot(plot_df, aes(x = Gene_id, y = Max)) +
    geom_bar(stat = 'identity') +
    ggtitle(paste0('VAR gene expression ', strain)) +
    ylab(paste0('Normalized Cy5 signal')) +
    theme_classic() +
    theme(axis.text.x=element_text(angle = -90, hjust = 0)) +
    coord_cartesian(ylim = c(0,60000))

  #print(vars_plot)

  ggsave(paste0(figPath, strain, '_var_genes_red.pdf'), vars_plot, device = 'pdf')

  ## Tp 10 Plot
  plot10tp_df <- red_df %>%
    select(Gene_id, contains(strain) & contains('tp10'), Family, SubFamily) %>%
    set_names(c('Gene_id', 'RedSignal', 'Family', 'SubFamily')) %>%
    dplyr::filter(Family == 'VAR' & SubFamily != 'var pseudo,truncated or -like.')

  write_csv(plot10tp_df, paste0(outdir, 'max_VAR_redsignal_tp10_', strain, '.csv'))


  vars10tp_plot <- ggplot(plot10tp_df, aes(x = Gene_id, y = RedSignal)) +
    geom_bar(stat = 'identity') +
    ggtitle(paste0('VAR gene expression ', strain)) +
    ylab(paste0('Normalized Cy5 signal')) +
    theme_classic() +
    theme(axis.text.x=element_text(angle = -90, hjust = 0)) +
    coord_cartesian(ylim = c(0,60000))

  #print(vars10tp_plot)
  ggsave(paste0(figPath, strain, '_var_genes_red_tp10.pdf'), vars10tp_plot, device = 'pdf')
}


strains <- c('12B', '10G', '3D7B')
for (strain in strains) {varPlot(strain)}
#+end_src
*** Single Gene Plot
#+begin_src R
#### Single Gene Plot ####
plot_gene <- function(type, gid, out){
  ## Set df and lims depending on what we are plotting.
  if (type == "gene"){
    df = xgene
    path = "/Ratio/Gene_Level/"

  } else if (type == "gene_red"){
    df = xgene_red
    path = "/Red_Signal/Gene_Level/"

  } else if (type == "probe"){
    df = xprobe
    path = "/Ratio/Probe_Level/"

  } else if (type == "probe_red"){
    df = xprobe_red
    path = "/Red_Signal/Probe_Level/"

  }

  ## Set ylims
  ylim = c(min(exprs(df), na.rm = T), max(exprs(df), na.rm = T))


  ## Plot
  ## Set gene for title or gene and probe for probe-level plots.
  gn <- gsub("[/:;.]", "_", gid)
  if (type %in% c("probe", "probe_red")){
    prb <- paste0("_", gsub("[/:;.]", "_" , gid))
  } else {
    prb <- ""
  }
  title <- paste0(gn, prb)

  ## Set y-axis title depending on ratio/red_signal
  ytitle <- ifelse(type %in% c("gene_red", "probe_red"), 'log2(Cy5)', 'log2(Cy3/Cy5)')

  ## Plot
  graf <- melt(df[fData(df)$Gene_id == gid,])
  graf["Type"] <- xgene@phenoData@data$type
  graf["Time"] <- xgene@phenoData@data$time
  p <- ggplot(graf, aes(x = Time, y = value, col = Type, group = Type))
  p <- p + geom_point(aes(color = Type, size = 2))
  p <- p + geom_line(aes(size = 2))
  p <- p + coord_cartesian(ylim = ylim)
  p <- p + theme_classic()
  # p <- p + ggtitle(title)
  # p <- p + ylab(ytitle)
  p <- p + theme(text = element_text(size = 36))
  p <- p + theme(axis.title.x = element_blank())
  p <- p + theme(axis.title.y = element_blank())
  p <- p + theme(legend.position = 'none')
  ggsave(p, file=out, device = "svg")
  print(p)
}

type <- 'gene'
gid <- 'PF3D7_0302200'
outpath <- '/home/lucas/Documents/BioMalPar_2021/Microarrays/Gene_plots/'
outname <- 'PF3D7_0302200_12b10g.svg'

plot_gene(type, gid, paste0(outpath, outname))

#+end_src
*** Filter aFCs
**** Red Filter
#+begin_src R
xgene_red_tibble <- as.data.frame(exprs(xgene_red)) %>%
  tibble() %>%
  mutate(Gene_id = rownames(exprs(xgene_red))) %>%
  select(Gene_id, everything())

## First get maxcol then percentile (OLD)
## get_red_percent <- function(strain){

##   ## Subset to strain
##   red_strain <- xgene_red_tibble %>%
##     select(Gene_id, contains(strain))

##   ## Calculate Max col
##   maxred <- red_strain %>%
##     dplyr::select(-Gene_id) %>%
##     mutate(Max_Red = do.call(pmax, (.))) %>%
##     select(Max_Red)

##   ## Create "percentile" function from Max col
##   percentile <- ecdf(maxred$Max_Red)
##   red_pcnt <- percentile(maxred$Max_Red)

##   return(red_pcnt)
## }

## perc_12B <- get_red_percent('12B')
## perc_10G <- get_red_percent('10G')

## red_percent <- tibble('Gene_id' = xgene_red_tibble$Gene_id,
##                       '12B' = perc_12B,
##                       '10G' = perc_10G)


## First percentile per col -> max percentile (NEW)

my_percentile <- function(vector){
  ecdf(vector)(vector)*100
}

xgene_red_tibble <- xgene_red_tibble %>%
  mutate(across(.cols = -Gene_id, .fns = my_percentile, .names = "Perc_{.col}"))

get_max_percent <- function(strain){

  ## Subset to strain
  red_strain <- xgene_red_tibble %>%
    select(Gene_id, contains('Perc') & contains(strain))

  ## Calculate Max col
  maxperc <- red_strain %>%
    dplyr::select(-Gene_id) %>%
    mutate(Max_Perc = do.call(pmax, c(., na.rm = T))) %>%
    select(Max_Perc) %>%
    pull()
  return(maxperc)
}

perc_12B <- get_max_percent('12B')
perc_10G <- get_max_percent('10G')
perc_3D7B <- get_max_percent('3D7B')

red_percent <- tibble('Gene_id' = xgene_red_tibble$Gene_id,
                      '12B' = perc_12B,
                      '10G' = perc_10G,
                      '3D7B' = perc_3D7B)

##hist(red_percent$`12B`)

write_csv(red_percent, paste0(outdir, "/red_percentiles.csv"))
names(red_percent)[2:4] <- paste0('Red_Pcnt_', names(red_percent)[2:4])

max_tibble <- as_tibble(max_df)
max_tibble <- max_tibble %>%
  left_join(red_percent, by='Gene_id', suffix = c('', '_Pcnt'))

maxFC_passe_red <- max_tibble %>%
  filter((`12B-10G_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
         (`12B-10G_MaxVal` <= -2 & Red_Pcnt_10G > 15) |
         (`12B-3D7B_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
         (`12B-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15) |
         (`10G-3D7B_MaxVal` >= 2 & Red_Pcnt_10G > 15) |
         (`10G-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15))

#+end_src
**** Get Max-Time for each gene
#+begin_src R
#### Get MaxTime for each gene ####

myWhichMax <- function(vect){
  if (all(is.na(vect))){
    return(NA)
  } else {
    return(which.max(vect))
  }
}

exp <- as.data.frame(exprs(xgene))

maxcol <- exp %>%
  apply(1, myWhichMax) %>%
  unlist()

times <- pData(xgene) %>%
  select(time) %>%
  pull()

maxtime <- sapply(maxcol, function(x) times[x])
head(maxtime)

max_time <- tibble(Gene_id = names(maxtime), Max_Time = maxtime)
breaks_df <- tibble(Areas_Breaks = mybreaks)

tibble(Gene_id = names(maxtime), Max_Time = maxtime) %>%
  write_csv(paste0(outdir, 'old_arrays_maxtime.csv'))

tibble(Areas_Breaks = mybreaks) %>%
  write_csv(paste0(outdir, 'old_area_breaks.csv'))
#+end_src
**** Filter Genes by timepoint
#+begin_src R
## #### Filter by Max-Time ####

## New approach
## Check which areas does maxtimepoint overlapp -> check if aAFC > th at this areas

point_overlap <- function(point, interval){
  point >= interval[1] & point <= interval[2]
}

areas_df <- as_tibble(allDifs) %>%
  mutate(Gene_id = rownames(allDifs)) %>%
  select(Gene_id, everything())

maxtimes_12B_10G <- c()
maxtimes_12B_3D7B <- c()
maxtimes_10G_3D7B <- c()
gids <- c()
th <- 2
for (gid in max_tibble$Gene_id){

  #gid <- 'PF3D7_0324600'
  ## Create time-regions
  breaks <- breaks_df$Areas_Breaks
  left <- c(breaks[1], breaks[3])
  right <- c(breaks[3], breaks[5])
  mid <- c(breaks[2], breaks[4])
  sides_l <- c(breaks[1], breaks[2])
  sides_r <- c(breaks[4], breaks[5])

  ## Get maxtime
  maxtime <- max_time %>%
    filter(Gene_id == gid) %>%
    pull()
  if (is.na(maxtime)){
    maxtimes_12B_10G <- c(maxtimes_12B_10G, NA)
    maxtimes_12B_3D7B <- c(maxtimes_12B_3D7B, NA)
    maxtimes_10G_3D7B <- c(maxtimes_10G_3D7B, NA)
    gids <- c(gids, gid)
  } else {
    ## Ensure maxtime is in the areas intervals
    if (maxtime < breaks[1]) {maxtime <- breaks[1]}
    if (maxtime > breaks[5]) {maxtime <- breaks[5]}

    ## Get overlappped areas
    areas <- list('left' = left, 'right' = right, 'mid' = mid,
                  'sides' = sides_l, 'sides' = sides_r)
    overlaps <- sapply(areas, function(x) point_overlap(maxtime, x))

    ## Get aAFC in overlapping areas by comparison
    aFCs <- areas_df %>%
      filter(Gene_id == gid) %>%
      select(contains(names(areas[overlaps])))

    fc_12B_10G <- aFCs %>%
      select(contains('12B-10G')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_12B_10G <- any(abs(fc_12B_10G) > th)

    fc_12B_3D7B <- aFCs %>%
      select(contains('12B-3D7B')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_12B_3D7B <- any(abs(fc_12B_3D7B) > th)

    fc_10G_3D7B <- aFCs %>%
      select(contains('10G-3D7B')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_10G_3D7B <- any(abs(fc_10G_3D7B) > th)

    maxtimes_12B_10G <- c(maxtimes_12B_10G, maxtime_FC_12B_10G)
    maxtimes_12B_3D7B <- c(maxtimes_12B_3D7B, maxtime_FC_12B_3D7B)
    maxtimes_10G_3D7B <- c(maxtimes_10G_3D7B, maxtime_FC_10G_3D7B)
    gids <- c(gids, gid)
  }
}
maxtime_aAFC_df <- tibble(
  Gene_id = gids,
  MaxTime_Filter_12B_10G = maxtimes_12B_10G,
  MaxTime_Filter_12B_3D7B = maxtimes_12B_3D7B,
  MaxTime_Filter_10G_3D7B = maxtimes_10G_3D7B
  )

maxtime_aAFC_df %>%
  count(MaxTime_Filter_12B_10G)

max_tibble <- max_tibble %>%
  left_join(maxtime_aAFC_df)


## final_llcm['MaxTime'] <- maxtime
## final_ll0['MaxTime'] <- maxtime
## final_lls['MaxTime'] <- maxtime

## tibble(finalDF)[,1:4]

## trans_df <- tibble(allDifs) %>%
##   mutate(Gene_id = rownames(allDifs)) %>%
##   select(Gene_id, everything())

## trans_df


## ## Define intervals
## left <- c(mybreaks[1], mybreaks[2])
## right <- c(mybreaks[3], mybreaks[5])
## mid <- c(mybreaks[2], mybreaks[4])
## sides1 <- c(mybreaks[1], mybreaks[2])
## sides2 <- c(mybreaks[4], mybreaks[5])

## checkOverap <- function(v1, v2){
##   v1[1] <= v2[2] & v2[1] <= v1[2]
## }

## getInterval <- function(x, width){
##   ## Will break if interval spans > 48h ("circular interval")
##   x_low <- ifelse(x-width >= mybreaks[1], x-width, mybreaks[1])
##   x_high <- ifelse(x+width <= mybreaks[5], x+width, mybreaks[5])
##   max_interval <- c(x_low, x_high)
##   return(max_interval)
## }

## ## Set width arround maxtime
## width <- 10

## ## Check wether each interval overlaps with MaxTime
## trans_df['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))

## final_llcm['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))
## final_llcm['Right_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), right))
## final_llcm['Mid_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), mid))
## final_llcm['Sides_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), sides1) | checkOverap(getInterval(x, width), sides2))

## final_ll0['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))
## final_ll0['Right_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), right))
## final_ll0['Mid_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), mid))
## final_ll0['Sides_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), sides1) | checkOverap(getInterval(x, width), sides2))

## final_lls['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))
## final_lls['Right_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), right))
## final_lls['Mid_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), mid))
## final_lls['Sides_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), sides1) | checkOverap(getInterval(x, width), sides2))

## head(final_llcm)

## ## Check wether max falls in MaxTime (contrast by contrast)
## final_llcm <- final_llcm %>%
##   mutate(Max_in_MaxTime = case_when(MaxFC_Interval == "left" & Left_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "right" & Right_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "mid" & Mid_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "sides" & Sides_in_MaxTime ~ TRUE,
##                                     TRUE ~ FALSE))

## final_ll0 <- final_ll0 %>%
##   mutate(Max_in_MaxTime = case_when(MaxFC_Interval == "left" & Left_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "right" & Right_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "mid" & Mid_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "sides" & Sides_in_MaxTime ~ TRUE,
##                                     TRUE ~ FALSE))

## final_lls <- final_lls %>%
##   mutate(Max_in_MaxTime = case_when(MaxFC_Interval == "left" & Left_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "right" & Right_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "mid" & Mid_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "sides" & Sides_in_MaxTime ~ TRUE,
##                                     TRUE ~ FALSE))
#+end_src
**** Filter Genes by Deletions/Duplications
#+begin_src R
f_path <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/Duplication_Deletion_Regions_Mean_Separate_DuplDel/Crossed_with_genes/'

file_list <- c('1.2B_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered_genes.tsv',
               '10G_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered_genes.tsv'
)

dupl_dl_12B <- read_tsv(paste0(f_path, file_list[1]), col_names = F) %>%
  select(X1) %>% pull()

dupl_dl_10G <- read_tsv(paste0(f_path, file_list[2]), col_names = F) %>%
  select(X1) %>% pull()
#+end_src
*** Get Final List of Genes
#+begin_src R
## Load Latest Annot
info_df <- read_csv(paste0(infiles, 'info_df.csv')) %>%
  dplyr::filter(!is.na(Gene_id))

final_df <- max_tibble %>%
  mutate(Gene_id = ifelse(Gene_id == 'PF3D7_0935400_as', 'PF3D7_0935390', Gene_id)) %>%
  mutate(Not_Plasmodium = !Gene_id %in% info_df$Gene_id)

final_df <- final_df %>%
  select(-Name, -Annot) %>%
  left_join(info_df, by='Gene_id')

colnames(final_df)

all_df <- final_df %>%
  select(
    Gene_id,
    contains('MaxVal'),
    contains('MaxTime'),
    contains('Red'),
    contains('Filter'),
  )

## Set thresholds
red_th <- 15

## 12B vs 10G

final_df %>%
  select(
    Gene_id,
    `12B-10G_MaxVal`,
    `12B-10G_MaxTime`,
    Red_Pcnt_12B,
    Red_Pcnt_10G,
    MaxTime_Filter_12B_10G
  ) %>%
  mutate(PassRed = ifelse(
           `12B-10G_MaxVal` >= 0,
           Red_Pcnt_12B >= red_th,
           Red_Pcnt_10G >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_12B_10G) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_12B & !Gene_id %in% dupl_dl_10G) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, '12B_10G_final_df.tsv'))

## 12B vs 3D7B

final_df %>%
  select(
    Gene_id,
    `12B-3D7B_MaxVal`,
    `12B-3D7B_MaxTime`,
    Red_Pcnt_12B,
    Red_Pcnt_3D7B,
    MaxTime_Filter_12B_3D7B
  ) %>%
  mutate(PassRed = ifelse(
           `12B-3D7B_MaxVal` >= 0,
           Red_Pcnt_12B >= red_th,
           Red_Pcnt_3D7B >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_12B_3D7B) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_12B) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, '12B_3D7B_final_df.tsv'))

## 10G vs 3D7B

final_df %>%
  select(
    Gene_id,
    `10G-3D7B_MaxVal`,
    `10G-3D7B_MaxTime`,
    Red_Pcnt_10G,
    Red_Pcnt_3D7B,
    MaxTime_Filter_10G_3D7B
  ) %>%
  mutate(PassRed = ifelse(
           `10G-3D7B_MaxVal` >= 0,
           Red_Pcnt_10G >= red_th,
           Red_Pcnt_3D7B >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_10G_3D7B) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_10G) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, '10G_3D7B_final_df.tsv'))


###################################################3


maxFC_pass_red <- final_df %>%
  filter((`12B-10G_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
         (`12B-10G_MaxVal` <= -2 & Red_Pcnt_10G > 15) |
         (`12B-3D7B_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
         (`12B-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15) |
         (`10G-3D7B_MaxVal` >= 2 & Red_Pcnt_10G > 15) |
         (`10G-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15))

## 12B vs 10G

difs_12B_10G <- final_df %>%
  filter(
  ((`12B-10G_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
   (`12B-10G_MaxVal` <= -2 & Red_Pcnt_10G > 15)) &
  MaxTime_Filter_12B_10G
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_12B | Gene_id %in% dupl_dl_10G) %>%
    dplyr::filter(!Not_Plasmodium & !Is_tRNA) %>%
  select(Gene_id, Name, Annot,
         `12B-10G_MaxVal`,
         Red_Pcnt_12B, Red_Pcnt_10G,
         MaxTime_Filter_12B_10G,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_12B_10G, paste0(outdir, '12B_vs_10G_log2FC2_red15_maxtime.csv'))


## 12B vs 3D7B

difs_12B_3D7B <- final_df %>%
  filter(
  ((`12B-3D7B_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
   (`12B-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15)) &
  MaxTime_Filter_12B_3D7B
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_12B) %>%
  select(Gene_id, Name, Annot,
         `12B-3D7B_MaxVal`,
         Red_Pcnt_12B, Red_Pcnt_3D7B,
         MaxTime_Filter_12B_3D7B,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_12B_3D7B, paste0(outdir, '12B_vs_3D7B_log2FC2_red15_maxtime.csv'))


## 10G vs 3D7B

difs_10G_3D7B <- final_df %>%
  filter(
  ((`10G-3D7B_MaxVal` >= 2 & Red_Pcnt_10G > 15) |
   (`10G-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15)) &
  MaxTime_Filter_10G_3D7B
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_10G) %>%
  select(Gene_id, Name, Annot,
         `10G-3D7B_MaxVal`,
         Red_Pcnt_10G, Red_Pcnt_3D7B,
         MaxTime_Filter_10G_3D7B,
         Variant, Gam_specific, Dupl_Del)


write_csv(difs_10G_3D7B, paste0(outdir, '10G_vs_3D7B_log2FC2_red15_maxtime.csv'))

write_csv(final_df, paste0(outdir, 'old_arrays_final_df.csv'))

#+end_src
*** Make Venn Diagram
#+begin_src R
library(eulerr)

A <- difs_12B_10G$Gene_id
B <- difs_12B_3D7B$Gene_id
C <- difs_10G_3D7B$Gene_id

AB <- intersect(A, B)
AC <- intersect(A, C)
BC <- intersect(B, C)

ABC <- intersect(AB, C)

abc <- length(ABC)
ab <- length(AB[!AB %in% ABC])
ac <- length(AC[!AC %in% ABC])
bc <- length(BC[!BC %in% ABC])

a <- length(A) -ab -ac -abc
b <- length(B) -ab -bc -abc
c <- length(C) -ac -bc -abc

fit <- euler(c(A=a, B=b, C=c, "A&B"=ab, "A&C"=ac, "B&C"=bc, "A&B&C" = abc))

scales::viridis_pal()(3)

d <- plot(fit, fills = list(fill = c('#440154FF', "#21908CFF", "#FDE725FF"), alpha = 0.5),
          edges = list(lwd = 0.1),
          quantities = list(quantities = T),
          labels = list(labels=c("1.2B vs 10G", "1.2B vs 3D7B", "10G vs 3D7B")))

ggsave(d, filename = paste0(figPath, "Difs_Venn.pdf"), device = "pdf",
       width = 15, height = 15, units = 'cm')

plot(d)
print(fit)
#+end_src
*** Save/Load environtment
#+begin_src R
#### Save environtment ####
##save.image(file = "array_12B10G3D7B_VariantomeData_work_space.RData")
##setwd('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/Old_Arrays/')
##load('array_12B10G3D7B_VariantomeData_work_space.RData')
##head(finalDF)
#+end_src

** A7, E5 and B11 (New_Arrays)
:PROPERTIES:
:header-args:R: :session new_arrays :tangle ./Paper_Analysis/Scripts/Microarrays/microarray_analysis_A7_E5_B11.R :results none
:END:
*** Import libraries
#+begin_src R
#### Import libraries ####

print("Importing Libraries...")
list.of.packages <- c("reshape2", "ggfortify", "tidyverse", "RColorBrewer", "sp")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(reshape2)
library(ggfortify)
library(tidyverse)
library(RColorBrewer)
library(sp)
library(readxl)

if (!("Biobase" %in% installed.packages()[,"Package"])){
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install()
}

library(Biobase)
#+end_src
*** Experiment Setup (modifiable part)
#+begin_src R
############## Experiment Setup: MODIFY THIS PART #######################
##*********************************************************************##
##*********************************************************************##

setwd('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/New_Arrays/')
datadir <- "./RawData/"
outdir <- "./R_results_NewArray/"

annot <- read.csv("./Files/array_anotation.csv", sep="\t", header = F)
## Add new GDV1as annotation
levels(annot$V2) <- c(levels(annot$V2), 'PF3D7_0935390')
annot[annot$V2 == 'PF3D7_0935400_as' & !is.na(annot$V2),]$V2 <- 'PF3D7_0935390'

infiles <- "./Files/"

sample_names <- sub("\\.txt$", "", list.files(datadir, pattern="\\.txt$"))
nsamples <- length(sample_names)

times <- as.integer(factor(sub("^.+_tp", "", sample_names)))
types <- sub("_tp.+", "", sample_names)

array_list <- lapply(list.files(datadir, pattern="\\.txt$", full.names=TRUE), read.table, sep="\t", stringsAsFactors=FALSE, skip=9, header=TRUE)
names(array_list) <- sample_names

run_all_plots <- "no"

#+end_src
*** Create folders for output
#+begin_src R
#### Create folders for output ####

print("Creating folders for Output...")
dir.create(paste0(outdir))
dir.create(paste0(outdir, "/Plots"))
dir.create(paste0(outdir, "/Plots/Array_Plots"))
dir.create(paste0(outdir, "/Plots/MA_Plots"))
dir.create(paste0(outdir, "/Plots/Time_estim/"))
dir.create(paste0(outdir, "/Plots/Ratio"))
dir.create(paste0(outdir, "/Plots/Ratio/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Ratio/Probe_Level"))
dir.create(paste0(outdir, "/Plots/Ratio/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Red_Signal"))
dir.create(paste0(outdir, "/Plots/Red_Signal/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Red_Signal/Probe_Level"))
figPath <- paste0(outdir, "/Plots/")
#+end_src
*** Load Array Annotation
#+begin_src R
#### Load Array annotation, Gene-list and Variant Genes ####

print("Loading Array Annotation...")
gene_list <- readLines(paste0(infiles, "gene_list.txt"))
gene_list <- c(gene_list, 'PF3D7_0935390')

cvgs <- read.csv2(paste0(infiles, 'taula_CVG_final.csv'), stringsAsFactors = F)
cvgs <- cvgs %>%
  select(Gene_id = Gene.ID, Variant = Final.Customized) %>%
  mutate(Variant = ifelse(Variant == 'YES', TRUE, FALSE)) %>%
  add_row(Gene_id = 'PF3D7_0935390', Variant = TRUE)

annot_df <- read_csv(paste0(infiles, 'info_df.csv')) %>%
  select(Gene_id, Name, Annot) %>%
  dplyr::filter(!is.na(Gene_id)) %>%
  left_join(cvgs, by = 'Gene_id') %>%
  replace_na(list(Variant = FALSE)) %>%
  select(Gene_id, Name, Variant, Annot)
#+end_src
*** Create probe_df
#+begin_src R
#### Create Probe-DF ####

print("Creating Probe DF...")
probe_df <- array_list[[1]][,c(7,11,14,15)]
probe_df_geo <- array_list[[1]][,c(7,11,14,15)]

getCols <- function(df){
  return(df[,c(11,14,15)])
}

goodCols <- lapply(array_list[2:nsamples], function(x) getCols(x))
df <- do.call("cbind", goodCols)

probe_df <- cbind(probe_df, df)
probe_df_geo <- cbind(probe_df_geo, df)
dim(probe_df)
dim(probe_df_geo)

probe_df["Gene_id"] <- annot$V2
probe_df <- probe_df %>%
  left_join(annot_df, by = 'Gene_id')

probe_df_geo["Gene_id"] <- annot$V2
probe_df_geo <- probe_df_geo %>%
  left_join(annot_df, by = 'Gene_id')

## probe_df["name"] <- annot$V4
## probe_df["Annot"] <- annot$V5

probe_df["Annot"] <- gsub("Plasmodium", "Pl.", probe_df$Annot)
probe_df["Annot"] <- gsub("protein", "prot.", probe_df$Annot)
probe_df["Annot"] <- gsub("membrane", "memb.", probe_df$Annot)
probe_df["Annot"] <- gsub("conserved", "cvd.", probe_df$Annot)
probe_df["Annot"] <- gsub("function", "func.", probe_df$Annot)
probe_df["Annot"] <- gsub("unknown", "ukwn.", probe_df$Annot)
probe_df["Annot"] <- gsub("exported", "xptd.", probe_df$Annot)
probe_df["Annot"] <- gsub("pseudogene", "pseudo", probe_df$Annot)
probe_df["Annot"] <- gsub("putative", "put.", probe_df$Annot)
probe_df["Annot"] <- gsub("%2C", "", probe_df$Annot)

## Remove probes that map to multiple genes.
probe_df <- probe_df[annot$V3 != "drop" | is.na(annot$V3),]

probe_df_geo['Drop_Mulimapper'] <- annot$V3 == "drop"
head(probe_df_geo)


## ## Add Variant Genes information
## varlist <- dplyr::filter(cvgs, Variant) %>% select(Gene_id)
## probe_df["Variant"] <- probe_df$Gene_id %in% varlist
#+end_src
*** Group Columns
#+begin_src R
#### Group Columns ####

signalCols <- nsamples*3+1
allcols <- dim(probe_df)[2]

ratioCols <- seq(2, signalCols, 3)
redCols <- seq(4, signalCols, 3)
greCols <- seq(3, signalCols, 3)

infoCols <- c(1, (signalCols+1):allcols)
#+end_src
*** Remove Low-expression Probes
#+begin_src R
#### Remove low expression probes ####

print("Removing low expression probes...")
medians <- list()
for (i in 1:nsamples){
  redm <- median(sort(probe_df[probe_df$Gene_id %in% gene_list, redCols][,i])[1:100])
  grenm <- median(sort(probe_df[probe_df$Gene_id %in% gene_list, greCols][,i])[1:100])
  medians[[i]] <- c(grenm, redm)
}

passTest <- list()
for(i in 1:nsamples){
  g <- probe_df[,greCols][i] < 3*medians[[i]][1]
  r <- probe_df[,redCols][i] < 3*medians[[i]][2]
  all <- g & r
  passTest[[i]] <- !all
}

testDF <- as.data.frame(passTest)
pass <- rowSums(testDF) > 0
write.csv(table(!pass), paste0(outdir, "/NA_probes.csv"))
probe_df[!pass,c(ratioCols)] <- NA

## Mark low expression probes for GEO df
medians_geo <- list()
for (i in 1:nsamples){
  redm <- median(sort(probe_df_geo[probe_df_geo$Gene_id %in% gene_list, redCols][,i])[1:100])
  grenm <- median(sort(probe_df_geo[probe_df_geo$Gene_id %in% gene_list, greCols][,i])[1:100])
  medians_geo[[i]] <- c(grenm, redm)
}

passTest_geo <- list()
for(i in 1:nsamples){
  g <- probe_df_geo[,greCols][i] < 3*medians[[i]][1]
  r <- probe_df_geo[,redCols][i] < 3*medians[[i]][2]
  all <- g & r
  passTest_geo[[i]] <- !all
}

testDF_geo <- as.data.frame(passTest_geo)
pass_geo <- rowSums(testDF_geo) > 0
length(pass_geo)
probe_df_geo['Drop_LowExpress'] <- !pass_geo

#+end_src
*** Array Plots
#+begin_src R
#### Array Plots ####

print("Plotting Arrays...")
cols <- rev(brewer.pal(11, 'Spectral'))

arrayPlot <- function(df) {
  df_name <- sample_names[i]
  p1 <- qplot(Col, Row, data=df, color=log2(rMedianSignal)<7) + scale_color_manual(values=c("aliceblue", "black")) + ggtitle(df_name)
  ggsave(p1, filename = paste0(figPath, "Array_Plots/sample_", df_name, "_boolean.jpeg"), device = "jpeg")

  p2 <- qplot(Col, Row, data=df, color=log2(rMedianSignal)) + scale_colour_gradientn(colours = cols) + ggtitle(df_name)
  ggsave(p2, filename = paste0(figPath, "Array_Plots/sample_", df_name, ".jpeg"), device = "jpeg")

  p3 <- qplot(Col, Row, data=df, color=is.na(LogRatio)) + scale_color_manual(values=c("aliceblue", "red")) + ggtitle(df_name)
  ggsave(p3, filename = paste0(figPath, "Array_Plots/sample_", df_name, "_NAs.jpeg"), device = "jpeg")
}

for (i in 1:length(array_list)) {arrayPlot(array_list[[i]])}
#+end_src
*** MA Plots
#+begin_src R
#### MA Plots ####

print("Plotting MA Plots...")
myMAplot  <- function(mray){
  df_name <- sample_names[i]
  m_vals <- log2(mray$gProcessedSignal) - log2(mray$rProcessedSignal)
  a_vals <- (log2(mray$gProcessedSignal) + log2(mray$rProcessedSignal))/2
  ma_df <- cbind(a_vals, m_vals)
  p <- ggplot(ma_df, aes(x=a_vals, y=m_vals))
  p <- p + geom_point()
  p <- p + geom_smooth(method = "lm", se=F, color= "red")
  p <- p + geom_hline(yintercept=0, color = "blue", size = 1)
  ggsave(p, filename = paste0(figPath, "MA_Plots/sample_", df_name, "_MA.jpeg"), device = "jpeg")
}

for (i in 1:length(array_list)) {myMAplot(array_list[[i]])}

#+end_src
*** Change to Log2 (Log-Ratio Cols, originally log10)
#+begin_src R
#### Change to Log2 (Log Ratio cols, originally log10) ####

print("Creating Eset...")
probe_df[,ratioCols] <- log2(10**probe_df[,ratioCols])
probe_df_geo[,ratioCols] <- log2(10**probe_df_geo[,ratioCols])

#+end_src
*** Change to Log2 (Raw data Cols, originally unlogged)
#+begin_src R
#### Change to Log2 (Raw signal Cols, originally unlogged) ####

probe_df[,redCols]  <- log2(probe_df[,redCols])
probe_df_geo[,redCols]  <- log2(probe_df_geo[,redCols])
#+end_src
*** Create Eset: xprobe
#+begin_src R
#### Create eSet: xprobe ####

exprsx <- as.matrix(probe_df[,ratioCols])
colnames(exprsx) <- sample_names
fdata <- new("AnnotatedDataFrame", probe_df[,infoCols])
teor_time <- times
type <- types
pdata <- data.frame(type=type, teor_time=teor_time); rownames(pdata) <- sample_names
pdata <- new("AnnotatedDataFrame", pdata)
xprobe <- new("ExpressionSet", exprs=exprsx, featureData=fdata, phenoData=pdata)
save(xprobe,file=paste0(outdir, '/probeLevel.RData'))

exprsx <- as.matrix(probe_df[,redCols])
colnames(exprsx) <- sample_names
xprobe_red <- new("ExpressionSet", exprs=exprsx, featureData=fdata, phenoData=pdata)

write.csv(cbind(fdata@data, exprs(xprobe)), paste0(outdir, "/probeLevel_exp.csv"), row.names=F)
write.csv(cbind(fdata@data, exprs(xprobe_red)), paste0(outdir, "/probeLevel_redSignalexp.csv"), row.names=F)
#+end_src
*** Rename and Summarize
#+begin_src R
#### Rename and Summarize ####

myRma <- function(x) {
  if (class(x)=='numeric') {
    ans <- x
  } else {
    ans <- medpolish(x,trace.iter=FALSE,na.rm=TRUE)
    ans <- ans$overall + ans$col
  }
  return(ans)
}

renameGenesAndSummarize <- function(genesToRename.sd,exprsx,geneid,summaryMethod=myRma,type) {

  if (type == "ratio"){
    xgene <- by(exprsx[,ratioCols],geneid,myRma)
  } else if (type == "red"){
    xgene <- by(exprsx[,redCols],geneid,myRma)
  }

  xgene <- do.call('rbind',xgene)

  mysd <- function(x) { ans <- ifelse(sum(!is.na(x))==1,0,sd(x,na.rm=TRUE)); return(ans) }
  sdgene <- aggregate(exprsx[, ratioCols],by=list(geneid),FUN=mysd)

  names(sdgene)[1] <- 'geneid'
  xgene <- data.frame(geneid=rownames(xgene),xgene); rownames(xgene) <- NULL

  fdata <- by(exprsx[,(signalCols+1):allcols],geneid,unique)

  genenames <- names(fdata)
  fdata <- do.call('rbind',fdata)

  fdata <- new("AnnotatedDataFrame", data.frame(fdata))
  rownames(fdata) <- as.character(xgene$geneid)

  exprsxgene <- as.matrix(xgene[,-1])
  rownames(exprsxgene) <- as.character(xgene$geneid);
  colnames(exprsxgene) <- sample_names
  eset <- new("ExpressionSet",exprs=exprsxgene, featureData=fdata, phenoData=pdata)
  return(list(eset=eset,sdgene=sdgene,fdata=fdata,geneid=geneid))
}

geneid <- probe_df$Gene_id
geneid <- as.character(geneid)
genesToRename.sd <- NA

tmp <- renameGenesAndSummarize(genesToRename.sd=genesToRename.sd,exprsx=probe_df,geneid=geneid,summaryMethod=myRma, type="ratio")
xgene <- tmp[['eset']]; sdgene <- tmp[['sdgene']]; fdata <- tmp[['fdata']]; geneid <- tmp[['geneid']]

tmp2 <- renameGenesAndSummarize(genesToRename.sd=genesToRename.sd,exprsx=probe_df,geneid=geneid,summaryMethod=myRma, type="red")
xgene_red <- tmp2[['eset']]; sdgene <- tmp2[['sdgene']]; fdata <- tmp2[['fdata']]; geneid <- tmp2[['geneid']]
#+end_src
*** Estimate Times
#+begin_src R
#### Estimate times ####

print("Estimating times...")
bozdechPath <- paste0(infiles, 'bozdech_Hb3_clean2.csv')
LemieuxFunctionsPath <- paste0(infiles, 'lemieux_et_al_pipeline_functions.r')

getTimeEstimation <- function(x,dataPath,functionsPath,figuresPath,B=100) {
                                        #  x: the expressionSet for which we want to estimate times (our data).
                                        #  dataPath: path to data that will be used to estimate timepoints (from Bozdech et al)
                                        #  functionsPath: path to the script containing the functions from Lemieux's paper.
                                        #  figuresPath: where we want to save the output plots.
  source(functionsPath)
                                        #  z <- read.csv(dataPath, as.is = T,sep='\t')
  z <- read.csv(dataPath, as.is = T)
                                        #  colnames(z)[1] <- 'Name'
                                        #  oldTime <- as.numeric(as.character(pData(x)$time))
  oldTime <- as.numeric(teor_time)
  x <- exprs(x)
  x <- data.frame(Name=as.character(rownames(x)),x,stringsAsFactors=FALSE); rownames(x) <- NULL
  data <- sync_data(x, z)
  x <- data[[1]]
  z <- data[[2]]
  x <- ordinal(x, use.name = T)
  z <- ordinal(z, use.name = T)
                                        #  z.na <- cbind(z[,1:22], rep(NA, nrow(z)), z[,23:27], rep(NA, nrow(z)), z[,28:56])
  z.na <- cbind(z[,1:22], rep(NA, nrow(z)), z[,23:27], rep(NA, nrow(z)), z[,28:46])
  z <- t(apply(z.na, 1, smooth.missing))
  sigma.epsilon <- 789.9056
  z.smooth <- smooth.ref(z, method = "spline", spar = 0.5)
  z.smooth.hourly <- z.smooth[,ll.par$hourly]
                                        #  sigma.eta <- mean(sd(z[,11:ncol(z)] - z.smooth.hourly, na.rm = T), na.rm=T)
  sigma.eta <- mean(sd(z - z.smooth.hourly, na.rm = T), na.rm=T)
  new.sigma <- sqrt(sigma.eta^2 + sigma.epsilon^2)
  ll <- compute.ll(x = x, z = z.smooth, sigma = new.sigma, bootstrap = T, B = B, sample.rate = 0.50)
  myTimes <- mle(ll)
  png(file.path(figuresPath,'/Time_estim/defaultPlots1.png'))
  plot.ll(ll)
  dev.off()
  png(file.path(figuresPath,'/Time_estim/defaultPlots2.png'))
  plot.mle(ll)
  dev.off()
  png(file.path(figuresPath,'/Time_estim/ownPlots1.png'))
  plot(density(myTimes),main='Estimated times density')
  dev.off()
  png(file.path(figuresPath,'/Time_estim/ownPlots2.png'))
  plot(oldTime, as.numeric(myTimes),xlab='Old times',ylab='Estimated times',xlim=c(-5,50),ylim=c(-5,50))
  abline(0,1,col=2,lwd=2)
  abline(v=oldTime,lwd=0.5,lty=3)
  dev.off()
  return(myTimes)
}

ascendingTime <- function(x){
  current <- 0
  ncycle <- 0
  for (i in 1:length(x)){
    val  <- x[i]+(48*ncycle)
    if (val < current){
      current <- val
      val <- val+48
      ncycle <- ncycle+1
    }
    current <- val
    x[i] <- val
  }
  return(x)
}


estimatedTimes <- getTimeEstimation(xgene,bozdechPath,LemieuxFunctionsPath,file.path(figPath),B=100)
estimatedTimes[estimatedTimes < 0] <- 0
hpi <- estimatedTimes

for (type in pData(xgene)$type){
  sel <- pData(xgene)$type == type
  typetime <- estimatedTimes[sel]
  time <- ascendingTime(typetime)
  estimatedTimes[sel] <- time
}

write.csv(estimatedTimes, paste0(outdir, "/Estimated_Times.csv"))
pData(xgene)$time <- estimatedTimes
pData(xgene_red)$time <- estimatedTimes
pData(xgene)$hpi <- hpi
pData(xgene_red)$hpi <- hpi

                                        # Save ExpressionSet at gene level
save(xgene,file=paste0(outdir, '/geneLevel.RData'))
save(xgene_red,file=paste0(outdir, '/geneLevel_redSignal.RData'))

                                        # Boxplot after summarization
pdf(file.path(figPath,'boxplot_afterSummarization.pdf'))
boxplot(exprs(xgene),main='summarization method: median poslish')
dev.off()
#+end_src
*** Save results in CSVs
#+begin_src R
#### Save results in CSVs ####

write.csv(xgene@phenoData@data, file = paste0(outdir, "/experiment_data.csv"))
write.csv(cbind(xgene@featureData@data, exprs(xgene)), paste0(outdir, "/geneLevel_exp.csv"), row.names=F)
write.csv(cbind(xgene_red@featureData@data, exprs(xgene_red)), paste0(outdir, "/geneLevel_redSignal_exp.csv"), row.names=F)
#+end_src
*** FC: Probe Level
#+begin_src R
#### FC: Probe Level ####

print("Calculating Fold-Changes...")
filter <- function(x,y) {x==y}
combs <- cross2(sample_names, sample_names, .filter = filter)

fc <- list()
for (i in combs) {
  fc[[paste0(i[[1]], "_",  i[[2]])]] <- exprs(xprobe)[,i[[1]]] - exprs(xprobe)[,i[[2]]]
}

probe_fc <- as.data.frame(fc)
probe_fc <- cbind(fData(xprobe), probe_fc)

write.csv(probe_fc, file = paste0(outdir, "/proveLevel_FC.csv"), row.names = F)
#+end_src
*** FC: Gene Level
#+begin_src R
#### FC: Gene Level ####

filter <- function(x,y) {x==y}
combs <- cross2(sample_names, sample_names, .filter = filter)

fc <- list()
for (i in combs) {
  fc[[paste0(i[[1]], "_",  i[[2]])]] <- exprs(xgene)[,i[[1]]] - exprs(xgene)[,i[[2]]]
}

gene_fc <- as.data.frame(fc)
gene_fc <- cbind(fData(xgene), gene_fc)

write.csv(gene_fc, file = paste0(outdir, "/geneLevel_FC.csv"), row.names = F)
#+end_src
*** Areas: Functions
#+begin_src R
#### Areas: Functions ####

imputePoint <- function(xs, ys, tp){

  ## "xs" and "ys" must be two vectors of equal length
  ## with the corresponding y(expression) and x(timepoint)
  ## values that form the expression plot of interest (one gene).
  ## "tp" must be the timepoint to impute.
  ## If the timepoint to be imputed is already present, leave it as is.
  ## Returns NA if missing the previous or next tp

  if (tp %in% xs){

    idx <- which(xs == tp)
    imputed <- list(x=xs[idx], y=ys[idx])

  } else {

    before <- which(xs == max(xs[xs < tp]))
    after <- which(xs == min(xs[xs > tp]))

    if (is.na(ys[before]) | is.na(ys[after])){

      imputed <- list(x=tp, y=NA)

    } else {

      x <- c(xs[c(before, after)])
      y <- c(ys[c(before, after)])

      imputed <- approx(x, y, xout=tp)
    }
  }
  return(imputed)
}

computeArea <- function(eset){

  ## Takes an eset and computes areas.
  ## pData(eset) must contain a field named "time" with the time-points.
  ## pData(eset) must have a field named "type" with the grouping variable.

  ## Set needed variables
  types <- unique(phenoData(eset)$type)
  type <- phenoData(eset)$type
  times <- phenoData(eset)$time

  maxminTP <- max(sapply(types,function(x) min(times[type==x])))
  minmaxTP <- min(sapply(types,function(x) max(times[type==x])))
  mybreaks <- seq(maxminTP, minmaxTP, length.out=5)
  tp1 <- mybreaks[2]
  tp2 <- mybreaks[3]
  tp3 <- mybreaks[4]

  xsList <- c()
  for (type in types){
    xsList <- c(xsList, list(pData(eset)$time[phenoData(eset)$type == type]))
  }

  ## Main loop
  all_areas <- c()
  for (i in 1:dim(eset)[1]){

    gene <- fData(eset)$geneID[i]

    ysList <- c()
    for (type in types){
      ysList <- c(ysList, list(exprs(eset)[i, phenoData(eset)$type == type]))
    }

    ## Estimate points where needed
    dfs <- list()
    for (i in 1:length(xsList)){

      x <- unlist(xsList[[i]])
      y <- unlist(ysList[[i]])

      points <- as.data.frame(cbind(x, y))
      midpoints <- points[points$x > maxminTP &
                          points$x < minmaxTP, ]

      first <- imputePoint(x, y, maxminTP)
      last <- imputePoint(x, y, minmaxTP)
      p1 <- imputePoint(x, y, tp1)
      p2 <- imputePoint(x, y, tp2)
      p3 <- imputePoint(x, y, tp3)

      impPoints <- rbind(first, last, p1, p2, p3)
      allpoints <- rbind(midpoints, impPoints)
      allpoints$x <- as.numeric(allpoints$x)
      allpoints$y <- as.numeric(allpoints$y)

      ordered <- arrange(allpoints, allpoints$x)

      dfs[[i]] <- ordered
    }

    ## Calculate minY on estimated DFs
    minY <- min(sapply(dfs, function(df) min(df$y, na.rm = T)))

    rowareas <- c()
    for (df in dfs){

      df$y <- df$y - minY

      ## Whole polygon from expression data
      polDF <- rbind(df,
                     c(minmaxTP, 0),
                     c(maxminTP, 0),
                     c(df[1,]))

      ## Create Polygons
      leftHalf <- rbind(df[which(df$x <= tp2),],
                        c(tp2, 0),
                        c(maxminTP, 0),
                        c(df[1,]))

      rightHalf <- rbind(df[which(df$x >= tp2),],
                         c(minmaxTP, 0),
                         c(tp2, 0),
                         c(df[df$x == tp2,]))

      mid <- rbind(df[which(df$x >= tp1 & df$x <= tp3),],
                   c(tp3, 0),
                   c(tp1, 0),
                   c(df[df$x == tp1,]))

      sides <- rbind(df[which(df$x <= tp1),],
                     c(tp1, 0),
                     c(tp3, 0),
                     df[which(df$x >= tp3),],
                     c(minmaxTP, 0),
                     c(maxminTP, 0),
                     df[1,])

      pols <- list(leftHalf, rightHalf, mid, sides)

      calcArea <- function(x) {ifelse(any(is.na(x)), NA, Polygon(x)@area)}
      areas <- unlist(lapply(pols, function(x) calcArea(x)))

      rowareas <- c(rowareas, areas)

      ## Plot polygons (for debugging purposes)
      ##pol <- Polygon(polDF)
      ##ps = Polygons(list(pol),1)
      ##sps = SpatialPolygons(list(ps))
      ##plot(sps)
    }
    all_areas <- c(all_areas, list(rowareas))
  }

  ## Set row and col names for output
  areaDF <- do.call(rbind, all_areas)
  titles <- c("Left", "Right", "Middle", "Sides")

  cols <- c()
  for (i in types){
    for (t in titles){
      name <- paste0(i, "_", t)
      cols <- c(cols, name)
    }
  }
  colnames(areaDF)  <- cols
  rownames(areaDF) <- rownames(exprs(eset))
  return(areaDF)
}
#+end_src
*** Areas: Calls
#+begin_src R
#### Calls: Compute Areas ####

print("Computing Areas...")
areasDF <- computeArea(xgene)
xout <- cbind(fData(xgene), areasDF)

write.csv(xout, paste0(outdir, "/area_geneLevel.csv"), row.names=F)
#+end_src
*** Compute aAFC (average Area Fold Change)
#+begin_src R
#### Calculate aAFC (average Area Fold-Change) ####

myMax <- function(x){
  y <- abs(x)
  if (all(is.na(y))){
    return(list(NA, NA))
  } else {
    pos <- which.max(y)
    times <- c("Left", "Right", "Mid", "Sides")
    return(list(maxVal = x[pos],
                maxTime = times[pos]))
  }
}

## Get number of categories.
n <- length(levels(pData(xgene)$type))

ns <- list()
i <- 1
while (i < n+1){
  ns[[i]] <- 1:4+(4*(i-1))
  i <- i+1
}

## Convert de areasDF into a list of DFs separated by types.
areas <- list()
for (i in 1:length(ns)) {
  areas[[i]] <- areasDF[,ns[[i]]]
}


## Calculate area differences

types <- unique(phenoData(xgene)$type)
type <- phenoData(xgene)$type
times <- phenoData(xgene)$time

maxminTP <- max(sapply(types,function(x) min(times[type==x])))
minmaxTP <- min(sapply(types,function(x) max(times[type==x])))
mybreaks <- seq(maxminTP, minmaxTP, length.out=5)

sets <- 1:length(areas)
combs <- combn(sets, 2)
span <- mybreaks[3] - mybreaks[1]
titles <- c("Left", "Right", "Middle", "Sides")


areaDifs <- list()
for (i in 1:dim(combs)[2]){

  one <- combs[1,i]
  two <- combs[2,i]

  dif1 <- as.data.frame((areas[[one]] - areas[[two]])/span)
  names  <- paste0(colnames(areas[[one]]),
                   "_minus_",
                   colnames(areas[[two]]))

  prefix <- paste0(strsplit(colnames(areas[[one]])[1], "_")[[1]][1],
                   "-",
                   strsplit(colnames(areas[[two]])[1], "_")[[1]][1])
  names <- sapply(titles, function(x) paste(prefix, x, sep = "_"))

  colnames(dif1) <- names

  maxval <- apply(dif1, 1, function(x) myMax(x)[[1]])
  maxtime <- apply(dif1, 1, function(x) myMax(x)[[2]])

  mv <- paste0(prefix, "_MaxVal")
  mt <- paste0(prefix, "_MaxTime")

  dif1[mv] <- maxval
  dif1[mt] <- maxtime

                                        #dif2 <- -dif1

  ## prefix <- paste0(strsplit(colnames(areas[[two]])[1], "_")[[1]][1],
  ##                  "-",
  ##                  strsplit(colnames(areas[[one]])[1], "_")[[1]][1])
  ## names <- sapply(titles, function(x) paste(prefix, x, sep = "_"))

  ## colnames(dif2) <- names

  areaDifs <- c(areaDifs, list(dif1))#, list(dif2))
}

allDifs <- do.call(cbind, areaDifs)
head(allDifs)
#+end_src
*** Convert Partitions into Life-stages
#+begin_src R
#### Areas: Convert Partitions into life stages ####

timetostage <- function(tp){
  while(tp > 48){
    tp = tp-48
  }
  return(tp)
}

getStage <- function(tp) {
  if ((tp >= 0) & (tp < 26)) {stg = "ring"}
  else if ((tp >= 26) & (tp < 38)) {stg = "troph"}
  else if ((tp >= 38) & (tp <= 48)) {stg = "schizont"}
  return(stg)
}

fracToStage <- function(frac, tps){
  if (is.na(frac)){
    return(NA)
  } else if (frac == "Left"){
    tp = tps[2]
    getStage(tp)
  } else if (frac == "Right"){
    tp = tps[4]
    getStage(tp)
  } else if (frac == "Mid"){
    tp = tps[3]
    getStage(tp)
  } else if (frac == "Sides"){
    tp1 = tps[1]+(span/4)
    tp2 = tps[4]+(span/4)
    stg1 <- getStage(tp1)
    stg2 <- getStage(tp2)
    return(paste0(stg1,"-",stg2))
  }
}


ncombs <- dim(combs)[2]

maxValCols <- seq(5, ncombs*6, 6)
maxTimeCols <- seq(6, ncombs*6, 6)

aMAFC <- cbind(allDifs[,c(maxValCols, maxTimeCols)])

timeCols <- (ncombs+1):(ncombs*2)

tps <- sapply(mybreaks, function(x) timetostage(x))

for (i in timeCols){
  aMAFC[,i] <- sapply(aMAFC[,i], function(x) fracToStage(x, tps))
}

write.csv(allDifs, paste0(outdir, "/areaDiferences_geneLevel.csv"))
write.csv(aMAFC, paste0(outdir, "/aMAFC_geneLevel.csv"))
#+end_src
*** Create Max diferences table
#+begin_src R
#### Create Max differences table ####

library(dplyr)

anot_table <- annot %>%
  select(V2, V4, V5) %>%
  rename(Gene_id=V2, Name=V4, Annot=V5) %>%
    dplyr::filter(!is.na(Gene_id)) %>%
  distinct()

head(anot_table)
head(allDifs)

max_df <- allDifs %>%
  mutate(Gene_id = rownames(allDifs)) %>%
  left_join(anot_table, by='Gene_id') %>%
  mutate(MaxMax = pmax(abs(`A7-B11_MaxVal`), abs(`A7-E5_MaxVal`), abs(`B11-E5_MaxVal`))) %>%
  arrange(desc(abs(MaxMax))) %>%
  select(Gene_id, Name, Annot, contains('MaxVal'), contains('MaxTime'), contains('-'))

max_df_top <- max_df %>% dplyr::filter(abs(`A7-B11_MaxVal`) > 4 | abs(`A7-E5_MaxVal`) > 4 | abs(`B11-E5_MaxVal`) > 4)

write.csv(max_df, paste0(outdir, "/all_aMAFC.csv"))
write.csv(max_df_top, paste0(outdir, "/top_aMAFC.csv"))
#+end_src
*** PCA Plots
#+begin_src R
#### PCA Plots ####

print("Plotting PCA..")
noNA <- xgene[complete.cases(exprs(xgene))]
df <- t(exprs(noNA))
df <- as.data.frame(df)

pca <- prcomp(df)
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
df_pca$Type <- noNA@phenoData@data$type
df_pca$Time <- noNA@phenoData@data$time

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Type, group = Type))
p <- p + geom_point(aes(size= Time))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))

ggsave(p, filename = paste0(figPath, "PCA.png"), device = "png", dpi = "retina")

p <- p + theme_classic()
p <- p + theme(text = element_text(size=20))
p

ggsave(p, filename = paste0(figPath, "PCA.svg"), device = "svg")
#+end_src
*** Expression Plots
#+begin_src R
#### Expression Plots ####

print("Plotting Expression Plots...")
expressionPlot <- function(type){

  ## Set df and lims depending on what we are plotting.
  if (type == "gene"){
    df = xgene
    path = "/Ratio/Gene_Level/"

  } else if (type == "gene_red"){
    df = xgene_red
    path = "/Red_Signal/Gene_Level/"

  } else if (type == "probe"){
    df = xprobe
    path = "/Ratio/Probe_Level/"

  } else if (type == "probe_red"){
    df = xprobe_red
    path = "/Red_Signal/Probe_Level/"

  }

  ## Set ylims
  ylim = c(min(exprs(df), na.rm = T), max(exprs(df), na.rm = T))

  ## Set number of plots
  if (run_all_plots == "yes"){
    nplots = dim(df)[1]
  } else {
    nplots = 20
  }

  ## Main Loop
  for (i in 1:nplots){

    ## Set gene for title or gene and probe for probe-level plots.
    gn <- gsub("[/:;.]", "_", fData(df)$Gene_id[i])
    if (type %in% c("probe", "probe_red")){
      prb <- paste0("_", gsub("[/:;.]", "_" , fData(xprobe)$ProbeName[i]))
    } else {
      prb <- ""
    }
    title <- paste0(gn, prb)

    ## Set y-axis title depending on ratio/red_signal
    ytitle <- ifelse(type %in% c("gene_red", "probe_red"), 'log2(Cy5)', 'log2(Cy3/Cy5)')

    ## Plot
    graf <- melt(df[i,])
    graf["Type"] <- xgene@phenoData@data$type
    graf["Time"] <- xgene@phenoData@data$time
    p <- ggplot(graf, aes(x = Time, y = value, col = Type, group = Type))
    p <- p + geom_point(aes(color = Type, shape = Type)) + geom_line()
    p <- p + coord_cartesian(ylim = ylim)
    p <- p + ggtitle(title)
    p <- p + ylab(ytitle)
    ggsave(p, file=paste0(figPath, path, gn, prb, ".jpeg"),
           device = "jpeg", width = 14, height = 10, units = "cm")

  }

}

expressionPlot("gene")
expressionPlot("gene_red")
expressionPlot("probe")
expressionPlot("probe_red")
#+end_src
*** Single Gene Plot
#+begin_src R
#### Single Gene Plot ####

plot_gene <- function(type, gid, out){
  ## Set df and lims depending on what we are plotting.
  if (type == "gene"){
    df = xgene
    path = "/Ratio/Gene_Level/"

  } else if (type == "gene_red"){
    df = xgene_red
    path = "/Red_Signal/Gene_Level/"

  } else if (type == "probe"){
    df = xprobe
    path = "/Ratio/Probe_Level/"

  } else if (type == "probe_red"){
    df = xprobe_red
    path = "/Red_Signal/Probe_Level/"

  }

  ## Set ylims
  ylim = c(min(exprs(df), na.rm = T), max(exprs(df), na.rm = T))


  ## Plot
  ## Set gene for title or gene and probe for probe-level plots.
  gn <- gsub("[/:;.]", "_", gid)
  if (type %in% c("probe", "probe_red")){
    prb <- paste0("_", gsub("[/:;.]", "_" , gid))
  } else {
    prb <- ""
  }
  title <- paste0(gn, prb)

  ## Set y-axis title depending on ratio/red_signal
  ytitle <- ifelse(type %in% c("gene_red", "probe_red"), 'log2(Cy5)', 'log2(Cy3/Cy5)')

  ## Plot
  graf <- melt(df[fData(df)$Gene_id == gid,])
  graf["Type"] <- xgene@phenoData@data$type
  graf["Time"] <- xgene@phenoData@data$time
  p <- ggplot(graf, aes(x = Time, y = value, col = Type, group = Type))
  p <- p + geom_point(aes(color = Type, size = 2))
  p <- p + geom_line(aes(size = 2))
  p <- p + coord_cartesian(ylim = ylim)
  p <- p + theme_classic()
  # p <- p + ggtitle(title)
  # p <- p + ylab(ytitle)
  p <- p + theme(text = element_text(size = 36))
  p <- p + theme(axis.title.x = element_blank())
  p <- p + theme(axis.title.y = element_blank())
  p <- p + theme(legend.position = 'none')
  ggsave(p, file=out, device = "svg")
  print(p)
}

type <- 'gene'
gid <- 'PF3D7_0302200'
outpath <- '/home/lucas/Documents/BioMalPar_2021/Microarrays/Gene_plots/'
outname <- 'PF3D7_0302200_12b10g.svg'

plot_gene(type, gid, paste0(outpath, outname))

#+end_src
*** Add Gametocyte genes info
#+begin_src R
#### Add gametocyte genes info ####
library(readxl)
gene_lists <- read_excel('../All gene lists_160719.xlsx', sheet = 2)

gam_genes <- gene_lists %>%
  select(`Lopez-Barragan`, Lasonder, Gametocites_Young, contains('gam'))

gam_list <- unique(gam_genes %>% pull())
gam_list[gam_list == 'NA'] <- NA
gam_list <- gam_list[!is.na(gam_list)]

finalDF <- max_df %>%
  select(Gene_id, Name, Annot, contains('MaxVal'), contains('MaxTime'))

finalDF['GamGene'] <- finalDF$Gene_id %in% gam_list

write.csv(finalDF, paste0(outdir, "/final_summary_table.csv"), row.names = F)
#+end_src
*** VAR genes plot
#+begin_src R
#### Var genes plot ####
gene_fam <- read_excel('/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/cvgfamilylist/Supplementary_table_2_CVG_list_161120_ap.xlsx', sheet = 2)
gene_fam <- gene_fam %>%
  rename(Gene_id = `Gene ID`,
         Gene_name = `Gene Name or Symbol`,
         SubFamily = `Family Detail`) %>%
  # mutate(SubFamily = case_when(SubFamily == 'var pseudo,truncated or -like.' ~ 'var-like',
  #                              TRUE ~ SubFamily)) %>%
  select(Gene_id, Gene_name, Family, SubFamily)

red_df <- as.data.frame(exprs(xgene_red))
red_df <- 2**(red_df)
red_df <- red_df %>%
  mutate(Gene_id = rownames(red_df)) %>%
  left_join(gene_fam, by='Gene_id')

varPlot <- function(strain){

  vals <- red_df %>% select(contains('tp') & contains(strain))
  max_tps <- colnames(vals)[apply(vals,1,which.max)]
  max_tps <- gsub(paste0(strain, '_'), '', max_tps)

  plot_df <- red_df %>%
    mutate(Max = select(., contains(strain)) %>% do.call(pmax, .)) %>%
    mutate(MaxTime = max_tps) %>%
    select(Gene_id, Max, MaxTime, Family, SubFamily) %>%
    dplyr::filter(Family == 'VAR' & SubFamily != 'var pseudo,truncated or -like.')

  write_csv(plot_df, paste0(outdir, 'max_VAR_redsignal_', strain, '.csv'))

  vars_plot <- ggplot(plot_df, aes(x = Gene_id, y = Max)) +
    geom_bar(stat = 'identity') +
    ggtitle(paste0('VAR gene expression ', strain)) +
    ylab(paste0('Normalized Cy5 signal')) +
    theme_classic() +
    theme(axis.text.x=element_text(angle = -90, hjust = 0)) +
    coord_cartesian(ylim = c(0,60000))

  #print(vars_plot)

  ggsave(paste0(figPath, strain, '_var_genes_red.pdf'), vars_plot, device = 'pdf')

  ## Tp 10 Plot
  plot10tp_df <- red_df %>%
    select(Gene_id, contains(strain) & contains('tp10'), Family, SubFamily) %>%
    set_names(c('Gene_id', 'RedSignal', 'Family', 'SubFamily')) %>%
    dplyr::filter(Family == 'VAR' & SubFamily != 'var pseudo,truncated or -like.')

  write_csv(plot10tp_df, paste0(outdir, 'max_VAR_redsignal_tp10_', strain, '.csv'))


  vars10tp_plot <- ggplot(plot10tp_df, aes(x = Gene_id, y = RedSignal)) +
    geom_bar(stat = 'identity') +
    ggtitle(paste0('VAR gene expression ', strain)) +
    ylab(paste0('Normalized Cy5 signal')) +
    theme_classic() +
    theme(axis.text.x=element_text(angle = -90, hjust = 0)) +
    coord_cartesian(ylim = c(0,60000))

  #print(vars10tp_plot)
  ggsave(paste0(figPath, strain, '_var_genes_red_tp10.pdf'), vars10tp_plot, device = 'pdf')
}

strains <- c('A7', 'E5', 'B11')
for (strain in strains) {varPlot(strain)}


vars_plot
#+end_src
*** Red Filter
#+begin_src R
xgene_red_tibble <- as.data.frame(exprs(xgene_red)) %>%
  tibble() %>%
  mutate(Gene_id = rownames(exprs(xgene_red))) %>%
  select(Gene_id, everything())

## By max col -> then percentile (old)
## get_red_percent <- function(strain){

##   ## Subset to strain
##   red_strain <- xgene_red_tibble %>%
##     select(Gene_id, contains(strain))

##   ## Calculate Max col
##   maxred <- red_strain %>%
##     dplyr::select(-Gene_id) %>%
##     mutate(Max_Red = do.call(pmax, (.))) %>%
##     select(Max_Red)

##   ## Create "percentile" function from Max col
##   percentile <- ecdf(maxred$Max_Red)
##   red_pcnt <- percentile(maxred$Max_Red)

##   return(red_pcnt)
## }

## perc_A7 <- get_red_percent('A7')
## perc_E5 <- get_red_percent('E5')
## perc_B11 <- get_red_percent('B11')

## red_percent <- tibble('Gene_id' = xgene_red_tibble$Gene_id,
##                       'A7' = perc_A7,
##                       'E5' = perc_E5,
##                       'B11' = perc_B11)


## First percentile per col -> max percentile (NEW)

my_percentile <- function(vector){
  ecdf(vector)(vector)*100
}

xgene_red_tibble <- xgene_red_tibble %>%
  mutate(across(.cols = -Gene_id, .fns = my_percentile, .names = "Perc_{.col}"))

get_max_percent <- function(strain){

  ## Subset to strain
  red_strain <- xgene_red_tibble %>%
    select(Gene_id, contains('Perc') & contains(strain))

  ## Calculate Max col
  maxperc <- red_strain %>%
    dplyr::select(-Gene_id) %>%
    mutate(Max_Perc = do.call(pmax, c(., na.rm = T))) %>%
    select(Max_Perc) %>%
    pull()
  return(maxperc)
}

perc_A7 <- get_max_percent('A7')
perc_E5 <- get_max_percent('E5')
perc_B11 <- get_max_percent('B11')

red_percent <- tibble('Gene_id' = xgene_red_tibble$Gene_id,
                      'A7' = perc_A7,
                      'E5' = perc_E5,
                      'B11' = perc_B11)


#hist(red_percent$A7)
write_csv(red_percent, paste0(outdir, "/red_percentiles.csv"))

names(red_percent)[2:4] <- paste0('Red_Pcnt_', names(red_percent)[2:4])

max_tibble <- as_tibble(max_df)
max_tibble <- max_tibble %>%
  left_join(red_percent, by='Gene_id', suffix = c('', '_Pcnt'))

maxFC_pass_red <- max_tibble %>%
  dplyr::filter((`A7-B11_MaxVal` >= 2 & Red_Pcnt_A7 > 15) |
         (`A7-B11_MaxVal` <= -2 & Red_Pcnt_B11 > 15) |
         (`A7-E5_MaxVal` >= 2 & Red_Pcnt_A7 > 15) |
         (`A7-E5_MaxVal` <= -2 & Red_Pcnt_E5 > 15) |
         (`B11-E5_MaxVal` >= 2 & Red_Pcnt_B11 > 15) |
         (`B11-E5_MaxVal` <= -2 & Red_Pcnt_E5 > 15))
#+end_src
*** Get Max-Time for each gene
#+begin_src R
#### Get MaxTime for each gene ####

myWhichMax <- function(vect){
  if (all(is.na(vect))){
    return(NA)
  } else {
    return(which.max(vect))
  }
}

exp <- as.data.frame(exprs(xgene))

maxcol <- exp %>%
  apply(1, myWhichMax) %>%
  unlist()

times <- pData(xgene) %>%
  select(time) %>%
  pull()

maxtime <- sapply(maxcol, function(x) times[x])

max_time <- tibble(Gene_id = names(maxtime), Max_Time = maxtime)
breaks_df <- tibble(Areas_Breaks = mybreaks)

tibble(Gene_id = names(maxtime), Max_Time = maxtime) %>%
  write_csv(paste0(outdir, 'new_arrays_maxtime.csv'))

tibble(Areas_Breaks = mybreaks) %>%
  write_csv(paste0(outdir, 'new_area_breaks.csv'))

## xgene_tibble <- as.data.frame(exprs(xgene)) %>%
##   tibble() %>%
##   mutate(Gene_id = rownames(exprs(xgene)))

## xgene_tibble %>%
##   select(contains('12B'))

## trans_df['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))
#+end_src
*** Filter Genes by Timepoint
#+begin_src R
## #### Filter by Max-Time ####

## New approach
## Check which areas does maxtimepoint overlapp -> check if aAFC > th at this areas

point_overlap <- function(point, interval){
  point >= interval[1] & point <= interval[2]
}

areas_df <- as_tibble(allDifs) %>%
  mutate(Gene_id = rownames(allDifs)) %>%
  select(Gene_id, everything())

maxtimes_A7_B11 <- c()
maxtimes_A7_E5 <- c()
maxtimes_B11_E5 <- c()
gids <- c()
th <- 2
for (gid in max_tibble$Gene_id){

  ## Create time-regions
  breaks <- breaks_df$Areas_Breaks
  left <- c(breaks[1], breaks[3])
  right <- c(breaks[3], breaks[5])
  mid <- c(breaks[2], breaks[4])
  sides_l <- c(breaks[1], breaks[2])
  sides_r <- c(breaks[4], breaks[5])

  ## Get maxtime
  maxtime <- max_time %>%
    dplyr::filter(Gene_id == gid) %>%
    pull()
  if (is.na(maxtime)){
    maxtimes_A7_B11 <- c(maxtimes_A7_B11, NA)
    maxtimes_A7_E5 <- c(maxtimes_A7_E5, NA)
    maxtimes_B11_E5 <- c(maxtimes_B11_E5, NA)
    gids <- c(gids, gid)
  } else {
    ## Ensure maxtime is in the areas intervals
    if (maxtime < breaks[1]) {maxtime <- breaks[1]}
    if (maxtime > breaks[5]) {maxtime <- breaks[5]}

    ## Get overlappped areas
    areas <- list('left' = left, 'right' = right, 'mid' = mid,
                  'sides' = sides_l, 'sides' = sides_r)
    overlaps <- sapply(areas, function(x) point_overlap(maxtime, x))

    ## Get aAFC in overlapping areas by comparison
    aFCs <- areas_df %>%
      dplyr::filter(Gene_id == gid) %>%
      select(contains(names(areas[overlaps])))

    fc_A7_B11 <- aFCs %>%
      select(contains('A7-B11')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_A7_B11 <- any(abs(fc_A7_B11) > th)

    fc_A7_E5 <- aFCs %>%
      select(contains('A7-E5')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_A7_E5 <- any(abs(fc_A7_E5) > th)

    fc_B11_E5 <- aFCs %>%
      select(contains('B11-E5')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_B11_E5 <- any(abs(fc_B11_E5) > th)

    maxtimes_A7_B11 <- c(maxtimes_A7_B11, maxtime_FC_A7_B11)
    maxtimes_A7_E5 <- c(maxtimes_A7_E5, maxtime_FC_A7_E5)
    maxtimes_B11_E5 <- c(maxtimes_B11_E5, maxtime_FC_B11_E5)
    gids <- c(gids, gid)
  }
}
maxtime_aAFC_df <- tibble(
  Gene_id = gids,
  MaxTime_Filter_A7_B11 = maxtimes_A7_B11,
  MaxTime_Filter_A7_E5 = maxtimes_A7_E5,
  MaxTime_Filter_B11_E5 = maxtimes_B11_E5
  )

max_tibble <- max_tibble %>%
  left_join(maxtime_aAFC_df)


#+end_src
*** Filter genes by Deletions/Duplications
#+begin_src R
f_path <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/Duplication_Deletion_Regions_Mean_Separate_DuplDel/Crossed_with_genes/'

file_list <- c(  'A7K9_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered_genes.tsv',
  'E5K9_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered_genes.tsv',
  'B11_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered_genes.tsv'
)

dupl_dl_A7 <- read_tsv(paste0(f_path, file_list[1]), col_names = F) %>%
  select(X1) %>% pull()

dupl_dl_E5 <- read_tsv(paste0(f_path, file_list[2]), col_names = F) %>%
  select(X1) %>% pull()

dupl_dl_B11 <- read_tsv(paste0(f_path, file_list[3]), col_names = F) %>%
  select(X1) %>% pull()

#+end_src
*** Get Final List of Genes
#+begin_src R
## Load Latest Annot
info_df <- read_csv(paste0(infiles, 'info_df.csv')) %>%
  dplyr::filter(!is.na(Gene_id))

final_df <- max_tibble %>%
  mutate(Gene_id = ifelse(Gene_id == 'PF3D7_0935400_as', 'PF3D7_0935390', Gene_id)) %>%
  mutate(Not_Plasmodium = !Gene_id %in% info_df$Gene_id)

final_df <- final_df %>%
  select(-Name, -Annot) %>%
  left_join(info_df, by='Gene_id')

## Set thresholds
red_th <- 15

## A7 vs B11

final_df %>%
  select(
    Gene_id,
    `A7-B11_MaxVal`,
    `A7-B11_MaxTime`,
    Red_Pcnt_A7,
    Red_Pcnt_B11,
    MaxTime_Filter_A7_B11
  ) %>%
  mutate(PassRed = ifelse(
           `A7-B11_MaxVal` >= 0,
           Red_Pcnt_A7 >= red_th,
           Red_Pcnt_B11 >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_A7_B11) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_A7 & !Gene_id %in% dupl_dl_B11) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, 'A7_B11_final_df.tsv'))

## A7 vs E5

final_df %>%
  select(
    Gene_id,
    `A7-E5_MaxVal`,
    `A7-E5_MaxTime`,
    Red_Pcnt_A7,
    Red_Pcnt_E5,
    MaxTime_Filter_A7_E5
  ) %>%
  mutate(PassRed = ifelse(
           `A7-E5_MaxVal` >= 0,
           Red_Pcnt_A7 >= red_th,
           Red_Pcnt_E5 >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_A7_E5) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_A7 & !Gene_id %in% dupl_dl_E5) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, 'A7_E5_final_df.tsv'))

## B11 vs E5

final_df %>%
  select(
    Gene_id,
    `B11-E5_MaxVal`,
    `B11-E5_MaxTime`,
    Red_Pcnt_B11,
    Red_Pcnt_E5,
    MaxTime_Filter_B11_E5
  ) %>%
  mutate(PassRed = ifelse(
           `B11-E5_MaxVal` >= 0,
           Red_Pcnt_B11 >= red_th,
           Red_Pcnt_E5 >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_B11_E5) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_B11 & !Gene_id %in% dupl_dl_E5) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, 'B11_E5_final_df.tsv'))


###################################################


## A7 vs B11

difs_A7_B11 <- final_df %>%
  dplyr::filter(
  ((`A7-B11_MaxVal` >= 2 & Red_Pcnt_A7 > 15) |
   (`A7-B11_MaxVal` <= -2 & Red_Pcnt_B11 > 15)) &
  MaxTime_Filter_A7_B11
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_A7 | Gene_id %in% dupl_dl_B11) %>%
  dplyr::filter(!Not_Plasmodium & !Is_tRNA) %>%
  select(Gene_id, Name, Annot,
         `A7-B11_MaxVal`,
         Red_Pcnt_A7, Red_Pcnt_B11,
         MaxTime_Filter_A7_B11,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_A7_B11, paste0(outdir, 'A7_vs_B11_log2FC2_red15_maxtime.csv'))


## A7 vs E5

difs_A7_E5 <- final_df %>%
  dplyr::filter(
  ((`A7-E5_MaxVal` >= 2 & Red_Pcnt_A7 > 15) |
   (`A7-E5_MaxVal` <= -2 & Red_Pcnt_E5 > 15)) &
  MaxTime_Filter_A7_E5
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_A7 | Gene_id %in% dupl_dl_E5) %>%
  dplyr::filter(!Not_Plasmodium & !Is_tRNA) %>%
  select(Gene_id, Name, Annot,
         `A7-E5_MaxVal`,
         Red_Pcnt_A7, Red_Pcnt_E5,
         MaxTime_Filter_A7_E5,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_A7_E5, paste0(outdir, 'A7_vs_E5_log2FC2_red15_maxtime.csv'))


## B11 vs E5

difs_B11_E5 <- final_df %>%
  dplyr::filter(
  ((`B11-E5_MaxVal` >= 2 & Red_Pcnt_B11 > 15) |
   (`B11-E5_MaxVal` <= -2 & Red_Pcnt_E5 > 15)) &
  MaxTime_Filter_B11_E5
  ) %>%
  dplyr::filter(!Not_Plasmodium & !Is_tRNA) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_B11 | Gene_id %in% dupl_dl_E5) %>%
  select(Gene_id, Name, Annot,
         `B11-E5_MaxVal`,
         Red_Pcnt_B11, Red_Pcnt_E5,
         MaxTime_Filter_B11_E5,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_B11_E5, paste0(outdir, 'B11_vs_E5_log2FC2_red15_maxtime.csv'))

write_csv(final_df, paste0(outdir, 'new_arrays_final_df.csv'))
#+end_src
*** Make Venn Diagram
#+begin_src R
library(eulerr)

A <- difs_A7_E5$Gene_id
B <- difs_A7_B11$Gene_id
C <- difs_B11_E5$Gene_id

AB <- intersect(A, B)
AC <- intersect(A, C)
BC <- intersect(B, C)

ABC <- intersect(AB, C)

abc <- length(ABC)
ab <- length(AB[!AB %in% ABC])
ac <- length(AC[!AC %in% ABC])
bc <- length(BC[!BC %in% ABC])

a <- length(A) -ab -ac -abc
b <- length(B) -ab -bc -abc
c <- length(C) -ac -bc -abc

fit <- euler(c(A=a, B=b, C=c, "A&B"=ab, "A&C"=ac, "B&C"=bc, "A&B&C" = abc))

scales::viridis_pal()(3)

d <- plot(fit, fills = list(fill = c('#440154FF', "#21908CFF", "#FDE725FF"), alpha = 0.5),
          edges = list(lwd = 0.1),
          quantities = list(quantities = T),
          labels = list(labels=c("A7 vs E5", "A7 vs B11", "B11 vs E5"), fontsize = 7))

ggsave(d, filename = paste0(figPath, "Difs_Venn.pdf"), device = "pdf")

plot(d)
print(fit)
#+end_src
*** Make DF for GEO
#+begin_src R
array_list_tibble <- lapply(array_list, as.tibble)
raw_array <- array_list_tibble[[1]] %>%
  select(ProbeName, FeatureNum)

geo_df <- tibble(probe_df_geo)
geo_df['FeatureNum'] <- raw_array$FeatureNum
geo_df <- geo_df %>%
  mutate(Drop_Gene_id = !(Gene_id %in% final_df$Gene_id)) %>%
  mutate(Excluded_from_Analysis = Drop_Mulimapper | Drop_LowExpress | Drop_Gene_id) %>%
  select(
    ProbeName, FeatureNum, Gene_id,
    contains('Drop'), Excluded_from_Analysis,
    contains('Log')
  ) %>%
  write_tsv(paste0(outdir, 'geo_processed_data.tsv'))

#+end_src
*** Save/Load environtment
#+begin_src R
#### Save environtment ####
#save.image(file = "array_A7E5B11_work_space.RData")
##setwd('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/New_Arrays/')
##load('array_A7E5B11_work_space.RData')
head(final_df)
#+end_src
** Join Analysis
:PROPERTIES:
:header-args:R: :session join_analysis :tangle ./Paper_Analysis/Scripts/Microarrays/microarray_analysis_joinAnalysis.R :results none
:END:
*** WD and libraries
#+begin_src R
wd <- '/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/Join_Analysis/'
setwd(wd)

library(scales)
library(tidyverse)
library(eulerr)
library(readxl)
library(viridis)
library(ggdendro)
library(gridExtra)
library(Cairo)
#+end_src
*** Join Venns
#+begin_src R
## Load Old Dif Genes
old_fld <- '../Old_Arrays/R_results_OldArrays_Variantome/'
suffix <- '_log2FC2_red15_maxtime2.csv'

v12B_10G <- read_csv(paste0(old_fld, '12B_vs_10G', suffix)) %>%
         select(Gene_id) %>%
         pull()

v12B_3D7B <- read_csv(paste0(old_fld, '12B_vs_3D7B', suffix)) %>%
  select(Gene_id) %>%
  pull()

v10G_3D7B <- read_csv(paste0(old_fld, '10G_vs_3D7B', suffix)) %>%
  select(Gene_id) %>%
  pull()

old_gids <- unique(c(v12B_10G, v12B_3D7B, v10G_3D7B))


## Load New Dif Genes
new_fld <- '../New_Arrays/R_results_NewArray/'
suffix <- '_log2FC2_red15_maxtime2.csv'

vA7_B11 <- read_csv(paste0(new_fld, 'A7_vs_B11', suffix)) %>%
  select(Gene_id) %>%
  pull()

vA7_E5 <- read_csv(paste0(new_fld, 'A7_vs_E5', suffix)) %>%
  select(Gene_id) %>%
  pull()

vB11_E5 <- read_csv(paste0(new_fld, 'B11_vs_E5', suffix)) %>%
  select(Gene_id) %>%
  pull()

new_gids <- unique(c(vA7_B11, vA7_E5, vB11_E5))


## Plot
A <- old_gids
B <- new_gids
AB <- intersect(A, B)

ab <- length(AB)
a <- length(A[!A %in% AB])
b <- length(B[!B %in% AB])


fit <- euler(c(A=a, B=b, "A&B"=ab))

scales::viridis_pal()(2)

d <- plot(fit, fills = list(fill = c('#440154FF', "#FDE725FF"), alpha = 0.5),
          edges = list(lwd = 0.1),
          quantities = list(quantities = T),
          labels = list(labels=c("Old Arrays", "New Arrays")))

ggsave(d, filename = './join_Difs_Venn.pdf', device = "pdf")

plot(d)
print(fit)

#+end_src
*** Join PCAs
**** Load Data
#+begin_src R
## Load Areas
exp_old <- read_csv('../Old_Arrays/R_results_OldArrays_Variantome/geneLevel_exp.csv') %>%
  select(-Name, -Variant, -Annot)

exp_new <- read_csv('../New_Arrays/R_results_NewArray/geneLevel_exp.csv') %>%
  select(-Name, -Variant, -Annot)

exp_df <- full_join(exp_old, exp_new)
exp_df[exp_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Load Red Signal
red_old <- read_csv('../Old_Arrays/R_results_OldArrays_Variantome/geneLevel_redSignalexp.csv') %>%
  select(-Name, -Variant, -Annot)

red_new <- read_csv('../New_Arrays/R_results_NewArray/geneLevel_redSignal_exp.csv') %>%
  select(-Name, -Variant, -Annot)

red_df <- full_join(red_old, red_new)
red_df[red_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Load info_df
info_df <- read_csv('../../../Binned_Coverage/info_df.csv')

## Load dif_genes
dif_df <- read_csv('../../../Binned_Coverage/max_log2FC2_filters_passed.csv')


#+end_src
**** Dif Genes
#+begin_src R
## PCA Dif Genes

pca_df <- exp_df %>%
  filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
head(df_pca)

strains <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][1])
tps <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][2])

?str_split

df_pca$Strain <- strains
df_pca$TimePoint <- tps

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point(aes(size= TimePoint))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
#p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_dif_genes.pdf", device = "pdf")

#+end_src
**** Collapse genes to 1 val
#+begin_src R
## PCA colapse genes into 1 val

maxexp_df <- exp_df %>%
  rowwise() %>%
  mutate(Max12B = max(c_across(contains('12B')))) %>%
  mutate(Max10G = max(c_across(contains('10G')))) %>%
  mutate(Max3D7B = max(c_across(contains('3D7B')))) %>%
  mutate(MaxA7 = max(c_across(contains('A7')))) %>%
  mutate(MaxE5 = max(c_across(contains('E5')))) %>%
  mutate(MaxB11 = max(c_across(contains('B11')))) %>%
  ungroup() %>%
  select(Gene_id, contains('Max'))

pca_df <- maxexp_df %>%
  #filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
head(df_pca)

strains <- sapply(pca_df$name, function(x) gsub('Max', '', x, fixed = T))
df_pca$Strain <- strains

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point()
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
##p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_collapsed_genes.pdf", device = "pdf")

#+end_src
**** Percentiles
#+begin_src R
my_percentile <- function(vector){
  ecdf(vector)(vector)*100
}

red_perc_df <- red_df %>%
  mutate(across(.cols = -Gene_id, .fns = my_percentile, .names = "Perc_{.col}")) %>%
  select(Gene_id, contains('Perc'))


## PCA Red Signal Perc

pca_df <- red_perc_df %>%
  #filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)

strains <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][2])
tps <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][3])

df_pca$Strain <- strains
df_pca$TimePoint <- tps

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point(aes(size= TimePoint))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
#p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_redperc_genes.pdf", device = "pdf")

## Collapse into 1 val

maxperc_df <- red_perc_df %>%
  rowwise() %>%
  mutate(Max12B = max(c_across(contains('12B')))) %>%
  mutate(Max10G = max(c_across(contains('10G')))) %>%
  mutate(Max3D7B = max(c_across(contains('3D7B')))) %>%
  mutate(MaxA7 = max(c_across(contains('A7')))) %>%
  mutate(MaxE5 = max(c_across(contains('E5')))) %>%
  mutate(MaxB11 = max(c_across(contains('B11')))) %>%
  ungroup() %>%
  select(Gene_id, contains('Max'))

pca_df <- maxexp_df %>%
  #filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
head(df_pca)

strains <- sapply(pca_df$name, function(x) gsub('Max', '', x, fixed = T))
df_pca$Strain <- strains

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point()
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
##p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_redperc_collapsed_genes.pdf", device = "pdf")
#+end_src
*** Join PCAs with 3D7B/mean(new) as ref
**** Areas
#+begin_src R
old_ref <- old_areas %>%
  mutate(l_12B_ref = `12B_Left` - `3D7B_Left`) %>%
  mutate(r_12B_ref = `12B_Right` - `3D7B_Right`) %>%
  mutate(m_12B_ref = `12B_Middle` - `3D7B_Middle`) %>%
  mutate(s_12B_ref = `12B_Sides` - `3D7B_Sides`) %>%
  mutate(l_10G_ref = `10G_Left` - `3D7B_Left`) %>%
  mutate(r_10G_ref = `10G_Right` - `3D7B_Right`) %>%
  mutate(m_10G_ref = `10G_Middle` - `3D7B_Middle`) %>%
  mutate(s_10G_ref = `10G_Sides` - `3D7B_Sides`) %>%
  select(Gene_id, contains('_ref'))

new_ref <- new_areas %>%
  rowwise() %>%
  mutate(l_A7_ref = `A7_Left` - mean(c(`A7_Left`, `E5_Left`, `B11_Left`))) %>%
  mutate(r_A7_ref = `A7_Right` - mean(c(`A7_Right`, `E5_Right`, `B11_Right`))) %>%
  mutate(m_A7_ref = `A7_Middle` - mean(c(`A7_Middle`, `E5_Middle`, `B11_Middle`))) %>%
  mutate(s_A7_ref = `A7_Sides` - mean(c(`A7_Sides`, `E5_Sides`, `B11_Sides`))) %>%
  mutate(l_E5_ref = `E5_Left` - mean(c(`A7_Left`, `E5_Left`, `B11_Left`))) %>%
  mutate(r_E5_ref = `E5_Right` - mean(c(`A7_Right`, `E5_Right`, `B11_Right`))) %>%
  mutate(m_E5_ref = `E5_Middle` - mean(c(`A7_Middle`, `E5_Middle`, `B11_Middle`))) %>%
  mutate(s_E5_ref = `E5_Sides` - mean(c(`A7_Sides`, `E5_Sides`, `B11_Sides`))) %>%
  mutate(l_B11_ref = `B11_Left` - mean(c(`A7_Left`, `E5_Left`, `B11_Left`))) %>%
  mutate(r_B11_ref = `B11_Right` - mean(c(`A7_Right`, `E5_Right`, `B11_Right`))) %>%
  mutate(m_B11_ref = `B11_Middle` - mean(c(`A7_Middle`, `E5_Middle`, `B11_Middle`))) %>%
  mutate(s_B11_ref = `B11_Sides` - mean(c(`A7_Sides`, `E5_Sides`, `B11_Sides`))) %>%
  ungroup() %>%
  select(Gene_id, contains('_ref'))


join_ref <- old_ref %>%
  full_join(new_ref, by = 'Gene_id')

join_ref_nona <- join_ref %>%
  select(-Gene_id) %>%
  filter(complete.cases(.))


pca <- prcomp(t(join_ref_nona))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
df_pca$Sample <- colnames(join_ref_nona)
df_pca$Strain <- c(rep('12B', 4), rep('10G', 4), rep('A7', 4), rep('E5', 4), rep('B11', 4))

library(ggrepel)

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point(aes(), size = 3)
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
p <- p + theme_classic()
p <- p + theme(text = element_text(size=20))
p <- p + geom_label_repel(aes(label = Sample))
p <- p + theme(legend.position = "none")
p
                                        #p
ggsave(p, filename = paste0('./PCAs/', "coverage_", str_selector, '_PCA.png'), device = "png")

#+end_src
**** Expressio
#+begin_src R

exp_ref <- exp_df %>%
  mutate(tp_10_12B_ref = `12B_tp10` - `3D7B_tp10`) %>%
  mutate(tp_20_12B_ref = `12B_tp20` - `3D7B_tp20`) %>%
  mutate(tp_30_12B_ref = `12B_tp30` - `3D7B_tp30`) %>%
  mutate(tp_37_12B_ref = `12B_tp37` - `3D7B_tp37`) %>%
  mutate(tp_40_12B_ref = `12B_tp40` - `3D7B_tp40`) %>%
  mutate(tp_43_12B_ref = `12B_tp43` - `3D7B_tp43`) %>%

  mutate(tp_10_10G_ref = `10G_tp10` - `3D7B_tp10`) %>%
  mutate(tp_20_10G_ref = `10G_tp20` - `3D7B_tp20`) %>%
  mutate(tp_30_10G_ref = `10G_tp30` - `3D7B_tp30`) %>%
  mutate(tp_37_10G_ref = `10G_tp37` - `3D7B_tp37`) %>%
  mutate(tp_40_10G_ref = `10G_tp40` - `3D7B_tp40`) %>%
  mutate(tp_43_10G_ref = `10G_tp43` - `3D7B_tp43`) %>%

  rowwise() %>%

  mutate(tp_10_A7_ref = `A7_tp10` - mean(c(`A7_tp10`, `E5_tp10`, `B11_tp10`))) %>%
  mutate(tp_20_A7_ref = `A7_tp20` - mean(c(`A7_tp20`, `E5_tp20`, `B11_tp20`))) %>%
  mutate(tp_30_A7_ref = `A7_tp30` - mean(c(`A7_tp30`, `E5_tp30`, `B11_tp30`))) %>%
  mutate(tp_37_A7_ref = `A7_tp37` - mean(c(`A7_tp37`, `E5_tp37`, `B11_tp37`))) %>%
  mutate(tp_40_A7_ref = `A7_tp40` - mean(c(`A7_tp40`, `E5_tp40`, `B11_tp40`))) %>%
  mutate(tp_43_A7_ref = `A7_tp43` - mean(c(`A7_tp43`, `E5_tp43`, `B11_tp43`))) %>%

  mutate(tp_10_E5_ref = `E5_tp10` - mean(c(`A7_tp10`, `E5_tp10`, `B11_tp10`))) %>%
  mutate(tp_20_E5_ref = `E5_tp20` - mean(c(`A7_tp20`, `E5_tp20`, `B11_tp20`))) %>%
  mutate(tp_30_E5_ref = `E5_tp30` - mean(c(`A7_tp30`, `E5_tp30`, `B11_tp30`))) %>%
  mutate(tp_37_E5_ref = `E5_tp37` - mean(c(`A7_tp37`, `E5_tp37`, `B11_tp37`))) %>%
  mutate(tp_40_E5_ref = `E5_tp40` - mean(c(`A7_tp40`, `E5_tp40`, `B11_tp40`))) %>%
  mutate(tp_43_E5_ref = `E5_tp43` - mean(c(`A7_tp43`, `E5_tp43`, `B11_tp43`))) %>%

  mutate(tp_10_B11_ref = `B11_tp10` - mean(c(`A7_tp10`, `E5_tp10`, `B11_tp10`))) %>%
  mutate(tp_20_B11_ref = `B11_tp20` - mean(c(`A7_tp20`, `E5_tp20`, `B11_tp20`))) %>%
  mutate(tp_30_B11_ref = `B11_tp30` - mean(c(`A7_tp30`, `E5_tp30`, `B11_tp30`))) %>%
  mutate(tp_37_B11_ref = `B11_tp37` - mean(c(`A7_tp37`, `E5_tp37`, `B11_tp37`))) %>%
  mutate(tp_40_B11_ref = `B11_tp40` - mean(c(`A7_tp40`, `E5_tp40`, `B11_tp40`))) %>%
  mutate(tp_43_B11_ref = `B11_tp43` - mean(c(`A7_tp43`, `E5_tp43`, `B11_tp43`))) %>%

  ungroup() %>%
  select(Gene_id, contains('_ref'))

pca_df <- exp_ref %>%
  filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
head(df_pca)

strains <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][3])
tps <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][2])

df_pca$Strain <- strains
df_pca$TimePoint <- tps

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point(aes(size= TimePoint))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
#p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_ref3D7BorMean_dif_genes.pdf", device = "pdf")

#+end_src
*** Heatmaps
**** Load Data
#+begin_src R
##save.image('trans_heatmaps.RData')
##load('trans_heatmaps.RData')

old_path <-'../Old_Arrays/R_results_OldArrays_Variantome/'
new_path <-'../New_Arrays/R_results_NewArray/'

old_df <- read_csv(paste0(old_path, 'old_arrays_final_df.csv'))
new_df <- read_csv(paste0(new_path, 'new_arrays_final_df.csv'))

old_areas <- read_csv(paste0(old_path, 'area_geneLevel.csv'))
new_areas <- read_csv(paste0(new_path, 'area_geneLevel.csv'))
new_areas[new_areas$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

old_max <- read_csv(paste0(old_path, 'all_aMAFC.csv'))
new_max <- read_csv(paste0(new_path, 'all_aMAFC.csv'))
new_max[new_max$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Load info_df
info_df <- read_csv('../../../Binned_Coverage/info_df.csv')

## Outdir
outdir <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Plots/Transcription_Heatmaps/'

oldtime <- 13.5
newtime <- 14.95
#+end_src
**** Create old maxFC DF
#+begin_src R
## OLD TOP DIFERENCES
## Quin timepoint agafem? El de m√†xima difer√®ncia. Entre quines soques?
## Qu√® passa si un mateix gen t√© difer√®ncies a TPs diferents en contrastos diferents?

## Agafem per a cada gen el timepoint de m√†xima difer√®ncia del contrast amb m√†xima difer√®ncia.

dif_12B_10G <- read_csv(paste0(old_path, '12B_vs_10G_log2FC2_red15_maxtime.csv'))
dif_12B_3D7B <- read_csv(paste0(old_path, '12B_vs_3D7B_log2FC2_red15_maxtime.csv'))
dif_10G_3D7B <- read_csv(paste0(old_path, '10G_vs_3D7B_log2FC2_red15_maxtime.csv'))

table(dif_12B_10G$Dupl_Del)
table(dif_12B_3D7B$Dupl_Del)
table(dif_10G_3D7B$Dupl_Del)

tp_12B_10G <- old_max %>%
  select(Gene_id, `12B-10G_MaxTime`) %>%
  filter(Gene_id %in% dif_12B_10G$Gene_id)

tp_12B_3D7B <- old_max %>%
  select(Gene_id, `12B-3D7B_MaxTime`) %>%
  filter(Gene_id %in% dif_12B_3D7B$Gene_id)

tp_10G_3D7B <- old_max %>%
  select(Gene_id, `10G-3D7B_MaxTime`) %>%
  filter(Gene_id %in% dif_10G_3D7B$Gene_id)

x <- dif_12B_10G %>%
  select(Gene_id, `12B-10G_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `12B-10G_MaxVal`) %>%
  mutate(Contrast = '12B_10G') %>%
  left_join(tp_12B_10G) %>%
  rename(MaxTime = `12B-10G_MaxTime`)

y <- dif_12B_3D7B %>%
  select(Gene_id, `12B-3D7B_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `12B-3D7B_MaxVal`) %>%
  mutate(Contrast = '12B_3D7B') %>%
  left_join(tp_12B_3D7B) %>%
  rename(MaxTime = `12B-3D7B_MaxTime`)

z <- dif_10G_3D7B %>%
  select(Gene_id, `10G-3D7B_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `10G-3D7B_MaxVal`) %>%
  mutate(Contrast = '10G_3D7B') %>%
  left_join(tp_10G_3D7B) %>%
  rename(MaxTime = `10G-3D7B_MaxTime`)

old_maxdifs <- bind_rows(x, y, z) %>%
  arrange(-abs(MaxVal)) %>%
  distinct(Gene_id, .keep_all = TRUE)

old_heat_areas <- NULL
new_heat_areas <- NULL
for (gid in old_maxdifs$Gene_id) {
  tp <- old_maxdifs %>%
    filter(Gene_id == gid) %>%
    select(MaxTime) %>%
    pull()

  old_a <- old_areas %>%
    filter(Gene_id == gid) %>%
    select(contains(tp))

  new_a <- new_areas %>%
    filter(Gene_id == gid) %>%
    select(contains(tp))

  if (dim(new_a)[1] == 0){
    new_a = tibble(
      c1 = as.numeric(NA),
      c2 = as.numeric(NA),
      c3 = as.numeric(NA)
    )
    }
  names(old_a) <- c('1.2B', '10G', '3D7-B')
  names(new_a) <- c('A7', 'B11', 'E5')

  old_heat_areas <- bind_rows(old_heat_areas, old_a)
  new_heat_areas <- bind_rows(new_heat_areas, new_a)
}

old_heat_df <- bind_cols(old_maxdifs, old_heat_areas)
new_heat_df <- bind_cols(old_maxdifs %>% select(Gene_id, Variant, Gam_specific, Dupl_Del), new_heat_areas)

old_heat_df <- old_heat_df %>%
  rowwise() %>%
  mutate(rwmean_centered_12B = (`1.2B` - mean(c(`1.2B`, `10G`, `3D7-B`)))/oldtime) %>%
  mutate(rwmean_centered_10G = (`10G` - mean(c(`1.2B`, `10G`, `3D7-B`)))/oldtime) %>%
  mutate(rwmean_centered_3D7B = (`3D7-B` - mean(c(`1.2B`, `10G`, `3D7-B`)))/oldtime)

new_heat_df <- new_heat_df %>%
  rowwise() %>%
  mutate(rwmean_centered_A7 = (A7 - mean(c(A7, E5, B11)))/newtime) %>%
  mutate(rwmean_centered_E5 = (E5 - mean(c(A7, E5, B11)))/newtime) %>%
  mutate(rwmean_centered_B11 = (B11 - mean(c(A7, E5, B11)))/newtime)

old_pre_dupl_filtering <- old_heat_df
new_pre_dupl_filtering <- new_heat_df

old_heat_df <- old_heat_df %>%
  filter(!Dupl_Del)

new_heat_df <- new_heat_df %>%
  filter(!Dupl_Del)

old_heat_df
new_heat_df

gids <- old_heat_df$Gene_id

## Ordering
mtx <- old_heat_df %>%
  select(contains('rwmean'))

##Make hierarquical Clustering
dmtx <- dist(scale(mtx), method = "euclidean")
cl <- hclust(dmtx, method = 'average')

old_heat_df$Gene_id <- factor(old_heat_df$Gene_id, levels = old_heat_df$Gene_id[cl$order])
new_heat_df$Gene_id <- factor(new_heat_df$Gene_id, levels = new_heat_df$Gene_id[cl$order])

old_heat_df %>%
  full_join(new_heat_df %>% select(-Variant, -Gam_specific, -Dupl_Del)) %>%
  arrange(fct_rev(Gene_id)) %>%
  write_tsv(paste0(
    outdir,
    './figure2_12b10g3d7b_selected_heatmap.tsv'
  ))

## new_heat_df %>%
##   arrange(Clust_Order) %>%
##   write_tsv(paste0(
##     outdir,
##     './figure2_12b10g3d7bselected_a7e5b11_heatmap.tsv'
##   ))


## old_heat_df$Order <- cl$order
## old_heat_df %>%
##   arrange(Order) %>%
##   select(Gene_id, Order)

old_tree <- ggdendrogram(cl, rotate = T)

old_m_infodf <- old_heat_df %>%
  select(Gene_id, Variant, Gam_specific) %>%
  gather(variable, value, -Gene_id)

old_order <- c(
  'rwmean_centered_12B',
  'rwmean_centered_10G',
  'rwmean_centered_3D7B'
)

new_order <- c(
  'rwmean_centered_A7',
  'rwmean_centered_E5',
  'rwmean_centered_B11'
)

old_heat_df

mold_df <- old_heat_df %>%
  select(Gene_id, contains('rwmean')) %>%
  gather(variable, value, -Gene_id) %>%
  mutate(variable = factor(variable, levels = old_order))

mnew_df <- new_heat_df %>%
  select(Gene_id, contains('rwmean')) %>%
  gather(variable, value, -Gene_id) %>%
  mutate(variable = factor(variable, levels = new_order))

## old_heat_df %>%
##   left_join(info_df, by = 'Gene_id') %>%
##   select(
##     Gene_id,
##     Variant,
##     Gam_specific,
##     contains('rwmean')
##     ) %>%
##   write_tsv('old_arrays_maxFC_heatmap_df.tsv')
#+end_src
**** Create new maxFC DF
#+begin_src R
## NEW TOP DIFERENCES
## Quin timepoint agafem? El de m√†xima difer√®ncia. Entre quines soques?
## Qu√® passa si un mateix gen t√© difer√®ncies a TPs diferents en contrastos diferents?

## Agafem per a cada gen el timepoint de m√†xima difer√®ncia del contrast amb m√†xima difer√®ncia.

dif_A7_E5 <- read_csv(paste0(new_path, 'A7_vs_E5_log2FC2_red15_maxtime.csv'))
dif_A7_B11 <- read_csv(paste0(new_path, 'A7_vs_B11_log2FC2_red15_maxtime.csv'))
dif_B11_E5 <- read_csv(paste0(new_path, 'B11_vs_E5_log2FC2_red15_maxtime.csv'))

tp_A7_E5 <- new_max %>%
  select(Gene_id, `A7-E5_MaxTime`) %>%
  filter(Gene_id %in% dif_A7_E5$Gene_id)

tp_A7_B11 <- new_max %>%
  select(Gene_id, `A7-B11_MaxTime`) %>%
  filter(Gene_id %in% dif_A7_B11$Gene_id)

tp_B11_E5 <- new_max %>%
  select(Gene_id, `B11-E5_MaxTime`) %>%
  filter(Gene_id %in% dif_B11_E5$Gene_id)

x <- dif_A7_E5 %>%
  select(Gene_id, `A7-E5_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `A7-E5_MaxVal`) %>%
  mutate(Contrast = 'A7_E5') %>%
  left_join(tp_A7_E5) %>%
  rename(MaxTime = `A7-E5_MaxTime`)

y <- dif_A7_B11 %>%
  select(Gene_id, `A7-B11_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `A7-B11_MaxVal`) %>%
  mutate(Contrast = 'A7_B11') %>%
  left_join(tp_A7_B11) %>%
  rename(MaxTime = `A7-B11_MaxTime`)

z <- dif_B11_E5 %>%
  select(Gene_id, `B11-E5_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `B11-E5_MaxVal`) %>%
  mutate(Contrast = 'B11_E5') %>%
  left_join(tp_B11_E5) %>%
  rename(MaxTime = `B11-E5_MaxTime`)

new_maxdifs <- bind_rows(x, y, z) %>%
  arrange(-abs(MaxVal)) %>%
  distinct(Gene_id, .keep_all = TRUE)

new_old_heat_areas <- NULL
new_new_heat_areas <- NULL
for (gid in new_maxdifs$Gene_id) {

  tp <- new_maxdifs %>%
    filter(Gene_id == gid) %>%
    select(MaxTime) %>%
    pull()

  old_a <- old_areas %>%
    filter(Gene_id == gid) %>%
    select(contains(tp))

  new_a <- new_areas %>%
    filter(Gene_id == gid) %>%
    select(contains(tp))

  if (dim(old_a)[1] == 0){
    old_a = tibble(
      c1 = as.numeric(NA),
      c2 = as.numeric(NA),
      c3 = as.numeric(NA)
    )
    }
  names(old_a) <- c('1.2B', '10G', '3D7-B')
  names(new_a) <- c('A7', 'B11', 'E5')

  new_old_heat_areas <- bind_rows(new_old_heat_areas, old_a)
  new_new_heat_areas <- bind_rows(new_new_heat_areas, new_a)
}
new_old_heat_df <- bind_cols(new_maxdifs %>% select(Gene_id, Variant, Gam_specific, Dupl_Del), new_old_heat_areas)
new_new_heat_df <- bind_cols(new_maxdifs, new_new_heat_areas)

new_old_heat_df <- new_old_heat_df %>%
  rowwise() %>%
  mutate(rwmean_centered_12B = (`1.2B` - mean(c(`1.2B`, `10G`, `3D7-B`)))/oldtime) %>%
  mutate(rwmean_centered_10G = (`10G` - mean(c(`1.2B`, `10G`, `3D7-B`)))/oldtime) %>%
  mutate(rwmean_centered_3D7B = (`3D7-B` - mean(c(`1.2B`, `10G`, `3D7-B`)))/oldtime)

new_new_heat_df <- new_new_heat_df %>%
  rowwise() %>%
  mutate(rwmean_centered_A7 = (A7 - mean(c(A7, E5, B11)))/newtime) %>%
  mutate(rwmean_centered_E5 = (E5 - mean(c(A7, E5, B11)))/newtime) %>%
  mutate(rwmean_centered_B11 = (B11 - mean(c(A7, E5, B11)))/newtime)


new_old_pre_dupl_filtering <- new_old_heat_df
new_new_pre_dupl_filtering <- new_new_heat_df

new_old_heat_df <- new_old_heat_df %>%
  filter(!Dupl_Del)

new_new_heat_df <- new_new_heat_df %>%
  filter(!Dupl_Del)

## Ordering
mtx <- new_new_heat_df %>%
  select(contains('rwmean'))

##Make hierarquical Clustering
dmtx <- dist(scale(mtx), method = "euclidean")
cl <- hclust(dmtx, method = 'average')
new_old_heat_df$Gene_id <- factor(new_old_heat_df$Gene_id, levels = new_old_heat_df$Gene_id[cl$order])
new_new_heat_df$Gene_id <- factor(new_new_heat_df$Gene_id, levels = new_new_heat_df$Gene_id[cl$order])

new_new_heat_df %>%
  full_join(new_old_heat_df %>% select(-Variant, -Gam_specific, -Dupl_Del)) %>%
  arrange(fct_rev(Gene_id)) %>%
  write_tsv(paste0(
    outdir,
    './figure2_a7e5b11_selected_heatmap.tsv'
  ))


new_tree <- ggdendrogram(cl, rotate = T)

new_m_infodf <- new_new_heat_df %>%
  select(Gene_id, Variant, Gam_specific) %>%
  gather(variable, value, -Gene_id)

mnew_old_df <- new_old_heat_df %>%
  select(Gene_id, contains('rwmean')) %>%
  gather(variable, value, -Gene_id) %>%
  mutate(variable = factor(variable, levels = old_order))

mnew_new_df <- new_new_heat_df %>%
  select(Gene_id, contains('rwmean')) %>%
  gather(variable, value, -Gene_id) %>%
  mutate(variable = factor(variable, levels = new_order))

#+end_src
**** Create join maxFC DF with 3D7-B/mean(A7, E5, B11) as reference
The idea is to generate area values with respect to the 3D7-B value for 1.2B and 10G and with respect with the mean of A7/E5/B11 value for A7, E5 and B11.
This way we can directly compare them in a single heatmap.
#+begin_src R

old_heat_df
new_heat_df
new_old_heat_df
new_new_heat_df

## Old Arrays selected

old_sel <- old_heat_df %>%
  full_join(new_heat_df) %>%
  select(-contains('rwmean')) %>%
  mutate(`12B_ref` = `1.2B`-`3D7-B`) %>%
  mutate(`10G_ref` = `10G`-`3D7-B`) %>%
  rowwise() %>%
  mutate(A7_ref = A7-mean(c(A7, E5, B11))) %>%
  mutate(E5_ref = E5-mean(c(A7, E5, B11))) %>%
  mutate(B11_ref = B11-mean(c(A7, E5, B11))) %>%
  ungroup()

## Ordering
mtx <- old_sel %>%
  select(contains('_ref'))

##Make hierarquical Clustering
dmtx_rw <- dist(scale(mtx), method = "euclidean")
dmtx_col <- dist(scale(t(mtx)), method = "euclidean")
rw_order <- hclust(dmtx_rw, method = 'average')$order
col_order <- hclust(dmtx_col, method = 'average')$order

old_sel$Gene_id <- factor(old_sel$Gene_id, levels = old_sel$Gene_id[rw_order])

old_sel_m_info <- old_sel %>%
  select(Gene_id, Variant, Gam_specific) %>%
  gather(variable, value, -Gene_id)

old_sel_m <- old_sel %>%
  select(Gene_id, contains('_ref')) %>%
  gather(variable, value, -Gene_id)

col_names <- old_sel %>%
  select(contains('_ref')) %>%
  colnames()

old_sel_m$variable <- factor(old_sel_m$variable, levels = col_names[col_order])

## New Arrays selected

new_sel <- new_new_heat_df %>%
  full_join(new_old_heat_df) %>%
  select(-contains('rwmean')) %>%
  mutate(`12B_ref` = `1.2B`-`3D7-B`) %>%
  mutate(`10G_ref` = `10G`-`3D7-B`) %>%
  rowwise() %>%
  mutate(A7_ref = A7-mean(c(A7, E5, B11))) %>%
  mutate(E5_ref = E5-mean(c(A7, E5, B11))) %>%
  mutate(B11_ref = B11-mean(c(A7, E5, B11))) %>%
  ungroup()

## Ordering
mtx <- new_sel %>%
  select(contains('_ref'))

##Make hierarquical Clustering
dmtx_rw <- dist(scale(mtx), method = "euclidean")
dmtx_col <- dist(scale(t(mtx)), method = "euclidean")
rw_order <- hclust(dmtx_rw, method = 'average')$order
col_order <- hclust(dmtx_col, method = 'average')$order

new_sel$Gene_id <- factor(new_sel$Gene_id, levels = new_sel$Gene_id[rw_order])

new_sel_m_info <- new_sel %>%
  select(Gene_id, Variant, Gam_specific) %>%
  gather(variable, value, -Gene_id)

new_sel_m <- new_sel %>%
  select(Gene_id, contains('_ref')) %>%
  gather(variable, value, -Gene_id)
new_sel_m$variable <- factor(new_sel_m$variable, levels = col_names[col_order])




#+end_src
**** Heatmaps
#+begin_src R
## Heatmap function

my_heatmap <- function(m_df){
  p <- ggplot(m_df, aes(x = variable, y = Gene_id, fill = value))
  p <- p + geom_tile()
  p <- p + theme(
             ##text=element_text(size=24, family="Roboto"),
             legend.position='bottom',
             legend.title = element_blank(),

             panel.background=element_blank(),
             panel.grid.minor=element_blank(),
             panel.grid.major=element_blank(),
             plot.background=element_blank(),

             axis.title = element_blank(),
             axis.line.x = element_blank(),
             axis.ticks.x = element_blank(),
             axis.title.x = element_blank()
           )
  return(p)
}

my_areas_heatmap <- function(m_df){
  p <- my_heatmap(m_df)
  p <- p + scale_fill_gradient2(
             low = "blue",
             high = "yellow",
             mid = 'black',
             na.value="grey",
             limits = c(-3, 3),
             oob = squish
             )
  return(p)
}

my_info_heatmap <- function(m_df){
  p <- my_heatmap(m_df)
  p <- p + scale_fill_manual(
             values = c('white', 'black')
           )
  p <- p + theme(
               axis.text.y = element_blank(),
               axis.ticks.y = element_blank(),

               panel.border=element_blank(),
               panel.grid.major=element_blank(),

               strip.background = element_blank(),
               strip.text.x = element_blank(),
               strip.text.y = element_blank(),
             )
  return(p)
}


max(mold_df$value, na.rm = T)
min(mold_df$value, na.rm = T)

max(mnew_df$value, na.rm = T)
min(mnew_df$value, na.rm = T)

max(mnew_new_df$value, na.rm = T)
min(mnew_new_df$value, na.rm = T)

max(mnew_old_df$value, na.rm = T)
min(mnew_old_df$value, na.rm = T)

## Old maxFC
p_old <- my_areas_heatmap(mold_df)
p_new <- my_areas_heatmap(mnew_df)
i <- my_info_heatmap(old_m_infodf)
whole_plot <- arrangeGrob(p_old, p_new, i, old_tree, nrow = 1, widths = c(2, 2, 1, 1))
plot(whole_plot)
ggsave(paste0(
  outdir,
  'figure2_12b10g3d7b_topdif_whole_new_reordered_version_new.pdf'
), whole_plot, device = 'pdf')

## New maxFC
p_new <- my_areas_heatmap(mnew_new_df)
p_old <- my_areas_heatmap(mnew_old_df)
i <- my_info_heatmap(new_m_infodf)
whole_plot <- arrangeGrob(p_new, p_old, i, new_tree, nrow = 1, widths = c(2, 2, 1, 1))
plot(whole_plot)
ggsave(paste0(
  outdir,
  'figure2_a7e5b11_topdif_whole_new_reordered_version_new.pdf'
), whole_plot, device = 'pdf')

## Join with 3D7B/mean(A7/E5/B11) ref

## Old sel
p_old_sel <- my_areas_heatmap(old_sel_m)
p_info <- my_info_heatmap(old_sel_m_info)
whole_plot <- arrangeGrob(p_old_sel, p_info, old_tree, nrow = 1, widths = c(2, 1, 1))
plot(whole_plot)
ggsave('./Heatmaps/old_sel_topdif_3D7BmeanA7E5B11_ref.pdf', whole_plot, device = 'pdf')

## New sel
p_new_sel <- my_areas_heatmap(new_sel_m)
p_info <- my_info_heatmap(new_sel_m_info)
whole_plot <- arrangeGrob(p_new_sel, p_info, old_tree, nrow = 1, widths = c(2, 1, 1))
plot(whole_plot)
ggsave('./Heatmaps/new_sel_topdif_3D7BmeanA7E5B11_ref.pdf', whole_plot, device = 'pdf')
#+end_src
*** Compare FC genes with B11
#+begin_src R
## Load Old Dif genes
old_fld <- '../Old_Arrays/R_results_OldArrays_Variantome/'
suffix <- '_log2FC2_red15_maxtime.csv'

v12B_10G <- read_csv(paste0(old_fld, '12B_vs_10G', suffix))
v12B_3D7B <- read_csv(paste0(old_fld, '12B_vs_3D7B', suffix))
v10G_3D7B <- read_csv(paste0(old_fld, '10G_vs_3D7B', suffix))

## Load New Dif Genes
new_fld <- '../New_Arrays/R_results_NewArray/'
suffix <- '_log2FC2_red15_maxtime.csv'

vA7_B11 <- read_csv(paste0(new_fld, 'A7_vs_B11', suffix))
vA7_E5 <- read_csv(paste0(new_fld, 'A7_vs_E5', suffix))
vB11_E5 <- read_csv(paste0(new_fld, 'B11_vs_E5', suffix))

## Mix
n <- unique(c(vA7_B11$Gene_id, vB11_E5$Gene_id))
o <- unique(c(v12B_3D7B$Gene_id, v10G_3D7B$Gene_id))
intersect(n,o)


x <- v12B_3D7B %>%
  select(Gene_id, contains('MaxVal')) %>%
  full_join(v10G_3D7B %>% select(Gene_id, contains('MaxVal'))) %>%
  full_join(vA7_B11 %>% select(Gene_id, contains('MaxVal'))) %>%
  full_join(vB11_E5 %>% select(Gene_id, contains('MaxVal')))

x %>%
  filter(Gene_id %in% intersect(n,o)) %>%
  print(n = 100)


info_df %>%
  filter(Gene_id %in% intersect(n,o)) %>%
  select(Gene_id, Name, Annot, Variant, Gam_specific, Family, SubFamily) %>%
  write_csv('similarities_3D7A_B11.csv')
#+end_src
*** 1.2B+10G and B11 commonalities
Since both 1.2B/10G and B11 have truncations in GDV1 we want to analyze those genes differentially expressed in these subclones that go in a same direction.
#+begin_src R
library(tidyverse)

getwd()

## Annot
info_df <- read_csv('./info_df.csv')

## Old arrays
old <- read_csv('../Microarrays/New_Old_separate_approach/Old_Arrays/R_results_OldArrays_Variantome/all_aMAFC.csv')

## New arrays
new <- read_csv('../Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/all_aMAFC.csv')

## Set thresholds
fc_th <- 1 ## FC considered to be a DE gene
dif_th <- 1 ## difference we alow between strains

### Get 3D7B DE genes
old
s3d7b_difs <- old %>%
  filter(abs(`12B-3D7B_MaxVal`) > fc_th | abs(`10G-3D7B_MaxVal`) > fc_th) %>%
  select(Gene_id, `12B-3D7B_MaxVal`, `10G-3D7B_MaxVal`)

s12B10G_3d7b <- s3d7b_difs %>%
  filter(sign(`12B-3D7B_MaxVal`) == sign(`10G-3D7B_MaxVal`)) %>% ## Check for different sign
  rowwise() %>%
  filter(abs(`12B-3D7B_MaxVal` - `10G-3D7B_MaxVal`) < dif_th) %>%
  mutate(Meandif_12B10G_3D7B = mean(c(`12B-3D7B_MaxVal`, `10G-3D7B_MaxVal`))) %>%
  ungroup()

### Get B11 DE genes
b11_difs <- new %>%
  filter(abs(`A7-B11_MaxVal`) > fc_th | abs(`B11-E5_MaxVal`) > fc_th) %>%
  select(Gene_id, `A7-B11_MaxVal`, `B11-E5_MaxVal`)

b11_a7e5 <- b11_difs %>%
  filter(sign(`A7-B11_MaxVal`) != sign(`B11-E5_MaxVal`)) %>% ## Check for different sign
  rowwise() %>%
  filter(abs(sum(`A7-B11_MaxVal`, `B11-E5_MaxVal`)) < dif_th) %>%
  mutate(Meandif_A7E5_B11 = mean(c(`A7-B11_MaxVal`, -`B11-E5_MaxVal`))) %>%
  ungroup()

## Join differences
join_meandifs <- b11_a7e5 %>%
  select(Gene_id, contains('Mean')) %>%
  left_join(s12B10G_3d7b %>% select(Gene_id, contains('Mean')), by = 'Gene_id') %>%
  filter(complete.cases(.))

final_df <- join_meandifs %>%
  filter(sign(Meandif_A7E5_B11) != sign(Meandif_12B10G_3D7B)) %>% ## Check for different sign
  rowwise() %>%
  filter(abs(Meandif_A7E5_B11 + Meandif_12B10G_3D7B) < 1) %>%
  #mutate(Meandif_12B10G_3D7B = mean(c(`12B-3D7B_MaxVal`, `10G-3D7B_MaxVal`))) %>%
  ungroup() %>%
  left_join(info_df, by = 'Gene_id')

final_df

final_df %>%
  write_tsv('B11_12B10G_similarities.tsv')

#+end_src
*** Comparison with GDV1 paper
#+begin_src R
library(readxl)
library(tidyverse)

gdv1_dd <- read_xlsx('./GDV1_del_effects/gdv1_DD_supptable.xlsx')

gdv1_paper <- gdv1_dd %>%
  rename(Gene_id = `Gene Id`, GDV1_paper = `sig. up or down`) %>%
  select(Gene_id, GDV1_paper) %>%
  filter(GDV1_paper %in% c('u', 'd'))

our_list <- read_tsv('./GDV1_del_effects/B11_12B10G_similarities.tsv')

cross_df <- our_list %>%
  left_join(gdv1_paper)

cross_df %>%
  count(GDV1_paper)

cross_df %>%
  filter(!is.na(GDV1_paper)) %>%
  select(Gene_id, contains('Mean'), GDV1_paper, Annot)
#+end_src
*** Var Genes Heatmap
#+begin_src R
## Load Red Signal
red_old <- read_csv('../Old_Arrays/R_results_OldArrays_Variantome/geneLevel_redSignalexp.csv') %>% select(-Name, -Variant, -Annot)

red_new <- read_csv('../New_Arrays/R_results_NewArray/geneLevel_redSignal_exp.csv') %>%
  select(-Name, -Variant, -Annot)

red_df <- full_join(red_old, red_new)
red_df[red_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Load info_df
info_df <- read_tsv('/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Output_Tables/info_df.tsv')

vals <- tibble(red_df) %>% select(contains('tp'))

max_tps <- colnames(vals)[apply(vals,1,which.max)]
max_tps <- gsub(paste0(strain, '_'), '', max_tps)


strains <- c('A7', 'E5', 'B11')
strain <- strains[1]

plot_df <- red_df %>%
  left_join(info_df) %>%
  mutate(Max_12B = select(., contains('12B')) %>% do.call(pmax, .)) %>%
  mutate(Max_10G = select(., contains('10G')) %>% do.call(pmax, .)) %>%
  mutate(Max_A7 = select(., contains('A7')) %>% do.call(pmax, .)) %>%
  mutate(Max_E5 = select(., contains('E5')) %>% do.call(pmax, .)) %>%
  mutate(Max_B11 = select(., contains('B11')) %>% do.call(pmax, .)) %>%
  select(Gene_id, contains('Max_'), Family, SubFamily) %>%
  filter(Family == 'VAR' & SubFamily != 'var pseudo,truncated or -like.')
  #mutate(across(contains('Max_'), ~ log2(.)))

scaled_plot_df  <- plot_df %>% mutate(across(contains('Max_'), ~(scale(.) %>% as.vector)))


##mplot_df <- scaled_plot_df %>%
mplot_df <- plot_df %>%
  pivot_longer(contains('Max_'), names_to = 'Strain', values_to = 'Cy5') %>%
  mutate(Strain = gsub('Max_', '', Strain, fixed = T)) %>%
  mutate(SubFamily = factor(SubFamily, levels = unique(SubFamily))) %>%
  mutate(Log2Cy5 = log2(Cy5))

mplot_df
p <- ggplot(mplot_df, aes(x = Strain, y = Gene_id, fill = Cy5))
p <- p + geom_tile(colour="snow3")
p <- p + theme(
           ##text=element_text(size=24, family="Roboto"),
           legend.position='bottom',
           legend.title = element_blank(),

           panel.background=element_blank(),
           panel.grid.minor=element_blank(),
           plot.background=element_blank(),

           axis.title = element_blank(),
           axis.line.x = element_blank(),
           axis.ticks.x = element_blank(),
           axis.title.x = element_blank()
         )
p <- p + scale_fill_gradient(
           low = "blue",
           high = "yellow",
           na.value="grey",
           limits=c(0,5000)
           )
p
#+end_src
* ChIP-Seq Data
** ChIP-Seq Analysis until Tracks
*** Files description
This are all the primary output generated by analyzing the ChIP-Sequencing data we have.
**** Folders
***** Bams
BAM format raw alignments. This files represent the alignment of the obtained reads to the reference genome, without further processing.
***** RPKMs
Reads per kilo-base million reads. For each sample (IP and input) we calculate the RPKMs in 100bp bins. This files can bu used to visualize the normalized by number of reads coverage for each sample.
***** RPKMs_normInput
Normalized by input RPKMs. We first calculate RPKMs as above, and we then normalize by input. Coverage is calculated as log2(IP_rpkm/input_rpkm). This files can be use to visualize the normalized (by number of reads and input) coverage.
*** Pre-processing and Alignment
:PROPERTIES:
:header-args:python: :session chip_seq_process :tangle ./Paper_Analysis/Scripts/ChIP_Seq/chip_seq_preprocess_and_align.py
:END:
**** Reads Quality Control
The first step is to evaluate the quality of the reads using ~fastqc~
We check the report for any possible problem in the data.
#+begin_example
$fastqc ./*\.fastq
#+end_example
**** Clean reads: BBDUK
The next step is to "clean" the read files using BBDUK
#+begin_src python
#### Clean Reads with BBDUK ####

import subprocess as sp
import os

## Functions

def call_BBDUK(in1, in2, out1, out2, outm, ref, params):
    cmd = ("bbduk.sh in={} in2={} "
           "out={} out2={} outm={} "
           "ref={}") .format(in1, in2, out1, out2, outm, ref)

    cmd = cmd+" "+params
    sp.call(cmd, shell=True)

## Calls

params = "ktrim=r k=22 mink=6 overwrite=t"
ref = "/home/lucas/Programs/bbmap/resources/adapters.fa"

root_path = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Raw_Data/"
read1s = []
read2s = []
for path, subdirs, files in os.walk(root_path):
    for f in files:
        if all(x in f for x in ["read1", ".fastq"]):
            read1s.append(os.path.join(path, f))
        elif all(x in f for x in ["read2", ".fastq"]):
            read2s.append(os.path.join(path, f))
        else:
            print(f)


read1s = sorted(read1s)
read2s = sorted(read2s)
outpath = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Clean_Reads/"

for pair in zip(read1s, read2s):
    in1, in2 = pair[0], pair[1]
    out1 = outpath + pair[0].rsplit("/", 1)[1].replace(".fastq", "_clean.fastq")
    out2 = outpath + pair[1].rsplit("/", 1)[1].replace(".fastq", "_clean.fastq")
    outm = outpath + pair[0].rsplit("/", 1)[1].replace(".fastq", "_badreads.fastq")
    call_BBDUK(in1, in2, out1, out2, outm, ref, params)
#+end_src
**** Align Reads: Bowtie2
For each pair of .fastq read files we create an aligned BAM file.
#+begin_src python
#### Align with Bowtie2 ####

## Funtions

def call_Bowtie2(in1, in2, out, params):
    cmd = "bowtie2 -1 {} -2 {} -S {}" .format(in1, in2, out)
    cmd = cmd+" "+params
    print(cmd)
    sp.call(cmd, shell=True)

## Calls
params = ("-p 4 --very-sensitive --local "
          "-5 4 -3 4 -I 50 -X 200 "
          "-x /home/lucas/Programs/bowtie2-2.3.0-legacy/Pf3D7")

inpath = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Clean_Reads/"
files = [f for f in os.listdir(inpath)if f.endswith("_clean.fastq.gz")]

read1s = sorted([f for f in files if "read1" in f])
read2s = sorted([f for f in files if "read2" in f])

outpath = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Current/"

for pair in zip(read1s, read2s):
    name = pair[0].split("_")[0]

    in1, in2 = inpath+pair[0], inpath+pair[1]
    out = outpath+name+".sam"
    call_Bowtie2(in1, in2, out, params)
#+end_src
**** From SAM to BAM
Convert to human-readable sam format to binary bam format.
#+begin_src python
#### Convert to BAM, sort and index ####

import subprocess as sp
import sys
from tqdm import tqdm

## Functions

def from_sam_to_bam(samfile):
    name = samfile.rsplit(".")[0]
    cmd = "samtools view -bS {} > {}" .format(samfile, name+".bam")
    sp.call(cmd, shell=True)

    ### Erase SAM after creating BAM
    # cmd = "rm {}" .format(samfile)
    # sp.call(cmd, shell=True)

    cmd = "samtools sort {} > {}" .format(name+".bam", name+"_sort.bam")
    sp.call(cmd, shell=True)

    ### Erase bam after creating sortedBAM
    cmd = "rm {}" .format(name+".bam")
    sp.call(cmd, shell=True)

    cmd = "samtools index {} > {}" .format(name+"_sort.bam", name+"_sort.bam.bai")
    sp.call(cmd, shell=True)

    ## Filter only >=q5 reads
    cmd = "samtools view -b -q 5 {} > {}" .format(name+"_sort.bam", name+"_q5_sort.bam")
    sp.call(cmd, shell=True)

## Calls

#indir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Bams/"
indir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/New_Bams/"
samfiles = [f for f in os.listdir(indir) if f.endswith(".sam")]

for f in tqdm(samfiles):
    sam = indir+f
    from_sam_to_bam(sam)

#+end_src
**** Remove Duplicates
We finally use ~RemoveDuplicates~ from the ~PICARD~ suite to prune any
duplicated reads.
#+begin_src python
#### Remove duplicates using GATK MarkDuplicates ####

import os
import subprocess as sp

def remove_duplicates(indir, outdir, bam):

    gatk_path = '/home/lucas/Programs/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar'
    i = indir+bam
    o = outdir+bam.replace(".bam", "_noDup.bam")
    m = outdir+bam.replace(".bam", "_metrics.txt")

    cmd = (f"java -jar {gatk_path} MarkDuplicates "
           "REMOVE_DUPLICATES=true I={} O={} M={}") .format(i, o, m)

    sp.call(cmd, shell=True)


indir = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Bams/'
bams = sorted([b for b in os.listdir(indir) if b.endswith("sort_q5.bam")])
outdir = indir

bams = ['E5HA_ac_renamed_sort_q5.bam']


for bam in bams:
    remove_duplicates(indir, outdir, bam)

#+end_src
*** Coverage Tracks
We use DeepTools to get raw and normalized by input RPKMs per sample.
#+begin_src python :tangle ./Paper_Analysis/Scripts/ChIP_Seq/coverage_tracks.py
import os
from chip_seq_processing import *

wd = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/'
os.chdir(wd)

bamdir = './Bams/'
bams = [b for b in os.listdir(bamdir) if b.endswith('_sort_q5.bam')]
IPs = [f for f in bams if '_me_' in f or '_ac_' in f]
IPs.sort()
inputs = [f for f in bams if '_in_' in f]
inputs.sort()
me_files = [f for f in bams if '_me_' in f]
me_files.sort()
ac_files = [f for f in bams if '_ac_' in f]
ac_files.sort()


#### Get RPKMs ####


wd = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/'
os.chdir(wd)

bamdir = './Bams/'
outdir = './RPKMs_noDup_bs10_smth_200/'

bams = [b for b in os.listdir(bamdir) if b.endswith('_noDup.bam')]

bs = 10
smooth = 200
norm = 'RPKM'

for bam in bams:
    out = outdir+bam.replace('.bam', '_RPKMs.bdg')
    get_RPKMs(bamdir+bam, bs, smooth, norm, outdir)

#### Get normalized by input RPKMs ####

outdir = './RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'
IPs = [b for b in os.listdir(bamdir) if b.endswith('_noDup.bam') and '_in_' not in b]
inputs = [b for b in os.listdir(bamdir) if b.endswith('_noDup.bam') and '_in_' in b]

bs = 10
smooth = 200
norm = 'RPKM'
of = 'bedgraph'
outfld = outdir
pseudo = 10
num_process = 8

for ip in IPs:
    prefix = ip.split('_')[0]
    inpt = [f for f in inputs if prefix in f][0]
    print(ip, inpt)

    get_RPKMs_normInput(
        bamdir+ip,
        bamdir+inpt,
        bs,
        smooth,
        norm,
        of,
        outfld,
        pseudo
    )
#+end_src
** MACS2 Individual Peak calling
*** Call Peaks
We use MACS2 to make the peak-calling for all samples.
#+begin_src python :tangle ./Paper_Analysis/Scripts/ChIP_Seq/macs2_peakcalling.py
#### Peak-Calling ####

os.makedirs('./Peak_Calling_MACS2', exist_ok=True)
outdir = './Peak_Calling_MACS2/'

params_form = ("-f BAMPE -B "
               "-g 2.41e7 "
               "--keep-dup all "
               "--fe-cutoff 1.5 "
               "--nomodel "
               "--extsize 150 "
               "-n {} "
               f"--outdir {outdir}")

for ip in IPs:
    prefix = ip.split('_')[0]
    inpt = [f for f in inputs if prefix in f][0]
    print(ip, inpt)
    pair = [ip, inpt]

    t = bamdir + pair[0]
    c = bamdir + pair[1]
    name = pair[0].split("_")[0]+'_'+pair[0].split("_")[1]+"_Macspeaks"
    params = params_form .format(name)

    macs2callpeak(t, c, params)

    print("==============================")
    print("Finished {}!" .format(name))
    print("==============================\n\n\n")
#+end_src
*** Parse MACS2 peaks for Supp. Table
#+begin_src R
library(tidyverse)

wd <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Peak_Calling_MACS2/'
setwd(wd)

me_peaks <- list.files(wd, pattern = '.*_me_.*annotated.csv')
info_df <- read_tsv(
  '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Output_Tables/info_df.tsv'
)

peaks_file <- me_peaks[1]

## Make tables for supplementary
parse_peaks_for_sup_table <- function(peaks_file){

  outname <- gsub('.csv', '_for_supp_table.tsv', peaks_file)

  cnms <- c(
    'Chrom', 'Start', 'Stop',
    'Peak', 'Score', 'Strand',
    'Fold-Enrichment', '-log10(pvalue)', '-log10(qvalue)',
    'Peak_Point-Source',
    'Gene_id', 'Annot'
  )

  peaks_file %>%
    read_tsv(col_names = cnms) %>%
    select(-Score, -Strand, -`Peak_Point-Source`) %>%
    left_join(info_df %>% select(Gene_id, Variant), by = 'Gene_id') %>%
    rename(`CVG` = Variant) %>%
    write_tsv(outname)
}

for (f in me_peaks) {parse_peaks_for_sup_table(f)}

## Make summary for supplementary

get_npeaks <- function(peaks_file){
  peaks_file %>%
    read_tsv(col_names = cnms) %>%
    nrow()
}

get_ngenes <- function(peaks_file){
  gids <- peaks_file %>%
    read_tsv(col_names = cnms) %>%
    pull(Gene_id) %>%
    unique()
  gids <- gids[gids != 'intergenic']
  return(length(gids))
}

get_strain <- function(peaks_file){
  str_split(peaks_file, '_')[[1]][1]
}

strains <- sapply(me_peaks, get_strain)
npeaks <- sapply(me_peaks, get_npeaks)
ngenes <- sapply(me_peaks, get_ngenes)

sum_table <- tibble(Strains = strains, Num_Peaks = npeaks, Num_Genes = ngenes) %>%
  write_tsv('macs2_peaks_summary_table.tsv')
#+end_src
** Correlations between ChIPs
*** Norm by input corrs (python)
#+begin_src python :tangle ./Paper_Analysis/Scripts/ChIP_Seq_Correlations/chip_seq_correlations_normInput.py
#### Calculate correlations between ChIP Coverage ####

import os
import pybedtools as pb
import subprocess as sp
import pandas as pd
from itertools import combinations
from scipy.stats.stats import pearsonr

#### FUNCTIONS ####

def get_bdg_cov(bdg_file, cov_col):
    bed = pb.BedTool(bdg_file)
    ## Get coverage (from cov_col)
    cov = [float(feat.fields[cov_col]) for feat in bed]
    return(cov)

def make_union_bed(indir, bed1, bed2, out_fld):
    if not out_fld.endswith('/'):
        out_fld = out_fld+'/'
    b1 = indir+bed1
    b2 = indir+bed2
    id1 = bed1.rsplit('.', 1)[0]
    id2 = bed2.rsplit('.', 1)[0]
    outfile = out_fld+f'union_{id1}_{id2}.bdg'
    cmd = ['bedtools', 'unionbedg', '-i', b1, b2, '>', outfile]
    sp.call(' '.join(cmd), shell = True)

#### CALLS ####

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/ChIP_Seq_Correlations/'
os.chdir(wd)

bdg_fld = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'

me_fls = [
    '1.2B_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    '10G_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'A7K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'B11_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'E5K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg'
    ]

ac_fls = [
    '1.2B_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    '10G_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'B11_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
]

## We first create "union beds" so that coverage is calculated for the same exact bins in both samples.
union_dir = './Union_Beds_NormInput/'
os.makedirs(union_dir, exist_ok=True)

for pair in combinations(me_fls, 2):
    print(pair)
    make_union_bed(bdg_fld, pair[0], pair[1], union_dir)

for pair in combinations(ac_fls, 2):
    print(pair)
    make_union_bed(bdg_fld, pair[0], pair[1], union_dir)

union_beds_me = sorted([b for b in os.listdir(union_dir) if '_me_' in b])
union_beds_ac = sorted([b for b in os.listdir(union_dir) if '_ac_' in b])

## Now we can calculate correlations for pairs of samples.

## Me
corrs = {}
for u_bed in union_beds_me:
    name = u_bed.replace('union_', '').replace('_me_sort_q5_RPKMs_normInput', '').replace('.bdg', '')
    cov1 = get_bdg_cov(union_dir+u_bed, 3)
    cov2 = get_bdg_cov(union_dir+u_bed, 4)
    corr = pearsonr(cov1,cov2)
    corrs[name] = corr

## Create Correlation Mtx
corr_with = [
    '1.2B',
    '10G',
    'A7',
    'E5',
    'B11',
]

cols_dict = {}
for track in corr_with:
    cols_dict[track] = {key:None for key in corr_with}
    for k in cols_dict[track].keys():
        if k == track:
            cols_dict[track][k] = 1
        else:
            for kk, v in corrs.items():
                if (track in kk and k in kk):
                    cols_dict[track][k] = v[0]

corr_df = pd.DataFrame.from_dict(cols_dict)
corr_df.to_csv('norm_by_input_corrs.csv')

## Ac
corrs = {}
for u_bed in union_beds_ac:
    name = u_bed.replace('union_', '').replace('_me_sort_q5_RPKMs_normInput', '').replace('.bdg', '')
    cov1 = get_bdg_cov(union_dir+u_bed, 3)
    cov2 = get_bdg_cov(union_dir+u_bed, 4)
    corr = pearsonr(cov1,cov2)
    corrs[name] = corr

## Create Correlation Mtx
corr_with = [
    '1.2B',
    '10G',
    'B11',
]

cols_dict = {}
for track in corr_with:
    cols_dict[track] = {key:None for key in corr_with}
    for k in cols_dict[track].keys():
        if k == track:
            cols_dict[track][k] = 1
        else:
            for kk, v in corrs.items():
                if (track in kk and k in kk):
                    cols_dict[track][k] = v[0]

corr_df = pd.DataFrame.from_dict(cols_dict)
corr_df.to_csv('norm_by_input_ac_corrs.csv')


## Met vs Ac
bdg_fld = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'

me_fls = [
    '1.2B_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    '10G_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'B11_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    ]

ac_fls = [
    '1.2B_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    '10G_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'B11_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
]

union_dir = './Union_Beds_NormInput/'
os.makedirs(union_dir, exist_ok=True)

for pair in zip(me_fls, ac_fls):
    print(pair)
    make_union_bed(bdg_fld, pair[0], pair[1], union_dir)

union_beds_me_ac = sorted([b for b in os.listdir(union_dir) if '_me_' in b and '_ac_' in b])

## Me
corrs = {}
for u_bed in union_beds_me_ac:
    name = u_bed.replace('union_', '').replace('_me_sort_q5_RPKMs_normInput', '').replace('.bdg', '')
    cov1 = get_bdg_cov(union_dir+u_bed, 3)
    cov2 = get_bdg_cov(union_dir+u_bed, 4)
    corr = pearsonr(cov1,cov2)
    corrs[name] = corr

pd.DataFrame(corrs).T.to_csv('norm_by_input_me_ac_corrs.csv')
#+end_src
*** Calculate Mean/Max/Min
#+begin_src R
## Norm by input corrs
library(tidyverse)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/ChIP_Seq_Correlations/'
setwd(wd)

## Ac
corr_df_ac <- read_csv('./norm_by_input_ac_corrs.csv') %>%
  rename(Corr_With = `...1`)

x <- corr_df_ac %>%
  select(-Corr_With)

mean(x[lower.tri(x, diag = FALSE)])
max(x[lower.tri(x, diag = FALSE)])
min(x[lower.tri(x, diag = FALSE)])

## Me-ac
corr_df_me_ac <- read_csv('./norm_by_input_me_ac_corrs.csv') %>%
  set_names(c('Contrast', 'PearsonR', 'Pval'))

mean(corr_df_me_ac$PearsonR)
max(corr_df_me_ac$PearsonR)
min(corr_df_me_ac$PearsonR)

#+end_src
*** Plot NormInput Heatmap using ggplot2
#+begin_src R :tangle ./Paper_Analysis/Scripts/ChIP_Seq_Correlations/correlation_heatmap_normInput.R
#### Plot heatmap ####

library(tidyverse)
library(reshape2)

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/ChIP_Seq_Correlations/'
setwd(wd)

## Norm by input corrs
corr_df <- read_csv('./norm_by_input_corrs.csv') %>%
  rename(Corr_With = `...1`)

x <- corr_df %>%
    select(-Corr_With)

mean(x[lower.tri(x, diag = FALSE)])
max(x[lower.tri(x, diag = FALSE)])
min(x[lower.tri(x, diag = FALSE)])

## Plot correlations
m_corr_df <- pivot_longer(corr_df, cols = !Corr_With)

p <- ggplot(m_corr_df, aes(x=Corr_With, y=name, fill=value))
p <- p + geom_tile()
p


reorder_cormat <- function(cormat){
  ## Use correlation between variables as distance
  dd <- as.dist((1-cormat)/2)
  hc <- hclust(dd)
  cormat <-cormat[hc$order, hc$order]
}


corr_mtx <- corr_df %>%
  select(-Corr_With) %>%
  as.matrix()

rownames(corr_mtx) <- corr_df$Corr_With

## Reorder the correlation matrix
sort_corr_mtx <- reorder_cormat(corr_mtx)
m_corr_mtx <- melt(sort_corr_mtx)
head(m_corr_mtx)

p <- ggplot(m_corr_mtx, aes(x=Var1, y=Var2, fill=value))
p <- p + geom_tile()
p <- p + theme(
           axis.title.x=element_blank(),
           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
           axis.title.y=element_blank(),
           legend.position="top"
           )
p <- p + scale_fill_gradient(
           low = "yellow",
           high = "red",
           limits = c(0.7,1),
           name = 'Correlation',
           )
p

ggsave('corr_norm_by_imput.pdf', p, device = 'pdf')





#+end_src
*** Me/Ac/In corrs (python)
#+begin_src python :tangle ./Paper_Analysis/Scripts/ChIP_Seq_Correlations/chip_seq_correlations_raw.py
#### Calculate correlations between ChIP Coverage ####

import os
import pybedtools as pb
import subprocess as sp
import pandas as pd
from itertools import combinations
from scipy.stats.stats import pearsonr

#### FUNCTIONS ####

def get_bdg_cov(bdg_file, cov_col):
    bed = pb.BedTool(bdg_file)
    ## Get coverage (from cov_col)
    cov = [float(feat.fields[cov_col]) for feat in bed]
    return(cov)

def make_union_bed(indir, bed1, bed2, out_fld):
    if not out_fld.endswith('/'):
        out_fld = out_fld+'/'
    b1 = indir+bed1
    b2 = indir+bed2
    id1 = bed1.rsplit('.', 1)[0]
    id2 = bed2.rsplit('.', 1)[0]
    outfile = out_fld+f'union_{id1}_{id2}.bdg'
    cmd = ['bedtools', 'unionbedg', '-i', b1, b2, '>', outfile]
    sp.call(' '.join(cmd), shell = True)

#### CALLS ####

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/ChIP_Seq_Correlations/'
os.chdir(wd)

bdg_fld = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_noDup_bs10_smth_200/'
me_fls = [
    '1.2B_me_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    '10G_me_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    'A7K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    'B11_me_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    'E5K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
]
ac_fls = [
    '1.2B_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    '10G_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    'B11_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
]
in_files = [
    '1.2B_in_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    '10G_in_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    'A7K9_in_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    'B11_in_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
    'E5K9_in_sort_q5_noDup_rpkm_normInput_bs10_smth200.bdg',
]

## We first create "union beds" so that coverage is calculated for the same exact bins in both samples.

union_dir = './Union_Beds/'
os.makedirs(union_dir, exist_ok=True)

for pair in combinations(me_fls+ac_fls+in_files, 2):
    print(pair)
    make_union_bed(bdg_fld, pair[0], pair[1], union_dir)

union_beds = sorted(os.listdir(union_dir))

## Now we can calculate correlations for pairs of samples.

corrs = {}
for u_bed in union_beds:
    name = u_bed.replace('union_', '').replace('.bdg', '')
    print(name)
    cov1 = get_bdg_cov(union_dir+u_bed, 3)
    cov2 = get_bdg_cov(union_dir+u_bed, 4)
    corr = pearsonr(cov1,cov2)
    corrs[name] = corr

## Create Correlation Mtx
corr_with = [
    '1.2B_ac', '1.2B_me', '1.2B_in',
    '10G_ac', '10G_me', '10G_in',
    'A7K9_me', 'A7K9_in',
    'E5K9_me', 'E5K9_in',
    'B11_ac', 'B11_me', 'B11_in'
]

cols_dict = {}
for track in corr_with:
    cols_dict[track] = {key:None for key in corr_with}
    for k in cols_dict[track].keys():
        if k == track:
            cols_dict[track][k] = 1
        else:
            for kk, v in corrs.items():
                if (track in kk and k in kk):
                    cols_dict[track][k] = v[0]

corr_df = pd.DataFrame.from_dict(cols_dict)
corr_df.to_csv('met_ac_in_corrs.csv')
#+end_src
*** Plot Me/Ac/In Heatmap using ggplot2
#+begin_src R :tangle ./Paper_Analysis/Scripts/ChIP_Seq_Correlations/correlation_heatmap_raw.R
#### Plot heatmap ####
library(tidyverse)
library(reshape2)

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/ChIP_Seq_Correlations/'
setwd(wd)

## Ac/Me/In corrs
corr_df <- read_csv('./met_ac_in_corrs.csv') %>%
  rename(Corr_With = `...1`)

x <- corr_df %>%
  filter(grepl('_me', Corr_With)) %>%
  select(contains('_me'))
x

mean(x[lower.tri(x, diag = FALSE)])
max(x[lower.tri(x, diag = FALSE)])
min(x[lower.tri(x, diag = FALSE)])

## Plot correlations
m_corr_df <- pivot_longer(corr_df, cols = !Corr_With)

p <- ggplot(m_corr_df, aes(x=Corr_With, y=name, fill=value))
p <- p + geom_tile()
p


reorder_cormat <- function(cormat){
  ## Use correlation between variables as distance
  dd <- as.dist((1-cormat)/2)
  hc <- hclust(dd)
  cormat <-cormat[hc$order, hc$order]
}


corr_mtx <- corr_df %>%
  select(-Corr_With) %>%
  as.matrix()

rownames(corr_mtx) <- corr_df$Corr_With

## Reorder the correlation matrix
sort_corr_mtx <- reorder_cormat(corr_mtx)
m_corr_mtx <- melt(sort_corr_mtx)
head(m_corr_mtx)

p <- ggplot(m_corr_mtx, aes(x=Var1, y=Var2, fill=value))
p <- p + geom_tile()
p <- p + theme(
           axis.title.x=element_blank(),
           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
           axis.title.y=element_blank(),
           legend.position="top"
         )
p <- p + scale_fill_gradient2(
           low = "yellow",
           high = "red",
           midpoint = 0,
           limits = c(-1,1),
           name = 'Correlation'
         )
p

ggsave('corr_met_ac_in_input.pdf', p, device = 'pdf')
#+end_src
** Gene model
:PROPERTIES:
:header-args:python: :tangle ./Paper_Analysis/Scripts/ChIP_Seq/get_gene_model_coverage.py
:END:
*** Binned Gene-Model (fig. 4), description
We will construct a gene model for downstream analysis. The gene model consists
in an array with 23 bins for each gene. Each bin represents the following:

- 1-2: Coverage of previous gene 2 (gene previous to previous gene)
- 3-4: Coverage of previous gene 1
- 5-9: Coverage in 5' region (until previous gene)
- 10-14: Coverage in gene body (CDS)
- 15-19: Coverage in 3' region (until next gene)
- 20-21: Coverage of next gene 1
- 22-23: Coverage of next gene 2

The underlying idea is to capture information not only about the gene itself
(and its 5' and 3' regions) but also on the neighboring genes.

*** Create binned bed file for gene model
We define 5' as everything until previous gene and 3' as everithing until next
gene. We also add bins for the 2 prev/post genes.
We will create a bed file from an annotation GFF (from PlasmoDB).
The aim is to create a bed file where each gene is binned according to our gene
model. Once we have the bedfile we will be able to compute coverage on each of
the defined regions of interest.
#+begin_src python
#### Create binned bed file for gene model ####

import os
import pybedtools as py
import numpy as np

def bin_region(start, stop, nbins=10):

    cuts = np.linspace(start, stop, num=(nbins+1), dtype = "int")
    bins = []

    for i in range(0,len(cuts)-1):
        bins.append((cuts[i], cuts[i+1]))

    return(bins)

def genome_to_dict(genome_file):

    chr_sizes = {}

    with open(genome_file) as infile:
        for line in infile:
            vals = line.strip().split()
            chr_sizes[vals[0]] = int(vals[1])

    return(chr_sizes)

def getGeneId(gene_bed):
    gid = gene_bed.fields[8].split(";")[0].replace("ID=", "")
    return(gid)

def elongate_and_bin_GFF(gff, genome, nbins=5):

    # Ensure output is overwritten
    prefix = "/mnt/Disc4T/Projects/PhD_Project/Data/"
    name = gff.rsplit( ".", 1 )[0].rsplit("/", 1)[1]
    sufix = "_bin"+str(nbins)+"_2prevGenes"
    outname = "".join([prefix, name, sufix])+".bed"

    print("Ouput will be written in:\n %s" % outname)

    fl = open(outname, "w+")
    fl.close()

    ## Load genome
    chr_sizes = genome_to_dict(genome)

    ## Load GFF for annotation
    ref = py.BedTool(gff)
    ref = ref.filter(lambda x: x[2] == "gene")
    ref = ref.sort()

    ## Create a variable for number of gene-bis
    gbins = nbins*3

    for gene in ref:

        ## Get gene ID
        gid = getGeneId(gene)
        chrom = gene.chrom
        start = int(gene.start)+1 #Compensate a base (maybe it comes from gff/bed)
        stop = int(gene.stop)

        ## Create a mini-bed for the gene and look for
        ## closest 2 genes before and after it (but not overlapping)
        linebed = "\t".join([gene.chrom, str(gene.start), str(gene.stop)])
        gene_bed = py.BedTool(linebed, from_string=True)

        pregenes = gene_bed.closest(ref, D = "ref", id = True, io = True, k = 2)
        postgenes = gene_bed.closest(ref, D = "ref", iu = True, io = True, k = 2)

        ## Resolve cases in which a gene has none or just one gene after/before it.
        ## In case there is no gene before/after:
        ## Set pre region to gene-start -2000 or start of chrom.
        ## Set post region to gene-stop + 2000 or end of chrom.

        if len(pregenes) == 1:

            pregene = pregenes[0]

            if pregene.fields[3] == ".": #No gene before
                pre_stop = max([start-2000, 0])
                pre_start = pre_stop
                prepre_start, prepre_stop = 0, 0

            else: #Just 1 gene before
                pre_start, pre_stop = pregene.fields[6], pregene.fields[7]
                prepre_start, prepre_stop = 0, 0

        else:

            pre_start, prepre_start = pregenes[0].fields[6], pregenes[1].fields[6]
            pre_stop, prepre_stop = pregenes[0].fields[7], pregenes[1].fields[7]

        if len(postgenes) == 1:

            postgene = postgenes[0]

            if postgene.fields[3] == ".": #No gene after
                post_start = min([stop+2000, chr_sizes[chrom]])
                post_stop = post_start
                postpost_start, postpost_stop = 0, 0

            else: #Just 1 gene after
                post_start, post_stop = postgene.fields[6], postgene.fields[7]
                postpost_start, postpost_stop = 0, 0

        else:

            post_stop, postpost_stop = postgenes[0].fields[7], postgenes[1].fields[7]
            post_start, postpost_start = postgenes[0].fields[6], postgenes[1].fields[6]


        ## Create bins

        prepre_gen_cov = bin_region(int(prepre_start), int(prepre_stop), nbins=2)
        pre_gen_cov = bin_region(int(pre_start), int(pre_stop), nbins=2)

        postpost_gen_cov = bin_region(int(postpost_start), int(postpost_stop), nbins=2)
        post_gen_cov = bin_region(int(post_start), int(post_stop), nbins=2)

        pre = bin_region(int(pre_stop), start, nbins=nbins)
        body = bin_region(start, stop, nbins=nbins)
        post = bin_region(stop, int(post_start), nbins=nbins)

        ## Print output taking into accound strandness
        ## We cannot sort here (reverse if strand is "-")
        ## because we will tabix afterwards.
        ## We create a column for sorting afterwards.

        output = []

        regions = [
            prepre_gen_cov,
            pre_gen_cov,
            pre,
            body,
            post,
            post_gen_cov,
            postpost_gen_cov,
        ]

        if gene.strand == "-":
            order = range(gbins+8, 0, -1)
        else:
            order = range(1, gbins+9)

        i = 0
        for reg in regions:
            for interval in reg:
                output.append([chrom,
                               str(interval[0]),
                               str(interval[1]),
                               gid, str(order[i])])
                i += 1

        for line in output:
            with open(outname, "a+") as outfile:
                outfile.write("\t".join(line)+"\n")


gff = "/mnt/Disc4T/Projects/PhD_Project/Data/PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs.gff"
gen = "/home/lucas/ISGlobal/Gen_Referencies/Pf3D7.genome"

elongate_and_bin_GFF(gff, gen)
#+end_src
*** Cross bed with coverage: gene model
**** BGZIP and TABIX coverage files
#+begin_src python
#### BGZIP and TABIX coverage files ####

import os
import subprocess as sp

wd = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10'
os.chdir(wd)

# cov_files = [
#     'E5K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
#     'A7K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
#     '1.2B_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
#     '10G_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
#     'B11_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg'
# ]

cov_files = [
    '1.2B_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    '10G_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'B11_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg'
]


for f in cov_files:
    outf = f.replace('.bdg', '.bdg.gz')
    cmd = f'bgzip -c -f {f} > {outf}'
    print(cmd)
    sp.call(cmd, shell=True)

gz_files = [f for f in os.listdir() if f.endswith('.bdg.gz') and '_ac_' in f]

for f in gz_files:
    cmd = f'tabix -p bed {f}'
    print(cmd)
    sp.call(cmd, shell=True)
#+end_src
**** Cross Coverage
We will use our binned bed as guide and our generated coverage bdg file as input to calculate average coverage over each bin of interest.
#+begin_src python
#### Cross Coverage data with binned BED file ####

import numpy as np
import pandas as pd
import os
import pybedtools as pb
from collections import defaultdict

wd = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'
os.chdir(wd)

indir = './'
bin_bed = pb.BedTool("/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs_bin5_2prevGenes.bed")

#cov_files = [f for f in os.listdir(indir) if f.endswith(".bdg.gz")]
cov_files = [f for f in os.listdir(indir) if f.endswith(".bdg.gz") and '_ac_' in f]
cov_files

for cov in cov_files:

    #cov = cov_files[0]
    flstr = indir+cov
    cov = pb.BedTool(flstr)
    print(flstr, "Converted to bed!")
    outfile = flstr.replace(".bdg.gz", "_5binned_cov_2prevpost.csv")
    #logfile = outfile.replace(".bed", ".log")
    genevals = defaultdict(list)

    for interval in bin_bed:

        #interval = bin_bed[0]
        gene = interval.name
        pos = interval.score

        # Not all of them have a match!
        try:
            match = cov.tabix_intervals(interval)
            val = np.mean([float(x.fields[3]) for x in match])
            genevals[gene].append((val, pos))

        except:
            pass

    # Rearrange values deppending on strandness (we have to "flip" genes on "-" strand)
    sorted_genevals = {}
    for gene, val in genevals.items():
        svals = sorted(val, key = lambda x:int(x[1]))
        vals = [x[0] for x in svals]
        sorted_genevals[gene] = vals

    # Write output
    df = pd.DataFrame.from_dict(sorted_genevals, orient='index')
    df.to_csv(outfile)
    print("Done with file: {}" .format(flstr))

#+end_src
** Get binned Coverage
*** Create "only_genes_gff"
#+begin_src python :tangle ./Paper_Analysis/Scripts/ChIP_Seq/binned_coverage.py
#### Create "only_genes_gff" ####

import pybedtools as pb
import subprocess as sp
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/'
os.chdir(wd)

# Create genome dict
genome={}
genome_file = './PlasmoDB-46_Pfalciparum3D7_Genome.fasta' #later versions have 5'UTRs and 3'UTRs
with open(genome_file, 'r+') as infile:
    for line in infile:
        if line.startswith('>'):
            linelist = line.strip().split(' | ')
            chrom = linelist[0].replace('>', '')
            seize = linelist[3].replace('length=', '')
            genome[chrom] = (0, int(seize))

# Import GFF
gff_file = './PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs.gff'
gff = pb.BedTool(gff_file)

## Filter genes only
sel = ['gene']
gene_gff = gff.filter(lambda x: x.fields[2] in sel)

## Discard Apicoplast
gene_gff = gene_gff.filter(lambda x: x.chrom != 'Pf3D7_API_v3')
gene_gff.saveas(gff_file.replace('.gff', '_only_genes.gff'))

## Sort Gene-GFF
unsorted = gff_file.replace('.gff', '_only_genes.gff')
sorted = gff_file.replace('.gff', '_only_genes_sorted.gff')
cmd = f'python3 ./gff_sorter.py {unsorted} > {sorted}'
sp.call(cmd, shell=True)

#+end_src
*** Find exceptions
There are a few genes that fall inside another gene (most notably GDV1 falls "inside" GDV1as). Since we usually don't want defined regulatory regions to span over previous/next gene this is a problem for the script. Therefore we will get those genes and put them in an exceptions list were we will allow for overlaps.
#+begin_src python :tangle ./Paper_Analysis/Scripts/ChIP_Seq/binned_coverage.py
#### Find genes that overlap neighboring genes ####

import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/'
os.chdir(wd)

gff = pb.BedTool('./PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs_only_genes_sorted.gff')

exceptions = set()
for idx, gene in enumerate(gff):
    if idx > 0 and idx < len(gff)-1:
        gid = gene.fields[8].split(';')[0].replace('ID=', '')

        if gene.chrom == gff[idx-1].chrom:
            if gene.start < gff[idx-1].stop or gene.stop <= gff[idx-1].stop:
                exceptions.add(gid)
                print(gid)

        if gene.chrom == gff[idx+1].chrom:
            if gene.start >= gff[idx+1].start or gene.stop > gff[idx+1].start:
                exceptions.add(gid)
                print(gid)

with open('gene_exceptions.txt', 'w+') as outfile:
    for gene in exceptions:
        outfile.write(gene+'\n')
#+end_src
*** -1000bp to +500bp
#+begin_src python :tangle ./Paper_Analysis/Scripts/ChIP_Seq/binned_coverage.py
#### Get binned BED for desired genomic regions ####

import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/'
os.chdir(wd)

def get_5prime_ORF_3prime(gff, genome_file, excep_file, fiveP=1000, threeP=1000, orf=[0,500], allowoverlap = False):

    if not allowoverlap:
    ## Get a list of genes that fall inside another gene
        with open(excep_file, 'r+') as f:
            exceptions = [g.strip() for g in f.readlines()]

    ## Create dict with lenght of each chromosome
    genome={}
    with open(genome_file, 'r+') as infile:
        for line in infile:
            if line.startswith('>'):
                linelist = line.strip().split(' | ')
                chrom = linelist[0].replace('>', '')
                seize = linelist[3].replace('length=', '')
                genome[chrom] = (0, int(seize))

    ## Set some variables and start!
    ref = pb.BedTool(gff)
    current_chrom = ''
    ngenes = len(ref)
    str_bed = ''
    first_in_chrom = False
    last_in_chrom = False

    for idx, gene in enumerate(ref):

        ## Get gene id
        gid = gene.fields[8].split(';')[0].replace('ID=', '')

        ## Check Orientation:
        strand = gene.fields[6]

        ## Check if first/last in chromosome
        chrom = gene.chrom

        if current_chrom != chrom:
            first_in_chrom = True

        if idx == ngenes-1:
            ## First check if we are in the last gene!
            last_in_chrom = True
        else:
            if ref[idx+1].chrom != chrom:
                last_in_chrom = True

        ## Set new start5, stop5 and star3, stop3 depending on strand:

        if strand == '+':

            prestart = gene.start-fiveP
            prestop = gene.start
            poststart = gene.stop
            poststop = gene.stop+threeP

        else:
            prestart = gene.start-threeP
            prestop = gene.start
            poststart = gene.stop
            poststop = gene.stop+fiveP

        ## Set ORF start-stop
        if strand == '+':
            orf_start = gene.start + orf[0]
            if orf_start > gene.stop: orf_start = orf_stop -1
            orf_stop = gene.start + orf[1]
            if orf_stop > gene.stop : orf_stop = gene.stop
        else:
            orf_start = gene.stop - orf[1]
            if orf_start < gene.start: orf_start = gene.start
            orf_stop = gene.stop - orf[0]
            if orf_stop < gene.start: orf_stop = gene.start + 1

        if not allowoverlap:
        ## Check overlapp previous gene if +strand or next gene if -strand
        ## Except for genes in exception list

            if gid not in exceptions:
                if first_in_chrom:
                    pass
                else:
                    if prestart < ref[idx-1].stop:
                        prestart = ref[idx-1].stop

                if last_in_chrom:
                    pass
                else:
                    if poststop > ref[idx+1].start:
                        poststop = ref[idx+1].start

        ## Check we dont go < 0
        if prestart < 0: prestart = 0
        if orf_start < 0: orf_start = 0

        ## Check we don't go > chrom length
        if poststop > genome[chrom][1]: poststop = genome[chrom][1]
        if orf_stop > genome[chrom][1]: orf_stop = genome[chrom][1]

        ## Check start always start < stop
        if prestart >= prestop:
            prestop = prestart+1
            print(f'Pre region error! In gene :{gid}')
            print(prestart, prestop)
        if orf_start >= orf_stop:
            print(f'ORF region error! In gene :{gid}')
            print(orf_start, orf_stop)
            orf_stop = orf_start+1
        if poststart >= poststop:
            poststop = poststart+1
            print(f'Post region error! In gene :{gid}')
            print(poststart, poststop)


        ## Reset variables
        first_in_chrom = False
        last_in_chrom = False
        current_chrom = chrom

        ## Prepare output
        presuffix = '_5prime' if strand == '+' else '_3prime'
        postsuffix = '_3prime' if strand == '+' else '_5prime'

        preline = '\t'.join([gene.chrom,
                             str(prestart),
                             str(prestop),
                             gid+presuffix, '.', strand])

        ORFline = '\t'.join([gene.chrom,
                             str(orf_start),
                             str(orf_stop),
                             gid, '.', strand])

        postline = '\t'.join([gene.chrom,
                              str(poststart),
                              str(poststop),
                              gid+postsuffix,'.', strand])

        str_bed += ('\n'.join([preline, ORFline, postline])+'\n')

    ## Convert strig output into bedtools object and return
    out_bed = pb.BedTool(str_bed, from_string=True)
    #out_bed.saveas(f'binned_5prime{fiveP}_ORF_{orf[0]}_{orf[1]}_3prime{threeP}.bed')
    return(out_bed)

ref = './PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs_only_genes_sorted.gff'
excep_file = './gene_exceptions.txt'
genome_file = './PlasmoDB-46_Pfalciparum3D7_Genome.fasta'

fiveP = 1000
threeP = 1000
orf = [0,500]
allowoverlap = False

binned_bed = get_5prime_ORF_3prime(ref, genome_file, excep_file, fiveP, threeP, orf, allowoverlap)
binned_bed.saveas(f'./Binned_Beds/binned_5prime{fiveP}_ORF_{orf[0]}_{orf[1]}_3prime{threeP}_allowoverlap{allowoverlap}.bed')

## Keep only 3' coverage:
file_3_orf_5 = 'binned_5prime1000_ORF_0_500_3prime1000_allowoverlapFalse_new.bed'
outfile = 'binned_3prime1000_allowoverlapFalse_new.bed'

with open(file_3_orf_5, 'r+') as infile:
    with open(outfile, 'w+') as output:
        for line in infile:
            if '_3prime' in line:
                output.write(line.replace('_3prime', ''))

#+end_src
*** Join 1000bp 5p and 500bp of CDS
#+begin_src R
library(tidyverse)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/Binned_Beds/'
setwd(wd)

cov5porf <- read_tsv(
  'binned_5prime1000_ORF_0_500_3prime1000_allowoverlapFalse.bed',
  col_names = c('Chrom', 'Start', 'Stop', 'Gene_id', 'bad', 'Strand')
) %>%
  select(Chrom, Start, Stop, Gene_id)

start_5p <- cov5porf %>%
  filter(grepl('5prime', Gene_id)) %>%
  select(Chrom, Start, Gene_id) %>%
  mutate(Gene_id = gsub('_5prime', '', Gene_id))

end_orf500 <- cov5porf %>%
  filter(!grepl('5prime', Gene_id) & !grepl('3prime', Gene_id)) %>%
  select(Chrom, Stop, Gene_id)

binned_1000_5p_500_orf <- start_5p %>%
  full_join(end_orf500 %>% select(-Chrom), by='Gene_id') %>%
  select(Chrom, Start, Stop, Gene_id) %>%
  mutate(Gene_id = ifelse(Gene_id == 'Custom_PF3D7_0935400_as', 'PF3D7_0935390', Gene_id))

write_tsv(binned_1000_5p_500_orf, 'binned_1000fp_500orf.bed', col_names = F)
#+end_src
** Cross Coverage with bins
We get the mean coverage across the submitted bed regions.
#+begin_src python :tangle ./Paper_Analysis/Scripts/ChIP_Seq/coverage_on_bins.py
#### Calculate coverage over regions defined in a BED file ####

import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/Binned_Beds/'
os.chdir(wd)

genes_bed_fnames = [f for f in os.listdir()]
genes_bed_fnames

## Me coverage
for gb in genes_bed_fnames:
    genes_bed = pb.BedTool(gb)

    cov_path = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'

    cov_tracks = [
        'E5K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
        'A7K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
        '1.2B_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
        '10G_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
        'B11_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg'
    ]

    for track in cov_tracks:
        coverage = pb.BedTool(cov_path+track)
        name = track.split('_')[0]
        print(f'Joining {name} coverage...')
        cov = genes_bed.sort().map(coverage, c = 4, o='mean')
        outname = gb.replace('.bed', '_coverage_')
        cov.saveas(f'../Coverages/{outname}{name}.bed')

## Ac coverage
genes_bed_fnames  = [
    'binned_1000tss_0orf_allowoverlaps_False.bed',
    'binned_0tss_500orf_allowoverlaps_True.bed',
    'binned_3prime1000_allowoverlaps_False.bed'
]

for gb in genes_bed_fnames:
    genes_bed = pb.BedTool(gb)

    cov_path = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'
    cov_tracks = [
        '1.2B_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
        '10G_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
        'B11_ac_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg'
    ]

    for track in cov_tracks:
        coverage = pb.BedTool(cov_path+track)
        name = track.split('_')[0]
        print(f'Joining {name} coverage...')
        cov = genes_bed.sort().map(coverage, c = 4, o='mean')
        outname = gb.replace('.bed', '_coverage_acetylation_')
        cov.saveas(f'../Coverages/{outname}{name}.bed')
#+end_src
** Get Duplicated/Deleted regions
:PROPERTIES:
:header-args:python: :tangle ./Paper_Analysis/Scripts/ChIP_Seq/get_dupl_del_genes.py
:END:
*** Check for Del and Dupl
#+begin_src python
#### Check for Del and Dupl ####

import os
import pybedtools as pb
import numpy as np
import subprocess as sp

##### Functions #####

def add_names(bed, featname):
    i = 1
    str_bed = ''
    for feat in bed:
        newline = [feat.chrom, feat.start, feat.stop, featname+'_'+str(i), feat.name]
        newline = [str(x) for x in newline]
        str_bed += '\t'.join(newline)+'\n'
        i += 1
    outbed = pb.BedTool(str_bed, from_string=True)
    return(outbed)

def set_score_x(feat, x):
        feat.score = x
        return(feat)

def get_dupl_del(bed, fact_up, fact_dw, score_col, mergelen, minlen):

    bedname = bed.rsplit('/', 1)[1]
    print(bedname)
    bed = pb.BedTool(bed)
    cov = [float(feat.fields[score_col]) for feat in bed]

    th_up = np.mean(cov)*fact_up
    th_dw = np.mean(cov)*fact_dw

    thbed_up = bed.filter(lambda x: float(x.name) >= th_up)
    thbed_dw = bed.filter(lambda x: float(x.name) <= th_dw)

    ## Cluster peaks together
    clu_bed_up = thbed_up.merge(d = mergelen, c = 4, o = 'mean')
    clu_bed_dw = thbed_dw.merge(d = mergelen, c = 4, o = 'mean')

    ## Filter peaks by length
    len_bed_up = clu_bed_up.filter(lambda x: float(x.stop) - float(x.start) >= minlen)
    len_bed_dw = clu_bed_dw.filter(lambda x: float(x.stop) - float(x.start) >= minlen)

    ## Add name (and move score to 5th column)

    blueprint = '_bymean_{}_fact_{}_minlen{}_mergelen_{}.bed'

    suffix_up =  blueprint .format('dupl', fact_up, minlen, mergelen)
    outname_up = ddfld+bedname.replace('.bdg', suffix_up)

    suffix_dw = blueprint .format('del', fact_dw, minlen, mergelen)
    outname_dw = ddfld+bedname.replace('.bdg', suffix_dw)

    dupl_bed = add_names(len_bed_up, 'duplication').each(set_score_x, 1).saveas(outname_up)
    del_bed = add_names(len_bed_dw, 'deletion').each(set_score_x, -1).saveas(outname_dw)

    ## Merge dupl and del
    strfact = '{}up_{}dw' .format(fact_up, fact_dw)
    suffix = blueprint .format('dupl_del', strfact, minlen, mergelen)
    outname = ddfld+bedname.replace('.bdg', suffix)
    cmd = f'cat {outname_up} {outname_dw} > {outname}'
    sp.call(cmd, shell = True)

    ## Sort and set score for all features to 1
    outbed = pb.BedTool(outname).sort().saveas(outname)


##### Calls #####

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/'
os.chdir(wd)

ddfld = './Data_Files/Duplication_Deletion_Regions_Mean_Separate_DuplDel/'
os.makedirs(ddfld, exist_ok=True)

rpkms_fld = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_noDup_bs10_smth_200/'

in_files = [f for f in os.listdir(rpkms_fld) if '_in_' in f and f.endswith('.bdg')]

## Params

fact_up = 1.75
fact_dw = 0.1
score_col = 3
mergelen = 200
minlen = 500

for f in in_files:
    get_dupl_del(rpkms_fld+f, fact_up, fact_dw, score_col, mergelen, minlen)
#+end_src
*** Check dupl/del present in ALL strains
#+begin_src python
#### Check dupl/del present in ALL strains ####

## Deletions present in all strains likely represent repetitive regions poorly mapped,
## by the aligner and instead of real deletions.

ddfld = './Data_Files/Duplication_Deletion_Regions_Mean_Separate_DuplDel/'

os.listdir(ddfld)

prefixes = ('1.2B', '10G', 'A7K9', 'E5K9', 'B11')
suffix = '_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200.bed'
files_to_cross = [f for f in os.listdir(ddfld) if f.endswith(suffix) and f.startswith(prefixes)]

##### Join all dupl_del files and select regions dupl/del in ALL samples

str_beds = ' '.join([ddfld+f for f in files_to_cross])
cmd = 'awk \'{print}\' '+f'{str_beds} > {ddfld}allstrains_supl_del.bed'
sp.call(cmd, shell = True)

join_bed = pb.BedTool(ddfld+'allstrains_supl_del.bed').sort()

result = join_bed.genome_coverage(bg=True, g='./Data_Files/Pf3D7.genome')
result.saveas(ddfld+'final_allsrtains_dupl_del.bdg')
filter_bed = result.filter(lambda x: int(x.name) >= 5)
filter_bed.saveas(ddfld+'final_allstrains_dupl_del_>5.bdg')

##### Cross each dupl/del file with the ALLstraisn dupl/del file

## Functions

def check_overlapp_perc(feat, bed, perc_th, exclude = False):
    """
    Check wether "feat" overlaps any feature in "bed" and if the overlapp spans
    >= "perc_th" % of "feat" (in length) If exclude = True keep peaks that don't
    overlapp another.
    """
    is_match = False
    for interval in bed:
        if interval.chrom == feat.chrom:
            # Check overlapp
            if feat.start <= interval.stop and interval.start <= feat.stop:
                #Check percentage overlapp
                bigger_start = max([feat.start, interval.start])
                smaller_end = min([feat.stop, interval.stop])
                perc_overlapp = (smaller_end - bigger_start/len(feat))*100

                if perc_overlapp >= perc_th: is_match = True
            else:
                pass
        else:
            pass

    if exclude: is_match = not is_match
    return(is_match)

## Calls

files_to_cross
perc = 80

## Retain only NON-overlapping peaks

for bed in files_to_cross:

    ref = 'final_allstrains_dupl_del_>5.bdg'
    refbed = pb.BedTool(ddfld+ref)

    outname = bed.replace('.bed', '_filtered.bed')
    bed1 = pb.BedTool(ddfld+bed)
    outbed = bed1.filter(lambda b: check_overlapp_perc(b, refbed, perc, exclude=True))
    outbed.saveas(ddfld+outname)
    print(outname)
#+end_src
*** Cross dupl/del with genes
#+begin_src python
#### Cross dupl/del with genes ####

import os
import pybedtools as pb

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/'
os.chdir(wd)

ddfld = './Data_Files/Duplication_Deletion_Regions_Mean_Separate_DuplDel/'
dupl_del_files = [f for f in os.listdir(ddfld) if f.endswith('_filtered.bed')]

ref_dir = './Data_Files/PlasmoDB-52_Pfalciparum3D7.gff'
gff = pb.BedTool(ref_dir)

types = set([entry.fields[2] for entry in gff])
gene_types = [
    'ncRNA_gene',
    'protein_coding_gene',
    'pseudogene'
]

outdir = ddfld+'/Crossed_with_genes/'
os.makedirs(outdir, exist_ok=True)

for bed_f in dupl_del_files:

    gene_gff = gff.filter(lambda x: x.fields[2] in gene_types)
    print(bed_f)
    outfile = outdir+bed_f.replace('.bed', '_genes.tsv')
    dd_bed = pb.BedTool(ddfld+bed_f)
    cross = dd_bed.intersect(gene_gff, wao = True)

    with open(outfile, 'w+') as out_file:
        for x in cross:
            #print(x)
            if x.fields[5] != '.':
                #print(x)
                attrs_field = x.fields[13].split(';')
                attrs_dict = {x.split('=')[0]:x.split('=')[1] for x in attrs_field}
                out_line = [
                    attrs_dict['ID'],
                    attrs_dict.get('Name', ''),
                    attrs_dict.get('description', '')
                ]
                #print(out_line)
                out_file.write('\t'.join(out_line)+'\n')

#+end_src
*** Make suplementary tables
#+begin_src R
library(tidyverse)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/Duplication_Deletion_Regions_Mean_Separate_DuplDel/'
setwd(wd)


dd_files <- list.files(wd, pattern = 'filtered.bed')

dd_file <- dd_files[1]

make_dupl_del_table <- function(dd_file){

  outname <- gsub('.bed', '_DupDel_table.tsv', dd_file)

  df <- dd_file %>%
    read_tsv(col_names = c('Chrom', 'Start', 'Stop', 'ID', 'Type')) %>%
    mutate(Modification = ifelse(Type == 1, 'duplication', 'deletion')) %>%
    select(-ID, -Type) %>%
    write_tsv(outname)

  ## dupls <- df %>%
  ##   filter(Type == 1) %>%
  ##   select(Chrom, Start, Stop) %>%
  ##   write_tsv(dup_name)

  ## dels <- df %>%
  ##   filter(Type == -1) %>%
  ##   select(Chrom, Start, Stop) %>%
  ##   write_tsv(del_name)
}

for (f in dd_files){make_dupl_del_table(f)}
#+end_src
** Subtelomeres Coverage
*** Create telomeres bed
We manually create a bedfile with temomeric regions for each chromosome.
We define telomere as the region spaning from the star of the chromosome to the first coding gene o from the last coding gene to the end of the chromosome.
*** Cross coverage with telomeres.bed
#+begin_src python
import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/'
os.chdir(wd)

ref_bed = pb.BedTool('./Data_Files/Telomeres/telomeres.bed')

cov_path = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'
cov_tracks = [f for f in os.listdir(cov_path) if '_me_' in f and f.endswith('.bdg')]

cov_tracks

for track in cov_tracks:
    coverage = pb.BedTool(cov_path+track)
    name = track.split('_')[0]
    print(f'Joining {name} coverage...')
    cov = ref_bed.sort().map(coverage, c = 4, o='mean')
    cov.saveas(f'./Data_Files/Telomeres/Coverages/cov_telomeres_{name}.bed')
#+end_src
** Custom Differential Peak-Calling
:PROPERTIES:
:header-args:python: :tangle ./Paper_Analysis/Scripts/ChIP_Seq/call_custom_differential_peaks.py
:END:
*** Call differential Peaks
#+begin_src python
from Custom_Differential_Peak_Calling.dif_peak_calling import *
from itertools import combinations

## Call differential on all samples
## Load MACS2 peaks file and normalized by input coverage

wd = '/mnt/Disc4T/Projects/Miniprojects/Custom_Differential_Peak_Calling/'
os.chdir(wd)

datadir = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/'

macs2_dir = datadir+'/Peak_Calling_MACS2/'
cov_dir = datadir+'/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'

macs2_fls = sorted([f for f in os.listdir(macs2_dir) if f.endswith('narrowPeak') and '_me_' in f])
cov_fls = sorted([f for f in os.listdir(cov_dir) if f.endswith('_pseudo10.bdg') and '_me_' in f])

macs2_fls = [
    '1.2B_me_Macspeaks_peaks.narrowPeak',
    '10G_me_Macspeaks_peaks.narrowPeak',
    'A7K9_me_Macspeaks_peaks.narrowPeak',
    'E5K9_me_Macspeaks_peaks.narrowPeak',
    'B11_me_Macspeaks_peaks.narrowPeak',
]

cov_fls = [
    '1.2B_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    '10G_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'A7K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'E5K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
    'B11_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10.bdg',
]

genome = './Pf3D7.genome'
winsize = 100
stepsize = 100
minprobdif = 0.3
mergedist = 500
minlen = 1000
outfld = f'./DifPeaks_W{winsize}_S{stepsize}_PD{minprobdif}_Mg{mergedist}_Ml{minlen}/'

for c in zip(combinations(macs2_fls, 2), combinations(cov_fls, 2)):
    print(c[0])
    print(c[1])

    peakfile1 = macs2_dir+c[0][0]
    peakfile2 = macs2_dir+c[0][1]
    covfile1 = cov_dir+c[1][0]
    covfile2 = cov_dir+c[1][1]
    prefix1 = c[0][0].split('_')[0]
    prefix2 = c[0][1].split('_')[0]

    get_differential_peaks(
        peakfile1, peakfile2,
        covfile1, covfile2,
        prefix1, prefix2,
        genome, winsize, stepsize,
        minprobdif, mergedist, minlen,
        outfld
    )

#+end_src
*** Annotate differential Peaks
#+begin_src python
#### Annotate differential peaks ####

import pybedtools as pb
import pandas as pd
import os

## Function

def annotate_bed(peaks_bed, ref_bed, ncols, gid_col):

    ref = pb.BedTool(ref_bed)
    ref = ref.sort()

    bed = pb.BedTool(peaks_bed)
    anot = bed.intersect(ref, wao=True)

    parsed_anot = []
    for interval in anot:

        originalfields = interval.fields[0:ncols]

        if interval.fields[ncols] == '.':
            gid = "intergenic"
        else:
            gid = interval.fields[ncols+gid_col-1]

        parsed_anot.append(originalfields + [gid])

    df = pd.DataFrame(parsed_anot)
    outfile = peaks_bed.replace(".bed", "_10005p_500orf_gene_crossed.tsv")
    df.to_csv(outfile, sep="\t", header=False, index=False)

## Calls

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/'
os.chdir(wd)

gff = './Binned_Beds/binned_1000fp_500orf.bed'
peaksdir = './DifPeaks_W100_S100_PD0.3_Mg500_Ml1000/'

ncols = 3
gid_col = 4

filtered_peaks = [f for f in os.listdir(peaksdir) if f.endswith('.bed')]
for f in filtered_peaks:
    annotate_bed(
        peaks_bed = peaksdir+f,
        ref_bed = gff,
        ncols = ncols,
        gid_col = gid_col
    )
#+end_src
*** Count Differential Peaks
#+begin_src R :results none
library(tidyverse)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/DifPeaks_W100_S100_PD0.3_Mg500_Ml1000/'
setwd(wd)

peak_fls <- list.files(pattern = '.*bed$')
peak_dfs <- lapply(peak_fls, function(x) read_tsv(x, col_names=F))
npeaks <- sapply(peak_dfs, function(x) dim(x)[[1]][1])
tibble(File = peak_fls, Npeaks = npeaks)
mean(npeaks)
max(npeaks)
min(npeaks)

annotated <- list.files(pattern = '*crossed.tsv')
annotated_dfs <- lapply(annotated, function(x) read_tsv(x, col_names = F) %>%
                                               filter(X4 != 'intergenic') %>%
                                               distinct(X4)
                        )
npeaks <- sapply(annotated_dfs, function(x) dim(x)[[1]][1])
tibble(File = annotated, Npeaks = npeaks)
mean(npeaks)
max(npeaks)
min(npeaks)

#+end_src
*** Parse Supp Tables
#+begin_src R
library(tidyverse)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/DifPeaks_W100_S100_PD0.3_Mg500_Ml1000/'
setwd(wd)

dif_peaks <- list.files(wd, pattern = 'crossed.tsv')
dif_peaks
info_df <- read_tsv(
  '../../Output_Tables/info_df.tsv'
)

peaks_file <- dif_peaks[1]

## Make tables for supplementary
parse_difpeaks_for_sup_table <- function(peaks_file){

  outname <- gsub('.tsv', '_for_supp_table.tsv', peaks_file)

  cnms <- c(
    'Chrom', 'Start', 'Stop', 'Gene_id'
  )

  peaks_file %>%
    read_tsv(col_names = cnms) %>%
    left_join(info_df %>% select(Gene_id, Annot, Variant), by = 'Gene_id') %>%
    rename(CVG = Variant) %>%
    write_tsv(outname)
}

for (f in dif_peaks) {parse_difpeaks_for_sup_table(f)}

## Make summary for supplementary

get_npeaks <- function(peaks_file){
  peaks_file %>%
    read_tsv(col_names = cnms) %>%
    nrow()
}

get_ngenes <- function(peaks_file){
  gids <- peaks_file %>%
    read_tsv(col_names = cnms) %>%
    pull(Gene_id) %>%
    unique()
  gids <- gids[gids != 'intergenic']
  return(length(gids))
}

get_strain <- function(peaks_file){
  str_split(peaks_file, '_')[[1]][2]
}

strains <- sapply(dif_peaks, get_strain)
npeaks <- sapply(dif_peaks, get_npeaks)
ngenes <- sapply(dif_peaks, get_ngenes)

sum_table <- tibble(Strains = strains, Num_Peaks = npeaks, Num_Genes = ngenes) %>%
  write_tsv('difpeaks_summary_table.tsv')
#+end_src
** Search "De Novo" Peaks
*** Find isolated Peaks
#+begin_src python ./Paper_Analysis/Scripts/ChIP_Seq/search_de_novo_peaks.py
import pybedtools as pb
import subprocess as sp
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/De_Novo_Peaks/'
os.chdir(wd)

## Create common bed reference
peaks_dir = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Peak_Calling_MACS2/'
pfiles = sorted([f for f in os.listdir(peaks_dir) if '_me_' in f and f.endswith('narrowPeak')])
pfiles = [
    '1.2B_me_Macspeaks_peaks.narrowPeak',
    '10G_me_Macspeaks_peaks.narrowPeak',
    'A7K9_me_Macspeaks_peaks.narrowPeak',
    'B11_me_Macspeaks_peaks.narrowPeak',
    'E5K9_me_Macspeaks_peaks.narrowPeak',
]

str_beds = ' '.join([peaks_dir+f for f in pfiles])
cmd = 'awk \'{print}\' '+f'{str_beds} > all_MACS2_peaks.bed'
sp.call(cmd, shell = True)
join_bed = pb.BedTool('all_MACS2_peaks.bed').sort().filter(lambda x: int(x.stop) - int(x.start) > 500).merge().saveas('all_MACS2_peaks_merged.bed')
ref_bed = pb.BedTool('all_MACS2_peaks_merged.bed')


## FUNCTIONS

def check_isolation(pf, dist, minlen):
    out = []
    for idx, peak in enumerate(pf):
        if idx > 0 and idx < len(pf)-1:
            peaklen = peak.stop - peak.start
            d1 = peak.start - pf[idx-1].stop
            d2 =  pf[idx+1].start - peak.stop
            if d1 > dist and d2 > dist and peaklen >= minlen:
                out.append(peak.fields)
    return(out)

def get_isolated_peaks(pf, dist, minlen, mergedist):
    pf = pb.BedTool(pf)

    ## without merging
    peaks = check_isolation(pf, dist, minlen)

    ## after merging
    pf_merged = pf.merge(d=mergedist)
    peaks_merged = check_isolation(pf_merged, dist, minlen)

    return(peaks+peaks_merged)

## CALLS

difpeaks_dir = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/DifPeaks_ProbDif_0.3_Merge_500_Minlen_500/'

## Check isolation in common macs2 peaks
common_isolated = get_isolated_peaks(ref_bed, dist = 5000, minlen = 500, mergedist = 1000)
pb.BedTool(common_isolated).saveas('macs2_common_isolated.bed')

## Cross common isolated with difpeaks

difpeaks_dir = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/Data_Files/DifPeaks_W100_S100_PD0.3_Mg500_Ml1000/'


fls = [f for f in os.listdir(difpeaks_dir) if f.endswith('.bed')]

dif_iso_common = './Dif_Crossed_Isolated_Common/'
os.makedirs(dif_iso_common, exist_ok=True)

for f in fls:
    outname = f.replace('.bed', '_isolated.bed')
    difpeaks = pb.BedTool(difpeaks_dir+f)
    isolated = pb.BedTool('macs2_common_isolated.bed')
    difpeaks.intersect(isolated, wa = True).saveas(dif_iso_common+outname)


## Join all isolated peaks
str_beds = ' '.join([dif_iso_common+f for f in os.listdir(dif_iso_common)])
cmd = 'awk \'{print}\' '+f'{str_beds} > {dif_iso_common}all_dif_isolated_peaks.bed'
sp.call(cmd, shell = True)

## Filter difpeaks by percentage of isolated peak they represent
## We do this to remove difpeaks that overlap large 'isolated peaks'
## which don't really correspond to isolated peaks...

iso = pb.BedTool(f'{dif_iso_common}all_dif_isolated_peaks.bed')
ref = pb.BedTool('macs2_common_isolated.bed')

outname = f'{dif_iso_common}all_dif_isolated_filtered.bed'
iso.sort().intersect(ref.sort(), wa = True, F = 0.5).merge().saveas(outname)

#+end_src
*** Annotate isolated peaks
#+begin_src python ./Paper_Analysis/Scripts/ChIP_Seq/search_de_novo_peaks.py
#### Annotate de novo peaks ####

import pybedtools as pb
import subprocess as sp
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/De_Novo_Peaks/'
os.chdir(wd)

## Annotate peaks
iso_file = './Dif_Crossed_Isolated_Common/all_dif_isolated_filtered_manually_curated.bed'
iso_peaks = pb.BedTool(iso_file)

ref_file = '../Data_Files/PlasmoDB-52_Pfalciparum3D7.gff'
gff = pb.BedTool(ref_file)

types = set([entry.fields[2] for entry in gff])
gene_types = [
    'ncRNA_gene',
    'protein_coding_gene',
    'pseudogene'
]

gene_gff = gff.filter(lambda x: x.fields[2] in gene_types)
outfile = iso_file.replace('.bed', '_annotated.bed')
cross = iso_peaks.intersect(gene_gff, wao = True)

with open(outfile, 'w+') as out_file:
    for x in cross:
        if x.fields[3] != '.':
            attrs_field = x.fields[11].split(';')
            attrs_dict = {
                x.split('=')[0]:x.split('=')[1].replace('+', ' ') for x in attrs_field
            }
            annot = [
                attrs_dict['ID'],
                attrs_dict.get('Name', 'NA'),
                attrs_dict.get('description', 'NA')
            ]
        else:
            annot = ['Intergenic', 'NA', 'NA']

        out_file.write('\t'.join(x.fields[0:3]+annot)+'\n')
#+end_src
** Variant Calling
:PROPERTIES:
:header-args:python: :tangle ./Paper_Analysis/Scripts/Variant_Calling/variant_calling.py
:END:
*** Define Functions
**** Imports
#+begin_src python
#### Imports ####

import subprocess as sp
import os

gatk = '/home/lucas/Programs/gatk-4.1.9.0/gatk'
wd = '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/'
os.chdir(wd)
#+end_src
**** Step -1: Create known sites of variation BED
Since we have no previous information on variants, we use an empty file.
#+begin_src python
### FUNTIONS ####

first = True
with open('./known_SNP.txt', 'r+') as infile:
    with open('known_SNPs.bed', 'w+') as outfile:
        for line in infile:
            if first:
                first = False
            else:
                linelist = line.strip().split('\t')
                chrompos = linelist[1]
                minorallel = linelist[3]
                #print(chrompos)
                chrom, pos = chrompos.split(': ')
                start = int(pos.replace(',', ''))
                outfile.write('\t'.join([chrom,
                                        str(start),
                                        str(start+1),
                                         minorallel])+'\n')

def index_feature_file(feat_file):
    cmd = '{} IndexFeatureFile -I {}' .format(gatk, feat_file)
    sp.call(cmd, shell = True)

index_feature_file('./empty.bed')


#+end_src

#+RESULTS:

**** Step 0: Add read-groups
#+begin_src python
def AddOrReplaceReadGroups(bam):
    output = bam.replace('.bam', '_withRG.bam')
    name = bam.rsplit('.')[0]
    cmd = ("java -jar /home/lucas/Programs/picard.jar "
           "AddOrReplaceReadGroups "
           "-INPUT {} "
           "-OUTPUT {} "
           "-RGID group_{} "
           "-RGLB lib_{} "
           "-RGPL illumina "
           "-RGPU unit1 "
           "-RGSM {}_sample") .format(bam, output, name, name, name)
    sp.call(cmd, shell=True)
#+end_src
**** Step 1: Mark Duplicates (MarkDuplicates, samtools sort)
This second processing step is performed per-sample and consists of identifying read pairs that are likely to have originated from duplicates of the same original DNA fragments through some artifactual processes. These are considered to be non-independent observations, so the program tags all but a single read pair within each set of duplicates, causing the marked pairs to be ignored by default during the variant discovery process. At this stage the reads also need to be sorted into coordinate-order for the next step of the pre-processing. MarkDuplicatesSpark performs both the duplicate marking step and the sort step for this stage of pre-processing. This phase of the pipeline has historically been a performance bottleneck due to the large number of comparisons made between read pairs in a sample so MarkDuplicatesSpark utilizes Apache Spark in order to parallelize the process to better take advantage all available resources. This tool can be run locally even without access to a dedicated Spark cluster.
#+begin_src python
def mark_duplicates(bam):
    outfile = bam.replace('.bam', '_markedDuplicates.bam')
    mtrcsfile = bam.replace('.bam', '_metrics.txt')
    args = [gatk, bam, outfile, mtrcsfile]
    cmd = '{} MarkDuplicates -I {} -O {} -M {}' .format(*args)
    sp.call(cmd, shell=True)

    cmd = 'samtools sort {} -o {}' .format(outfile, outfile)
    sp.call(cmd, shell=True)

#+end_src
**** Step 2: Base Recalibration (BaseRecalibrator, ApplyRecalibration)
This third processing step is performed per-sample and consists of applying machine learning to detect and correct for patterns of systematic errors in the base quality scores, which are confidence scores emitted by the sequencer for each base. Base quality scores play an important role in weighing the evidence for or against possible variant alleles during the variant discovery process, so it's important to correct any systematic bias observed in the data. Biases can originate from biochemical processes during library preparation and sequencing, from manufacturing defects in the chips, or instrumentation defects in the sequencer. The recalibration procedure involves collecting covariate measurements from all base calls in the dataset, building a model from those statistics, and applying base quality adjustments to the dataset based on the resulting model. The initial statistics collection can be parallelized by scattering across genomic coordinates, typically by chromosome or batches of chromosomes but this can be broken down further to boost throughput if needed. Then the per-region statistics must be gathered into a single genome-wide model of covariation; this cannot be parallelized but it is computationally trivial, and therefore not a bottleneck. Finally, the recalibration rules derived from the model are applied to the original dataset to produce a recalibrated dataset. This is parallelized in the same way as the initial statistics collection, over genomic regions, then followed by a final file merge operation to produce a single analysis-ready file per sample.
#+begin_src python
def base_recalibration(bam):

    outfile = bam.replace('.bam', '_baserecal_table.table')
    known = './empty.bed'
    ref = './ref.fasta'
    args = [gatk, bam, ref, known, outfile]

    cmd = ('{} BaseRecalibrator '
           '-I {} -R {} '
           '--known-sites {} '
           '-O {}') .format(*args)

    sp.call(cmd, shell=True)

def applyBQSR(bam):

    outfile = bam.replace('.bam', '_BQSR.bam')
    recal_table = bam.replace('.bam', '_baserecal_table.table')
    ref = './ref.fasta'
    args = [gatk, bam, ref, recal_table, outfile]

    cmd = ('{} ApplyBQSR '
           '-I {} -R {} '
           '--bqsr-recal-file {} '
           '-O {}') .format(*args)

    sp.call(cmd, shell=True)

#+end_src

#+RESULTS:
: None

**** Step 3: Merge Bams (MergeSamFiles)
This tool is used for combining SAM and/or BAM files from different runs or read groups into a single file, similar to the \"merge\" function of Samtools (http://www.htslib.org/doc/samtools.html).

Note that to prevent errors in downstream processing, it is critical to identify/label read groups appropriately. If different samples contain identical read group IDs, this tool will avoid collisions by modifying the read group IDs to be unique. For more information about read groups, see the GATK Dictionary entry.
#+begin_src python
def mergeBams(*bams, out):
    nbams = len(bams)
    inputs = '-I {} '*nbams
    cmd = 'java -jar /home/lucas/Programs/picard.jar ' \
        'MergeSamFiles ' + \
        inputs .format(*bams) + \
        '-O {}.bam' .format(out)
    sp.call(cmd, shell=True)


#+end_src

#+RESULTS:
: None

**** Step 3: Call Variants (Haplotype caller)
Call germline SNPs and indels via local re-assembly of haplotypes

The HaplotypeCaller is capable of calling SNPs and indels simultaneously via local de-novo assembly of haplotypes in an active region. In other words, whenever the program encounters a region showing signs of variation, it discards the existing mapping information and completely reassembles the reads in that region. This allows the HaplotypeCaller to be more accurate when calling regions that are traditionally difficult to call, for example when they contain different types of variants close to each other. It also makes the HaplotypeCaller much better at calling indels than position-based callers like UnifiedGenotyper.

In the GVCF workflow used for scalable variant calling in DNA sequence data, HaplotypeCaller runs per-sample to generate an intermediate GVCF (not to be used in final analysis), which can then be used in GenotypeGVCFs for joint genotyping of multiple samples in a very efficient way. The GVCF workflow enables rapid incremental processing of samples as they roll off the sequencer, as well as scaling to very large cohort sizes (e.g. the 92K exomes of ExAC).

In addition, HaplotypeCaller is able to handle non-diploid organisms as well as pooled experiment data. Note however that the algorithms used to calculate variant likelihoods is not well suited to extreme allele frequencies (relative to ploidy) so its use is not recommended for somatic (cancer) variant discovery. For that purpose, use Mutect2 instead.

How HaplotypeCaller works

1. Define active regions

The program determines which regions of the genome it needs to operate on (active regions), based on the presence of evidence for variation.
2. Determine haplotypes by assembly of the active region

For each active region, the program builds a De Bruijn-like graph to reassemble the active region and identifies what are the possible haplotypes present in the data. The program then realigns each haplotype against the reference haplotype using the Smith-Waterman algorithm in order to identify potentially variant sites.

3. Determine likelihoods of the haplotypes given the read data

For each active region, the program performs a pairwise alignment of each read against each haplotype using the PairHMM algorithm. This produces a matrix of likelihoods of haplotypes given the read data. These likelihoods are then marginalized to obtain the likelihoods of alleles for each potentially variant site given the read data.

4. Assign sample genotypes

For each potentially variant site, the program applies Bayes' rule, using the likelihoods of alleles given the read data to calculate the likelihoods of each genotype per sample given the read data observed for that sample. The most likely genotype is then assigned to the sample.

Input

Input bam file(s) from which to make variant calls

Output

Either a VCF or GVCF file with raw, unfiltered SNP and indel calls. Regular VCFs must be filtered either by variant recalibration (Best Practice) or hard-filtering before use in downstream analyses. If using the GVCF workflow, the output is a GVCF file that must first be run through GenotypeGVCFs and then filtering before further analysis.

#+begin_src python
def call_variants(bam):
    outfile = bam.replace('.bam', '_variants.vcf')
    ref = './ref.fasta'
    args = [gatk, ref, bam, outfile]

    cmd = ('{} --java-options "-Xmx4g" HaplotypeCaller '
           '-R {} -I {} -O {} -ploidy 1') .format(*args)

    sp.call(cmd, shell=True)
#+end_src

#+RESULTS:
: None

**** Step 4: Annotate variants (VEP)
We will use ~vep~ from [[https://www.ensembl.org/info/docs/tools/vep/index.html]]
~vep~ will give us annotations on both the nearest gene to a variant and the
genetic effects of it (synonymous/missense/stop_codon...).
Since P.Falciparum is not among the available species we will have to use a
custom annotation file.
For ~vep~ to be able to use it, the GFF file must be chromosome sorted and tabix
indexed and biotype annotations must be added.
We choose vcf output to retain it's information (allele freq, read depth...).
***** Create custom GFF (for VEP)
#+begin_src python :tangle ./Paper_Analysis/Scripts/Variant_Calling/create_custom_gff_for_VEP.py :eval never
import pybedtools as pb
import subprocess as sp
import os

outfld = "/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/"
os.chdir(outfld)

# Filter out lines that do not correspond to genes
gff = pb.BedTool("../Data/PlasmoDB-52_Pfalciparum3D7.gff")

types = [feat.fields[2] for feat in gff]
set(types)


# Add biotype info to transcripts (it is a VEP requisite)
biotypes = {
    "mRNA": "protein_coding",
    "ncRNA": "ncRNA",
    "rRNA": "rRNA",
    "snoRNA": "snoRNA",
    "snRNA": "snRNA",
    "tRNA": "tRNA",
    "five_prime_UTR": "five_prime_UTR",
    "three_prime_UTR": "three_prime_UTR",
    "pseudogenic_transcript": "pseudogenic_transcript"
}

def add_biotype(feature):
    if feature.fields[2] in biotypes.keys():
        feature.attrs["biotype"] = biotypes[feature.fields[2]]
    return(feature)

added_biotype = gff.each(add_biotype)

# Sort GFF

added_biotype.sort().saveas("PlDB-52_Pfalciparum3D7_vep.gff")

# Change type from "protein_coding_gene" to "gene"

types = ['ncRNA_gene', 'protein_coding_gene']

with open("PlDB-52_Pfalciparum3D7_vep.gff", 'r+') as infile:
    with open("PlDB-52_Pfalciparum3D7_vep_changetypes.gff", 'w+') as outfile:
        for line in infile:
            linelist = line.strip().split('\t')
            if linelist[2] in types:
                linelist[2] = 'gene'
            outfile.write('\t'.join(linelist)+'\n')

# Compress GFF
cmd = "bgzip PlDB-52_Pfalciparum3D7_vep_changetypes.gff"
sp.call(cmd, shell=True)

# Tabix GFF
cmd = "tabix -p gff PlDB-52_Pfalciparum3D7_vep_changetypes.gff.gz"
sp.call(cmd, shell=True)
#+end_src

***** Run VEP
#+begin_src python :tangle ./Paper_Analysis/Scripts/Variant_Calling/variant_calling.py
def call_VEP(vcf, gff, fasta):

    out = vcf.replace('.vcf', '_VEPannotated.txt')
    args = [vcf, out, gff, fasta]

    cmd = ("/home/lucas/Programs/ensembl-vep/vep "
           "-i {} "
           "-o {} "
           "--gff {} "
           "--fasta {} "
           "--force_overwrite "
           "--vcf") .format(*args)

    sp.call(cmd, shell=True)

#+end_src

#+RESULTS:
: None

*** Calls
#+begin_src python
#### CALLS ####

import os
import subprocess as sp

wd = '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/'
os.chdir(wd)

gatk = '/home/lucas/Programs/gatk-4.1.9.0/gatk'
indir = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Bams/'

os.listdir(indir)

bams = ['1.2B_in_sort_q5.bam',
        '10G_in_sort_q5.bam',
        'A7K9_in_sort_q5.bam',
        'E5K9_in_sort_q5.bam',
        'B11_in_sort_q5.bam'
        #'NF54_in_renamed_q5_sort.bam',
        ]

for bam in bams:
    bam = indir+bam

    AddOrReplaceReadGroups(bam)
    bam = bam.replace('.bam', '_withRG.bam')

    mark_duplicates(bam)
    bam = bam.replace('.bam', '_markedDuplicates.bam')

    base_recalibration(bam)
    applyBQSR(bam)
    bam = bam.replace('.bam', '_BQSR.bam')


bamlist = [f for f in os.listdir(indir) if f.endswith('_withRG_markedDuplicates_BQSR.bam')]

os.chdir(indir)
mergeBams(*bamlist, out = 'merged_12B_10G_A7_E5_B11')

bam = 'merged_12B_10G_A7_E5_B11.bam'
sp.call('samtools index {}' .format(bam), shell=True)
call_variants(bam)

os.chdir(wd)
vcf = './merged_12B_10G_A7_E5_B11_variants.vcf'
gff = './PlDB-52_Pfalciparum3D7_vep_changetypes.gff.gz'
fasta = './ref.fasta'
call_VEP(vcf, gff, fasta)

#+end_src

*** Parsing and Filtering
**** Step 5: Parse VEP output and annotate
#+begin_src python :tangle ./Paper_Analysis/Scripts/Variant_Calling/parse_VEP.py
import pybedtools as pb
import pandas as pd
import numpy as np
import os
from itertools import chain

project_path = "/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/"
os.chdir(project_path)

vep = pb.BedTool("merged_12B_10G_A7_E5_B11_variants_VEPannotated.txt")
gff = pb.BedTool("PlDB-52_Pfalciparum3D7_vep_changetypes.gff.gz")

# Create dict for annotation (from GFF)
gff_gene = gff.filter(lambda x: x[2] in ["gene", "pseudogene"])

def getAnnot(gffentry):

    info = gffentry.fields[8].split(";")
    dinfo = {x.split('=')[0]:x.split('=')[1] for x in info}
    gid = dinfo['ID']
    anot = dinfo['description']
    return([gid, anot])

annot = {}
for entry in gff_gene:
    ga = getAnnot(entry)
    annot[ga[0]] = ga[1]

def getRatioDepth(GF):
    if len(GF) <2:
        rf = np.nan
        alt = np.nan
        ratio = np.nan
        dp = 0
    else:
        rf = int(GF[1].split(",")[0])
        alt = int(GF[1].split(",")[1])
        dp = rf+alt

        if dp == 0:
            ratio = np.nan
        else:
            ratio = round(rf / dp, 2)

    return(rf, alt, ratio, dp)

# Create parsed output

def parse_variant(variant):

    # Parse vcf info
    ref = variant.fields[3]
    alt = variant.fields[4]
    pos = variant.start
    chrom = variant.chrom

    v10G = variant.fields[9].split(":")
    v12B = variant.fields[10].split(":")
    vA7 = variant.fields[11].split(":")
    vB11 = variant.fields[12].split(":")
    vE5 = variant.fields[13].split(":")

    ref_count1, alt_count1, r1, d1 = getRatioDepth(v10G)
    ref_count2, alt_count2, r2, d2 = getRatioDepth(v12B)
    ref_count3, alt_count3, r3, d3 = getRatioDepth(vA7)
    ref_count4, alt_count4, r4, d4 = getRatioDepth(vB11)
    ref_count5, alt_count5, r5, d5 = getRatioDepth(vE5)

    parsed_vcf = [chrom, pos, ref, alt,
                  ref_count1, alt_count1, r1, d1,
                  ref_count2, alt_count2, r2, d2,
                  ref_count3, alt_count3, r3, d3,
                  ref_count4, alt_count4, r4, d4,
                  ref_count5, alt_count5, r5, d5,
                  ]

    # Parse vep info
    info = {}
    for x in variant.fields[7].split(";"):
        feat = x.split("=")
        if len(feat) == 2:
            info[feat[0]] = feat[1]
        else:
            info[feat[0]] = ""

    vep_out = info["CSQ"].split(",")
    effects = [effect.split("|") for effect in vep_out]

    # Add annotation (from GFF)
    for effect in effects:
        gene = effect[4]
        if gene != "":
            gannot = annot[gene]
        else:
            gannot = ""
        effect.append(gannot)

    parsed_variant = [parsed_vcf + effect for effect in effects]

    return(parsed_variant)

# Create DF
colnames = ["Chrom", "Pos", "Ref", "Alt",
            "RefCount_10G", "AltCount_10G", "RefRatio_10G", "depth_10G",
            "RefCount_12B", "AltCount_12B", "RefRatio_12B", "depth_12B",
            "RefCount_A7", "AltCount_A7", "RefRatio_A7", "depth_A7",
            "RefCount_B11", "AltCount_B11", "RefRatio_B11", "depth_B11",
            "RefCount_E5", "AltCount_E5", "RefRatio_E5", "depth_E5",

            "Allele",
            "Consequence",
            "IMPACT",
            "SYMBOL",
            "Gene",
            "Feature_type",
            "Feature",
            "BIOTYPE",
            "EXON",
            "INTRON",
            "HGVSc",
            "HGVSp",
            "cDNA_position",
            "CDS_position",
            "Protein_position",
            "Amino_acids",
            "Codons",
            "Existing_variation",
            "DISTANCE",
            "STRAND",
            "FLAGS",
            "SYMBOL_SOURCE",
            "HGNC_ID",
            "SOURCE",
            "PlDB-52_Pfalciparum3D7_vep.gff.gz",

            "Annot"]


parsed = [parse_variant(var) for var in vep]
flat = list(chain.from_iterable(parsed))
var_df = pd.DataFrame.from_records(flat, columns=colnames)

var_df.to_csv("parsed_variants_new.tsv", sep = '\t')


#+end_src
**** Step 6: Subset Variants DF (dplyr)
#+begin_src R :session parse_variants :tangle ./Paper_Analysis/Scripts/Variant_Calling/parse_variants.R
library(tidyverse)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/'
setwd(wd)

variants <- read_tsv('parsed_variants_new.tsv') %>%
  mutate(Var_id = paste0('Variant_', `...1`)) %>%
  select(Var_id, everything(), `...1`)

parse_variants_bystrain <- function(strain, depth_filter, refratio_filter, impact_filter){
  depthcol <- paste0('depth_', strain)
  ratiocol <- paste0('RefRatio_', strain)
  outname <- paste0('./Parsed_by_Strain/',
                    strain,
                    '_variants_depth_', depth_filter,
                    '_refratio_', refratio_filter,
                    '_impactfilter_', impact_filter,
                    '.tsv'
                    )

  if (impact_filter){
    variants <- variants %>%
      filter(IMPACT == 'HIGH')
  }

  variants %>%
    filter(get(depthcol) >= depth_filter &
           get(ratiocol) <= refratio_filter) %>%
    select(Var_id, contains(strain), Gene, Annot, Consequence,
           Chrom, Pos, Ref, Alt, everything()) %>%
    mutate(Annot = gsub('\"', '', Annot)) %>%
    write_tsv(outname)
}

#### Parse variants per strain

depth_filter <- 20
refratio_filter <- 0.5
impact_filter <- F

strains <- c('12B', '10G', 'A7', 'E5', 'B11')
for (strain in strains){
  parse_variants_bystrain(
    strain, depth_filter, refratio_filter, impact_filter
  )
}

#### Parse variants, all strains together

## depth_filter <- 20
## refratio_filter <- 0.5
## impact_filter <- F

## outname <- paste0(
##   'allstrains_variants_depth_', depth_filter,
##   '_refratio_', refratio_filter,
##   '_impactfilter_', impact_filter,
##   '.tsv'
## )

## filtered_vars <- variants
## if (impact_filter){
##   filtered_vars <- variants %>%
##     filter(IMPACT == 'HIGH')
## }

## filtered_vars <- variants %>%
##   filter(
##   (RefRatio_12B <= refratio_filter & depth_12B >= depth_filter) |
##   (RefRatio_10G <= refratio_filter & depth_10G >= depth_filter) |
##   (RefRatio_A7 <= refratio_filter & depth_A7 >= depth_filter) |
##   (RefRatio_E5 <= refratio_filter & depth_E5 >= depth_filter) |
##   (RefRatio_B11 <= refratio_filter & depth_B11 >= depth_filter)
##   ) %>%
##   select(Chrom, Pos, Ref, Alt, everything()) %>%
##   mutate(Annot = gsub('\"', '', Annot)) %>%
##   write_tsv(outname)

#+end_src
**** Step 7: Collapse variants and keep only nearest annotation per SNP
#+begin_src python :tangle ./Paper_Analysis/Scripts/Variant_Calling/collapse_variants_only_nearest.py
import os
import pybedtools as pb
from collections import defaultdict

## FUNCTIONS

## Get all 'Consequences'

wd = '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/'
os.chdir(wd)
raw_vcf = 'parsed_variants.tsv'

firstline = True
consequences = []
cds_consequences = []
with open(raw_vcf, 'r+') as infile:
    for line in infile:
        ll = line.strip().split('\t')
        if firstline:
            colnames = ll
            firstline = False
        else:
            ll = line.strip().split('\t')[1:] #Skip first col (index)
            ld = {k:v for k, v in zip(colnames, ll)}
            consequences.append(ld['Consequence'])
            if ld.get('DISTANCE') == '':
                cds_consequences.append(ld['Consequence'])
colnames
set(consequences)
set(cds_consequences)
cds_vars = set(cds_consequences)
non_cds_vars = set(consequences) - set(cds_consequences)

## Parse variants

def variants_to_dict(var_file):
    variants = {}
    firstline = True
    i = 1
    with open(var_file, 'r+') as infile:
        for line in infile:
            ll = line.strip().split('\t')
            if firstline:
                colnames = ll
                firstline = False
            else:
                ld = {k:[v] for k, v in zip(colnames, ll)}
                var_id = '_'.join(ld['Chrom']+ld['Pos']+ld['Ref']+ld['Alt'])
                if var_id not in variants.keys():
                    variants[var_id] = ld
                    variants[var_id]['Unique_ID'] = f'Variant_{i}'
                    i += 1
                else:
                    ld = {k:v for k, v in zip(colnames, ll)}
                    for k, v in ld.items():
                        variants[var_id][k].append(v)
    return(variants)

## Filter variants


def filter_variants(var_dict, out_file):
    with open(out_file, 'w+') as outfile:

        ## Header
        outfile.write('Var_ID\t'+'\t'.join(colnames)+'\n')

        for k, v in var_dict.items():
            lmask = [vc in cds_vars for vc in v['Consequence']]
            true_idx = [i for i, x in enumerate(lmask) if x]
            if any(lmask):
                for idx in true_idx:
                    row = []
                    for cn in colnames:
                        row.append(v[cn][idx].replace('\"', ''))
                    outfile.write(v['Unique_ID']+'\t'+'\t'.join(row)+'\n')

            elif v['Consequence'] == ['intergenic_variant']:
                row = [v[cn][0].replace('\"', '') for cn in colnames]
                outfile.write(v['Unique_ID']+'\t'+'\t'.join(row)+'\n')

            elif 'upstream_gene_variant' in v['Consequence'] or 'downstream_gene_variant' in v['Consequence']:
                if 'upstream_gene_variant' in v['Consequence']:
                    up_mask = [vc == 'upstream_gene_variant' for vc in v['Consequence']]
                    true_idx = [i for i, x in enumerate(up_mask) if x]
                    to_sort_up = [int(v['DISTANCE'][idx]) for idx in true_idx]
                    for idx, val in enumerate(v['DISTANCE']):
                        if int(val) == min(to_sort_up):
                            up_idx = idx
                    row = [v[cn][up_idx].replace('\"', '') for cn in colnames]
                    outfile.write(v['Unique_ID']+'\t'+'\t'.join(row)+'\n')

                if 'downstream_gene_variant' in v['Consequence']:
                    down_mask = [vc == 'downstream_gene_variant' for vc in v['Consequence']]
                    true_idx = [i for i, x in enumerate(down_mask) if x]
                    to_sort_down = [int(v['DISTANCE'][idx]) for idx in true_idx]
                    for idx, val in enumerate(v['DISTANCE']):
                        if int(val) == min(to_sort_down):
                            down_idx = idx
                    row = [v[cn][down_idx].replace('\"', '') for cn in colnames]
                    outfile.write(v['Unique_ID']+'\t'+'\t'.join(row)+'\n')

## CALLS

wd = '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/'
os.chdir(wd)

var_fld = './Parsed_by_Strain/'
var_fls = [f for f in os.listdir(var_fld) if f.endswith('FALSE.tsv')]

for f in var_fls:
    vars = variants_to_dict(var_fld+f)
    filter_variants(vars, var_fld+f.replace('.tsv', '_nearest_only.tsv'))

# var_file = 'allstrains_variants_depth_20_refratio_0.5_impactfilter_FALSE.tsv'
# filter_variants(
#     variants_to_dict(var_file),
#     var_file.replace('.tsv', '_nearest_only.tsv')
# )

#+end_src

**** Step 8: Remove variants that overlap deleted regions
#+begin_src python :tangle ./Paper_Analysis/Scripts/Variant_Calling/remove_deleted_regions_variants.py
import os
import pybedtools as pb
from collections import defaultdict

## FUNTIONS

def filter_by_deletions(del_file, vars_file):

    dd = pb.BedTool(del_file)
    dd_del = dd.filter(lambda x: 'deletion' in x.fields[3])

    dels = defaultdict(list)
    for feat in dd_del:
        dels[feat.chrom ].append((feat.start, feat.stop))

    firstline = True
    out = vars_file.replace('.tsv', '_deletions_filtered.tsv')
    with open(vars_file, 'r+') as infile:
        with open(out, 'w+') as outfile:
            for line in infile:
                if firstline:
                    firstline = False
                    outfile.write(line)
                else:
                    linelist = line.split('\t')
                    chr = linelist[8]
                    pos = int(linelist[9])
                    del_regions = dels[chr]
                    in_del = [pos > _del[0] and pos < _del[1] for _del in del_regions]
                    if not any (in_del):
                            outfile.write('\t'.join(linelist))


## CALLS

wd = '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/'
os.chdir(wd)

dupl_del_dir = '../Paper/Paper_Analysis/Data_Files/Duplication_Deletion_Regions_Mean_Separate_DuplDel/'
v_dir = './Parsed_by_Strain/'

dd_files = [    '1.2B_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered.bed',                '10G_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered.bed', 'A7K9_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered.bed', 'B11_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered.bed', 'E5K9_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered.bed'
            ]

v_files = [
    '12B_variants_depth_20_refratio_0.5_impactfilter_FALSE_nearest_only.tsv',
    '10G_variants_depth_20_refratio_0.5_impactfilter_FALSE_nearest_only.tsv',
    'A7_variants_depth_20_refratio_0.5_impactfilter_FALSE_nearest_only.tsv',
    'B11_variants_depth_20_refratio_0.5_impactfilter_FALSE_nearest_only.tsv',
    'E5_variants_depth_20_refratio_0.5_impactfilter_FALSE_nearest_only.tsv'
]

for d, v in zip(dd_files, v_files):
    filter_by_deletions(dupl_del_dir+d, v_dir+v)
#+end_src
**** Step 9: Merge Strains and drop columns
#+begin_src R
library(tidyverse)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/Parsed_by_Strain/'
setwd(wd)
var_files <- list.files(wd, pattern = '_deletions_filtered.tsv')
df_names <- sapply(var_files, function(x) str_split(x, '_')[[1]][1])
var_dfs <- lapply(var_files, function(x) read_tsv(x) %>% select(-Var_ID))
names(var_dfs) <- df_names


colnames(var_dfs[[1]])

all_vars <- var_dfs %>%
  reduce(bind_rows) %>%
  distinct() %>%
  select(
    -HGVSc,
    -HGVSp,
    -Existing_variation,
    -FLAGS,
    -SYMBOL_SOURCE,
    -HGNC_ID,
    -SOURCE,
    -`PlDB-52_Pfalciparum3D7_vep.gff.gz`
  ) %>%
  select(
    Chrom, Pos, Ref, Alt,
    Gene, SYMBOL, Annot,
    Consequence, IMPACT,
    everything()
  ) %>%
  mutate(Annot = gsub('+', ' ', Annot, fixed = T)) %>%
  write_tsv('all_strains_merged_selected_cols.tsv')
#+end_src
**** Step 10: Column filtering for final table
#+begin_src R
library(tidyverse)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/Parsed_by_Strain/'
setwd(wd)

var_files <- list.files(wd, pattern = 'filtered.tsv')

filter_table <- function(vars_file){
  vars_file %>%
    read_tsv() %>%
    select(
      -HGVSc,
      -HGVSp,
      -Existing_variation,
      -FLAGS,
      -SYMBOL_SOURCE,
      -HGNC_ID,
      -SOURCE,
      -`PlDB-52_Pfalciparum3D7_vep.gff.gz`
    ) %>%
    select(Var_ID, Chrom, Pos, Ref, Alt, Gene, Annot, Consequence, everything()) %>%
    mutate(Annot = gsub('+', ' ', Annot, fixed = T)) %>%
    write_tsv(gsub('.tsv', '_col_filter.tsv', vars_file, fixed = T))
}

for (f in var_files){filter_table(f)}
#+end_src
* Joint Analysis of Micro-arrays and ChIP-Seq Data
:PROPERTIES:
:header-args:R: :session paper_analysis :tangle ./Paper_Analysis/Scripts/integrative_microarray_chipseq_analysis_(MAIN_ANALYSIS).R :results none
:END:
** Imports and dirs
#+begin_src R
#### Imports and Dirs ####

library(ggplot2)
library(tidyverse)
library(readxl)
library(reshape2)
require(gridExtra)
library(readxl)
library(ggh4x)
library(ggrepel)
library(tsne)
library(scales)
library(viridis)
library(cluster)
library(NbClust)
library(factoextra)
library(class)
library(eulerr)
library(ggpubr)
library("colorspace")

wd <- '/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/'
setwd(wd)

## Data Dirs
microarrays_dir <- '../../Microarrays/New_Old_separate_approach/'
sicer_dir <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/DiffPeaks_SICER/PhD_Project_Strains/Overlapped_with_MACS2_Peaks/'
dupl_del_dir <- './Data_Files/Duplication_Deletion_Regions_Mean_Separate_DuplDel/Crossed_with_genes/'
coverage_dir <- './Data_Files/Coverages/'
genemodel_dir <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_NormInput_noDup_bs10_smth_200_pseudo_10/'
telomeres_dir <- './Data_Files/Telomeres/Coverages/'

## Output Dirs
tables_dir <- './Output_Tables/'
plots_dir <- './Plots/'


## Create Output Dirs
dir.create(tables_dir)
dir.create(paste0(tables_dir, '/Sicer_no_trans'))

dir.create(plots_dir)
dir.create(paste0(plots_dir, '/Coverage_PCAs'))
dir.create(paste0(plots_dir, '/Correlations_byStrain'))
dir.create(paste0(plots_dir, '/Trans_Het_byStrain'))
dir.create(paste0(plots_dir, 'Transcription_Donuts_ByStrain/'))
dir.create(paste0(plots_dir, 'MaxFC_Cor_Plots/'))
dir.create(paste0(plots_dir, 'Correlations_Intervals/'))
dir.create(paste0(plots_dir, 'Gene_Model/'))
dir.create(paste0(plots_dir, 'Gene_Model/PCAs/'))
dir.create(paste0(plots_dir, 'Gene_Model/Family_Heatmaps/'))
dir.create(paste0(plots_dir, 'Gene_Model/States_OnOff/'))
dir.create(paste0(plots_dir, 'Met_Ac/'))
dir.create(paste0(plots_dir, 'Met_Ac/PCAs/'))
dir.create(paste0(plots_dir, 'Met_Ac/Scatterplots/'))
dir.create(paste0(plots_dir, 'Met_Ac/Boxplots/'))
#+end_src
** Load Data
*** Load Gene info
#+begin_src R
info_df <- read_tsv('./Data_Files/PlasmoDB-52_Pfalciparum3D7_parsed_annotation.tsv')

## Flag tRNAs
info_df <- info_df %>%
  mutate(Is_tRNA = grepl('tRNA', Annot, fixed = T) & Type == 'ncRNA_gene')
#+end_src
*** Load gene families data
#+begin_src R
#### Load gene families data ####

gene_fam <- read_excel('./Data_Files/Supplementary_table_2_CVG_list_161120_ap.xlsx', sheet = 2)
gene_fam <- gene_fam %>%
  rename(Gene_id = `Gene ID`,
         Gene_name = `Gene Name or Symbol`,
         SubFamily = `Family Detail`) %>%
  mutate(SubFamily = case_when(SubFamily == 'var pseudo,truncated or -like.' ~ 'var-like',
                               TRUE ~ SubFamily)) %>%
  mutate(Gene_name = ifelse(Gene_name == 'N/A', NA, Gene_name)) %>%
  select(Gene_id, Gene_name, Family, SubFamily)

gene_fam %>%
  filter(Family == 'OTHER') %>%
  mutate(NewFam = case_when(is.na(SubFamily) ~ Gene_name,
                            !is.na(SubFamily) ~ SubFamily))

bigfams <- c(
  'VAR',
  'FIKK',
  'HYP',
  'PHIST',
  'RIFIN',
  'STEVOR',
  'PFMC-2TM'
)

info_df <- info_df %>%
  left_join(gene_fam) %>%
  mutate(Name = ifelse(is.na(Name), Gene_name, Name)) %>%
  mutate(Name = ifelse(is.na(Name) & Family != 'OTHER', Family, Name)) %>%
  mutate(Name = ifelse(Gene_id == 'PF3D7_0935390', 'GDV1as', Name)) %>%
  mutate(Label = ifelse(is.na(Name), Gene_id, paste(Gene_id, Name, sep = ': '))) %>%
  mutate(Family_Grouped = case_when(
           Family %in% bigfams ~ Family,
           !is.na(Family) & !Family %in% bigfams ~ 'Other CVGs',
           Gene_id == 'PF3D7_0935390' ~ 'Other CVGs',
           is.na(Family) ~ 'Not CVGs'))

table(info_df$Name == info_df$Gene_name)

info_df %>%
  filter(Name != Gene_name) %>%
  select(Gene_id, Name, Gene_name) %>%
  print(n = 40)

#+end_src
*** Load variant genes data
#+begin_src R
#### Load variant genes data ####
cvgs <- read.csv2(paste0(microarrays_dir, 'New_Arrays/Files/taula_CVG_final.csv'), stringsAsFactors = F)
cvgs <- cvgs %>%
  select(Gene_id = Gene.ID, Variant = Final.Customized) %>%
  mutate(Variant = ifelse(Variant == 'YES', TRUE, FALSE))


varlist <- filter(cvgs, Variant) %>% select(Gene_id) %>% pull()
varlist <- c(varlist, 'PF3D7_0935390')

info_df <- info_df %>%
  mutate(Variant = Gene_id %in% varlist)

## Probably Variant
## Some genes are from variant families but we have them as non-variant
info_df %>%
  filter(!Variant & !is.na(Family)) %>%
  select(Gene_id, Annot, Family) %>%
  print(n = 100)

## Check no variant gene has NA Family
info_df <- info_df %>%
  mutate(Family = ifelse(Gene_id == 'PF3D7_0935390', 'GDV1as', Family))

info_df %>%
  filter(Variant & is.na(Family))

#+end_src
*** Load Gam genes data
#+begin_src R
gams <- read_csv(paste0(microarrays_dir, 'Oriol_Suplementary/gam_table.csv')) %>%
  select(Gene_id, Gam_specific)

info_df <- info_df %>%
  left_join(gams)
#+end_src
*** Load DuplDdel Data
#+begin_src R
## Load DuplDel Data
suffix <- '_in_sort_q5_noDup_rpkm_normInput_bs10_smth200_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered_genes.tsv'
prefix <- c('1.2B', '10G', 'A7K9', 'E5K9', 'B11')

get_dupl_del <- function(prefix){
  fname <- paste0(prefix, suffix)
  df <- read_tsv(paste0(dupl_del_dir, fname), col_names = F) %>%
    rename(Gene_id = X1, Name = X2, Annot = X3)
}

dupl_del <- lapply(prefix, get_dupl_del)
names(dupl_del) <- prefix

info_df <- info_df %>%
  mutate(DuplDel_12B = Gene_id %in% dupl_del$`1.2B`$Gene_id) %>%
  mutate(DuplDel_10G = Gene_id %in% dupl_del$`10G`$Gene_id) %>%
  mutate(DuplDel_A7 = Gene_id %in% dupl_del$A7K9$Gene_id) %>%
  mutate(DuplDel_E5 = Gene_id %in% dupl_del$E5K9$Gene_id) %>%
  mutate(DuplDel_B11 = Gene_id %in% dupl_del$B11$Gene_id)
#+end_src
*** Load Differential Peaks
#+begin_src R
#### Load Differential Peaks ####

difpeaks_dir <- './Data_Files/DifPeaks_W100_S100_PD0.3_Mg500_Ml1000/'
remove_transcript <- function(geneid){sub('\\.\\d$', '', geneid)}

difpeak_fls <- list.files(difpeaks_dir, pattern = 'gene_crossed.tsv')

get_peaks <- function(difpeaks_file){
  dp_colnames <- c('Chrom', 'Start', 'Stop', 'Gene_id')
  read_tsv(difpeaks_file, col_names = dp_colnames) %>%
    filter(Gene_id != 'intergenic') %>%
    select(Gene_id) %>%
    pull() %>%
    unique()
}

difpeaks <- lapply(difpeak_fls, function(x) get_peaks(paste0(difpeaks_dir, x)))
difpeaks_name <- function(x){
  paste(str_split(x, '_')[[1]][2], collapse = '_')
}
names(difpeaks) <- sapply(difpeak_fls, difpeaks_name)
difpeaks

difpeaks_df <- info_df %>%
  select(Gene_id) %>%
  mutate(peak_12B_10G = ifelse(Gene_id %in% difpeaks$`1.2Bover10G`, T, F)) %>%
  mutate(peak_12B_A7 = ifelse(Gene_id %in% difpeaks$`1.2BoverA7K9`, T, F)) %>%
  mutate(peak_12B_E5 = ifelse(Gene_id %in% difpeaks$`1.2BoverE5K9`, T, F)) %>%
  mutate(peak_12B_B11 = ifelse(Gene_id %in% difpeaks$`1.2BoverB11`, T, F)) %>%

  mutate(peak_10G_12B = ifelse(Gene_id %in% difpeaks$`10Gover1.2B`, T, F)) %>%
  mutate(peak_10G_A7 = ifelse(Gene_id %in% difpeaks$`10GoverA7K9`, T, F)) %>%
  mutate(peak_10G_E5 = ifelse(Gene_id %in% difpeaks$`10GoverE5K9`, T, F)) %>%
  mutate(peak_10G_B11 = ifelse(Gene_id %in% difpeaks$`10GoverB11`, T, F)) %>%

  mutate(peak_A7_12B = ifelse(Gene_id %in% difpeaks$`A7K9over1.2B`, T, F)) %>%
  mutate(peak_A7_10G = ifelse(Gene_id %in% difpeaks$`A7K9over10G`, T, F)) %>%
  mutate(peak_A7_E5 = ifelse(Gene_id %in% difpeaks$`A7K9overE5K9`, T, F)) %>%
  mutate(peak_A7_B11 = ifelse(Gene_id %in% difpeaks$`A7K9overB11`, T, F)) %>%

  mutate(peak_E5_12B = ifelse(Gene_id %in% difpeaks$`E5K9over1.2B`, T, F)) %>%
  mutate(peak_E5_10G = ifelse(Gene_id %in% difpeaks$`E5K9over10G`, T, F)) %>%
  mutate(peak_E5_A7 = ifelse(Gene_id %in% difpeaks$`E5K9overA7K9`, T, F)) %>%
  mutate(peak_E5_B11 = ifelse(Gene_id %in% difpeaks$`E5K9overB11`, T, F)) %>%

  mutate(peak_B11_12B = ifelse(Gene_id %in% difpeaks$`B11over1.2B`, T, F)) %>%
  mutate(peak_B11_10G = ifelse(Gene_id %in% difpeaks$`B11over10G`, T, F)) %>%
  mutate(peak_B11_A7 = ifelse(Gene_id %in% difpeaks$`B11overA7K9`, T, F)) %>%
  mutate(peak_B11_E5 = ifelse(Gene_id %in% difpeaks$`B11overE5K9`, T, F))

## Check Peaks that appear in both strains at the same time
sub_combs <- list(
  c('12B', '10G'),
  c('12B', 'A7'),
  c('12B', 'E5'),
  c('12B', 'B11'),
  c('10G', 'A7'),
  c('10G', 'E5'),
  c('10G', 'B11'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

for (i in 1:length(sub_combs)){
  print(sub_combs[i])
  difpeaks_df %>%
    select(Gene_id, contains(sub_combs[[i]][1]) & contains(sub_combs[[i]][2])) %>%
    set_names(c('Gene_id', 'Col1', 'Col2')) %>%
    filter(Col1 & Col2) %>%
    print()
  print('--------')
  print('')
  print('')
}

## Manually correct them
difpeaks_df[difpeaks_df$Gene_id == 'PF3D7_0936700',]$peak_B11_12B <- F
difpeaks_df[difpeaks_df$Gene_id == 'PF3D7_0936700',]$peak_B11_10G <- F
difpeaks_df[difpeaks_df$Gene_id == 'PF3D7_0401500',]$peak_B11_12B <- F


#+end_src
*** Some checks and save info_df
#+begin_src R
info_df %>%
  count(Family)

novar_family <- info_df %>%
  filter((!Variant & !is.na(Family)) | (Variant & is.na(Family)))

write_csv(novar_family, paste0(tables_dir, 'noVariant_with_family.csv'))
write_tsv(info_df, paste0(tables_dir, 'info_df.tsv'))
#+end_src
*** Load transcription data
#+begin_src R
#### Load transcription data ####
trans_df_old <- read_csv(paste0(microarrays_dir, 'Old_Arrays/R_results_OldArrays_Variantome/final_summary_table.csv'))
trans_df_new <- read_csv(paste0(microarrays_dir, 'New_Arrays/R_results_NewArray/final_summary_table.csv'))

trans_df <- full_join(trans_df_old, trans_df_new) %>%
  select(-Name, -Annot, -GamGene)

## Subset trans_df to genes that appear on info_df
trans_df %>%
  filter(!Gene_id %in% info_df$Gene_id) %>%
  select(Gene_id) %>%
  write_csv(paste0(tables_dir, 'gene_ids_not_in_info_df.csv'))

trans_df <- trans_df %>%
  filter(Gene_id %in% info_df$Gene_id)

trans_df <- trans_df %>%
  mutate(`E5-B11_MaxVal` = -`B11-E5_MaxVal`) %>%
  mutate(`E5-B11_MaxTime` = `B11-E5_MaxTime`) %>%
  select(-`B11-E5_MaxVal`, -`B11-E5_MaxTime`)

## Load Areas Data
arees_old <- read_csv(paste0(microarrays_dir, 'Old_Arrays/R_results_OldArrays_Variantome/areaDiferences_geneLevel.csv')) %>%
  rename(Gene_id = ...1)

arees_new <- read_csv(paste0(microarrays_dir, 'New_Arrays/R_results_NewArray/areaDiferences_geneLevel.csv')) %>%
  rename(Gene_id = ...1)

arees_df <- full_join(arees_old, arees_new)

## Load Red Percentile Data
red_percent_old <- read_csv(paste0(microarrays_dir, 'Old_Arrays/R_results_OldArrays_Variantome/red_percentiles.csv'))
red_percent_new <- read_csv(paste0(microarrays_dir, 'New_Arrays/R_results_NewArray/red_percentiles.csv'))

red_df <- full_join(red_percent_old, red_percent_new, by = 'Gene_id')

## Load Max-Time data
old_maxtime <- read_csv(paste0(microarrays_dir, 'Old_Arrays/R_results_OldArrays_Variantome/old_arrays_maxtime.csv'))

new_maxtime <- read_csv(paste0(microarrays_dir, 'New_Arrays/R_results_NewArray/new_arrays_maxtime.csv'))

maxtime_df <- full_join(old_maxtime, new_maxtime, by = 'Gene_id', suffix = c('_Old', '_New'))

old_breaks <- read_csv(paste0(microarrays_dir, 'Old_Arrays/R_results_OldArrays_Variantome/old_area_breaks.csv'))

new_breaks <- read_csv(paste0(microarrays_dir, 'New_Arrays/R_results_NewArray/new_area_breaks.csv'))

breaks_df <- bind_cols(old_breaks, new_breaks)
colnames(breaks_df) <- c('Old_Area_Breaks', 'New_Area_Breaks')
#+end_src
*** Load filteredFC tables
**** Get Trans ON/OFF genes, from filtered tables
#+begin_src R
#### Load Filtered FC Tables ####
old_arrays <- paste0(microarrays_dir, 'Old_Arrays/R_results_OldArrays_Variantome/')

filtered_12B_10G <- read_tsv(paste0(old_arrays, '12B_10G_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)
filtered_12B_3D7B <- read_tsv(paste0(old_arrays, '12B_3D7B_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)
filtered_10G_3D7B <- read_tsv(paste0(old_arrays, '10G_3D7B_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)

new_arrays <- paste0(microarrays_dir, 'New_Arrays/R_results_NewArray/')
filtered_A7_B11 <- read_tsv(paste0(new_arrays, 'A7_B11_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)
filtered_A7_E5 <- read_tsv(paste0(new_arrays, 'A7_E5_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)
filtered_B11_E5 <- read_tsv(paste0(new_arrays, 'B11_E5_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)

## Swich B11vsE5 for E5vsB11
filtered_E5_B11 <- filtered_B11_E5 %>%
  rename(`E5-B11_MaxVal` = `B11-E5_MaxVal`, `E5-B11_MaxTime` = `B11-E5_MaxTime`) %>%
  mutate(`E5-B11_MaxVal` = -`E5-B11_MaxVal`)


## Create filtered lists for each comparison, we need to add MaxTime and tRNA filters
difs_12B_10G <- filtered_12B_10G %>%
  filter(abs(`12B-10G_MaxVal`) > 2) %>%
  left_join(info_df %>% select(Gene_id, Is_tRNA)) %>%
  filter(PassAll) %>%
  filter(!Is_tRNA) %>%
  select(Gene_id) %>%
  pull()

difs_12B_3D7B <- filtered_12B_3D7B %>%
  filter(abs(`12B-3D7B_MaxVal`) > 2) %>%
  left_join(info_df %>% select(Gene_id, Is_tRNA)) %>%
  filter(PassAll) %>%
  filter(!Is_tRNA) %>%
  select(Gene_id) %>%
  pull()

difs_10G_3D7B <- filtered_10G_3D7B %>%
  filter(abs(`10G-3D7B_MaxVal`) > 2) %>%
  left_join(info_df %>% select(Gene_id, Is_tRNA)) %>%
  filter(PassAll) %>%
  filter(!Is_tRNA) %>%
  select(Gene_id) %>%
  pull()

difs_A7_E5 <- filtered_A7_E5 %>%
  filter(abs(`A7-E5_MaxVal`) > 2) %>%
  left_join(info_df %>% select(Gene_id, Is_tRNA)) %>%
  filter(PassAll) %>%
  filter(!Is_tRNA) %>%
  select(Gene_id) %>%
  pull()

difs_A7_B11 <- filtered_A7_B11 %>%
  filter(abs(`A7-B11_MaxVal`) > 2) %>%
  left_join(info_df %>% select(Gene_id, Is_tRNA)) %>%
  filter(PassAll) %>%
  filter(!Is_tRNA) %>%
  select(Gene_id) %>%
  pull()

difs_E5_B11 <- filtered_E5_B11 %>%
  filter(abs(`E5-B11_MaxVal`) > 2) %>%
  left_join(info_df %>% select(Gene_id, Is_tRNA)) %>%
  filter(PassAll) %>%
  filter(!Is_tRNA) %>%
  select(Gene_id) %>%
  pull()


all_difs <- unique(c(
  difs_12B_10G,
  difs_12B_3D7B,
  difs_10G_3D7B,
  difs_A7_E5,
  difs_A7_B11,
  difs_E5_B11
))

length(all_difs)

## Select MaxDif for each gene (once filtered by redfilter and dupl_del)
## It takes long to run so we read premade table, uncoment if need to rerun

maxDif_df <- tibble()
for (gid in trans_df$Gene_id){

  ## Create a list with each contrast difference df
  difs <- list(
    filtered_12B_10G,
    filtered_12B_3D7B,
    filtered_10G_3D7B,
    filtered_A7_B11,
    filtered_A7_E5,
    filtered_E5_B11
  )

  ## Filter by Gene_id
  dif_dfs <- lapply(difs, function(x) x %>% filter(Gene_id == gid))

  ## Function to get MaxVal of each df and join them in a vector
  get_MaxVal <- function(x){
    maxVal <- x %>%
      select(contains('MaxVal')) %>%
      pull()
    if (identical(maxVal, numeric(0))) {maxVal <- NA}
    return(maxVal)
  }

  maxVect <- sapply(dif_dfs, get_MaxVal)
  max_idx <- which.max(abs(maxVect))

  ## Handle genes that don't pass filters (set to NA)
  if (identical(maxVect, rep(NA, 6))) {
    out_row <- tibble(
      Gene_id = gid,
      Max_aMAFC = NA,
      Max_Time = NA,
      On_trans = NA,
      Off_trans = NA,
      PassMaxtime = FALSE
    )
    ## Handle rest of genes
  } else {
    ## Get on/off strain names
    maxDif <- dif_dfs[[max_idx]] %>% select(contains('_MaxVal'))
    maxVal <- maxDif %>% pull()

    maxStrains <- colnames(maxDif)
    strains <- strsplit(maxStrains, split = '_', fixed = T)[[1]][1]
    strains <- strsplit(strains, split = '-', fixed = T)[[1]]
    if (maxVal >= 0){
      On <- strains[1]
      Off <- strains[2]
    } else {
      On <- strains[2]
      Off <- strains[1]
    }

    ## Collect MaxDif row from the appropiate df
    out_row <- dif_dfs[[max_idx]] %>%
      select(Gene_id, contains('_MaxVal'), contains('_MaxTime'), PassMaxtime) %>%
      setNames(c('Gene_id', 'Max_aMAFC', 'Max_Time', 'PassMaxtime')) %>%
      mutate(
        On_trans = On,
        Off_trans = Off
      )

  }
  maxDif_df <- bind_rows(maxDif_df, out_row)
}

maxDif_df <- maxDif_df %>%
  arrange(-abs(Max_aMAFC)) %>%
  left_join(trans_df, by = 'Gene_id')

maxDif_df %>%
  write_tsv(paste0(tables_dir, 'max_differences_df.tsv'))

maxDif_df <- read_tsv(paste0(tables_dir, 'max_differences_df.tsv'))
maxDif_df_old <- read_tsv(paste0(tables_dir, 'max_differences_df_old.tsv'))

maxDif_df %>%
  print(width = 400)

maxDif_df %>%
  filter(abs(Max_aMAFC) > 2)
#+end_src
**** Replace 3D7B with pertinent new array subclone
#+begin_src R
pre3D7_substitution <- maxDif_df
new_array_areas <- read_csv(paste0(microarrays_dir, 'New_Arrays/R_results_NewArray/area_geneLevel.csv')) %>%
  select(-Name, -Annot, -Variant)

max_trans_newarray <- maxDif_df %>%
  left_join(new_array_areas)

get_new_onoff <- function(gid) {

  #gid <- 'PF3D7_0601200'
  on <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(On_trans) %>%
    pull()

  off <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(Off_trans) %>%
    pull()

  time <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(Max_Time) %>%
    pull()

  onoff <- TRUE
  if (is.na(on) | is.na(off)){
    onoff <- FALSE
  } else {
    if (on == '3D7B') {func <- which.max}
    if (off == '3D7B') {func <- which.min}
    if (on != '3D7B' & off != '3D7B') {onoff <- FALSE}
  }

  if (is.na(time)){
    out <- NA
  } else if (!onoff){
    out <- NA
  } else {
    strains <- c('A7', 'B11', 'E5')

    vect <- max_trans_newarray %>%
      filter(Gene_id == gid) %>%
      select(contains(time))

    ## Filter by red percent if 3D7B is 'On' strain
    red_pcnts <- red_df %>%
      filter(Gene_id == gid) %>%
      select(A7, B11, E5)

    red_mask <- red_pcnts > 15
    if (on != '3D7B'){red_mask <- c(TRUE, TRUE, TRUE)}

    ## Filter by dupl/del
    dupl_del_mask <- c(
      !gid %in% dupl_del$A7K9$Gene_id,
      !gid %in% dupl_del$B11$Gene_id,
      !gid %in% dupl_del$E5K9$Gene_id
    )

    ## Apply both filters
    whole_mask <- red_mask & dupl_del_mask

    vect <- vect[whole_mask]
    strains <- strains[whole_mask]

    ## Final output
    ifelse(all(is.na(vect)) | !any(whole_mask), out <- NA, out <- strains[func(vect)])
  }
  return(out)
}

newonoffs <- sapply(max_trans_newarray$Gene_id, get_new_onoff)
maxDif_df['New_OnOffs'] <- newonoffs
max_trans_newarray['New_OnOffs'] <- newonoffs

max_trans_newarray %>%
  select(Gene_id, On_trans, Off_trans, New_OnOffs) %>%
  print(n = 50)

maxDif_df <- maxDif_df %>%
  mutate(On_trans = ifelse(On_trans == '3D7B',
                           New_OnOffs,
                           On_trans)) %>%
  mutate(Off_trans = ifelse(Off_trans == '3D7B',
                           New_OnOffs,
                           Off_trans)) %>%
  mutate(Is_3D7B = !is.na(New_OnOffs)) %>%
  select(-New_OnOffs)

maxDif_df %>%
  select(-contains('_MaxVal'), -contains('_MaxTime'))

## Add tRNA info
maxDif_df <- maxDif_df %>%
  left_join(info_df %>% select(Gene_id, Is_tRNA), by = 'Gene_id')

maxDif_df %>%
  filter(Is_tRNA)
table(maxDif_df$Is_tRNA)
#+end_src
**** Create final filtered table
#+begin_src R
colnames(maxDif_df)

finalFC_df <- maxDif_df %>%
  filter(!is.na(On_trans) & !is.na(Off_trans)) %>%
  filter(!Is_tRNA) %>%
  filter(PassMaxtime)

## Missing Genes
msg <- all_difs[!all_difs %in% finalFC_df$Gene_id]

maxDif_df %>%
  filter(Gene_id %in% msg) %>%
  print(width = 999)

info_df %>%
  filter(Gene_id %in% msg) %>%
  print(width = 999)

write_csv(finalFC_df, paste0(tables_dir, 'final_filtered_transcription_differences.csv'))

colnames(info_df)

finalFC_df %>%
  filter(PassMaxtime) %>%
  filter(!Is_tRNA) %>%
  left_join(info_df, by = 'Gene_id') %>%
  filter(!Variant) %>%
  select(Gene_id, Name, Annot, Family, Gam_specific)

finalFC_df %>%
  left_join(info_df) %>%
  select(-PassMaxtime, -Is_3D7B, -Gene_name) %>%
  write_tsv(paste0(tables_dir, 'final_filtered_mAFC4_annotated.tsv'))


#+end_src
*** Load Coverages
**** Load Coverages: 1000bp+500CDS
#+begin_src R
#### Load heterochromatin data 1000bp+500CDS ####

cov_12b <- read_tsv(paste0(
  coverage_dir,
  'binned_1000tss_500orf_coverage_1.2B.bed'
), col_names = F)
cov_10g <- read_tsv(paste0(
  coverage_dir,
  'binned_1000tss_500orf_coverage_10G.bed'
), col_names = F)
cov_a7 <- read_tsv(paste0(
  coverage_dir,
  'binned_1000tss_500orf_coverage_A7K9.bed'
), col_names = F)
cov_e5 <- read_tsv(paste0(
  coverage_dir,
  'binned_1000tss_500orf_coverage_E5K9.bed'
), col_names = F)
cov_b11 <- read_tsv(paste0(
  coverage_dir,
  'binned_1000tss_500orf_coverage_B11.bed'
), col_names = F)

join_cols = c('X1', 'X2', 'X3', 'X4')

het_df <- cov_12b %>%
  full_join(cov_10g, by = join_cols) %>%
  full_join(cov_a7, by = join_cols) %>%
  full_join(cov_e5, by = join_cols) %>%
  full_join(cov_b11, by = join_cols)

colnames(het_df) <- c('Chrom', 'Start', 'Stop', 'Gene_id',
                      'Het_12B', 'Het_10G', 'Het_A7', 'Het_E5', 'Het_B11')

het_df <- het_df %>% select(Gene_id, contains('Het'), everything())

hdf <- het_df %>% select(Gene_id, contains('Het'))
cnames <- str_replace(colnames(hdf), 'Het', 'Cov_1000fp_500orf')
colnames(hdf) <- cnames
#+end_src
**** Load Coverages: 5pORF3p
#+begin_src R
#### Load heterochromatin data 5pORF3p ####
## Load 3prime, ORF, 5prime Coverage

load3ORF5 <- function(cov_5ORF3_file){
  cov_5ORF3 <- read_tsv(cov_5ORF3_file, col_names = F)
  cov_5ORF3 <- cov_5ORF3 %>%
    setNames(c('Chrom', 'Start', 'Stop', 'Gene_id', 'Intensity', 'Strand', 'Cov')) %>%
    select(-Intensity)
  prime5 <- cov_5ORF3 %>% filter(grepl('5prime', fixed = T, Gene_id))
  ORF <- cov_5ORF3 %>% filter(!grepl('5prime', fixed = T, Gene_id) & !grepl('3prime', fixed = T, Gene_id))
  prime3 <- cov_5ORF3 %>% filter(grepl('3prime', fixed = T, Gene_id))
  ORF['Cov_5prime'] <- prime5$Cov
  ORF['Cov_3prime'] <- prime3$Cov
  ORF <- ORF %>% rename(Cov_ORF = Cov)
  return(ORF)
}

e5_5ORF3 <- load3ORF5(paste0(coverage_dir, 'binned_5prime1000_ORF_3prime1000_coverage_E5K9.bed'))
a7_5ORF3 <- load3ORF5(paste0(coverage_dir, 'binned_5prime1000_ORF_3prime1000_coverage_A7K9.bed'))
b11_5ORF3 <- load3ORF5(paste0(coverage_dir, 'binned_5prime1000_ORF_3prime1000_coverage_B11.bed'))
x12b_5ORF3 <- load3ORF5(paste0(coverage_dir, 'binned_5prime1000_ORF_3prime1000_coverage_1.2B.bed'))
x10g_5ORF3 <- load3ORF5(paste0(coverage_dir, 'binned_5prime1000_ORF_3prime1000_coverage_10G.bed'))

join_cols = c('Chrom', 'Start', 'Stop', 'Gene_id', 'Strand')

cov_5ORF3_df <- x12b_5ORF3 %>%
  full_join(x10g_5ORF3, by = join_cols, suffix = c('_12B', '_10G')) %>%
  full_join(a7_5ORF3, by = join_cols, suffix = c('', '_A7')) %>%
  full_join(e5_5ORF3, by = join_cols, suffix = c('', '_E5')) %>%
  full_join(b11_5ORF3, by = join_cols, suffix = c('', '_B11')) %>%
  rename(Cov_ORF_A7 = Cov_ORF, Cov_5prime_A7 = Cov_5prime, Cov_3prime_A7 = Cov_3prime) %>%
  select(all_of(join_cols), contains('5prime'), contains('ORF'), contains('3prime'))

cov_5orf3 <- cov_5ORF3_df %>% select(Gene_id, contains('Cov'))
cnames <- str_replace(colnames(cov_5orf3), '5prime', '1000fp') %>%
  str_replace('ORF', 'allorf') %>%
  str_replace('3prime', '1000tp')
cov_5orf3 <- cov_5orf3 %>% set_names(cnames)
#+end_src
**** Load Coverages: ORF abs-bp
#+begin_src R
#### Load ORF abs-bp Coverages ####

read_abs_orf_cov <- function(strain, len){
  col_names <- c('Chrom', 'Start', 'Stop', 'Gene_id', 'Cov')
  path <- paste0(
    coverage_dir,
    'binned_0tss_', len,
    'orf_allowoverlaps_True_coverage_',
    strain, '.bed'
  )
  df <- read_tsv(path, col_names = col_names) %>%
    select(Gene_id, Cov)
  return(df)
}

cov_500_12B <- read_abs_orf_cov('1.2B', '500')
cov_500_10G <- read_abs_orf_cov('10G', '500')
cov_500_A7 <- read_abs_orf_cov('A7K9', '500')
cov_500_E5 <- read_abs_orf_cov('E5K9', '500')
cov_500_B11 <- read_abs_orf_cov('B11', '500')

cov_1000_12B <- read_abs_orf_cov('1.2B', '1000')
cov_1000_10G <- read_abs_orf_cov('10G', '1000')
cov_1000_A7 <- read_abs_orf_cov('A7K9', '1000')
cov_1000_E5 <- read_abs_orf_cov('E5K9', '1000')
cov_1000_B11 <- read_abs_orf_cov('B11', '1000')

cov_1500_12B <- read_abs_orf_cov('1.2B', '1500')
cov_1500_10G <- read_abs_orf_cov('10G', '1500')
cov_1500_A7 <- read_abs_orf_cov('A7K9', '1500')
cov_1500_E5 <- read_abs_orf_cov('E5K9', '1500')
cov_1500_B11 <- read_abs_orf_cov('B11', '1500')

cov_orf_abs_df <- cov_500_12B %>%
  full_join(cov_500_10G, by = 'Gene_id') %>%
  full_join(cov_500_A7, by = 'Gene_id') %>%
  full_join(cov_500_E5, by = 'Gene_id') %>%
  full_join(cov_500_B11, by = 'Gene_id') %>%

  full_join(cov_1000_12B, by = 'Gene_id') %>%
  full_join(cov_1000_10G, by = 'Gene_id') %>%
  full_join(cov_1000_A7, by = 'Gene_id') %>%
  full_join(cov_1000_E5, by = 'Gene_id') %>%
  full_join(cov_1000_B11, by = 'Gene_id') %>%

  full_join(cov_1500_12B, by = 'Gene_id') %>%
  full_join(cov_1500_10G, by = 'Gene_id') %>%
  full_join(cov_1500_A7, by = 'Gene_id') %>%
  full_join(cov_1500_E5, by = 'Gene_id') %>%
  full_join(cov_1500_B11, by = 'Gene_id') %>%

  set_names('Gene_id',
            'Cov_500orf_12B',
            'Cov_500orf_10G',
            'Cov_500orf_A7',
            'Cov_500orf_E5',
            'Cov_500orf_B11',
            'Cov_1000orf_12B',
            'Cov_1000orf_10G',
            'Cov_1000orf_A7',
            'Cov_1000orf_E5',
            'Cov_1000orf_B11',
            'Cov_1500orf_12B',
            'Cov_1500orf_10G',
            'Cov_1500orf_A7',
            'Cov_1500orf_E5',
            'Cov_1500orf_B11'
            )

cov_orf_abs_df %>%
  filter(!complete.cases(.))


cov_orf_abs_df %>%
  select(contains('12B'))

cov_orf_abs_df %>%
  select(contains('10G'))
#+end_src
**** Load Coverages: Plasmo-DB 51
#+begin_src R
#### Load plasmoDB TSS coverages ####
load_pDB <- function(cov_pDB_file){

  col_names <- c('Chrom', 'Start', 'Stop', 'Gene_id', 'Type', 'Cov')
  cov_pDB <- read_tsv(cov_pDB_file, col_names = col_names) %>%
    mutate(Gene_id = str_replace(Gene_id, '.*(PF3D7_\\d{7}).*', '\\1'))

  prime5 <- cov_pDB %>%
    filter(Type == 'five_prime_UTR') %>%
    rename(p5utr_Cov = Cov) %>%
    select(Gene_id, p5utr_Cov)

  prime3 <- cov_pDB %>%
    filter(Type == 'three_prime_UTR') %>%
    rename(p3utr_Cov = Cov) %>%
    select(Gene_id, p3utr_Cov)

  outdf <- prime5 %>%
    full_join(prime3, by = 'Gene_id') %>%
    group_by(Gene_id) %>%
    summarize(p5utr_Cov = mean(p5utr_Cov), p3utr_Cov = mean(p3utr_Cov))

  return(outdf)
}

cov_plasmoDB_12B <- load_pDB(paste0(coverage_dir, 'plasmoDB_UTRs_sorted_coverage_1.2B.bed'))
cov_plasmoDB_10G <- load_pDB(paste0(coverage_dir, 'plasmoDB_UTRs_sorted_coverage_10G.bed'))
cov_plasmoDB_A7 <- load_pDB(paste0(coverage_dir, 'plasmoDB_UTRs_sorted_coverage_A7K9.bed'))
cov_plasmoDB_E5 <- load_pDB(paste0(coverage_dir, 'plasmoDB_UTRs_sorted_coverage_E5K9.bed'))
cov_plasmoDB_B11 <- load_pDB(paste0(coverage_dir, 'plasmoDB_UTRs_sorted_coverage_B11.bed'))

cov_pDB_df <- cov_plasmoDB_12B %>%
  full_join(cov_plasmoDB_10G, by = 'Gene_id', suffix = c('_12B', '_10G')) %>%
  full_join(cov_plasmoDB_A7, by = 'Gene_id', suffix = c('', '_A7')) %>%
  full_join(cov_plasmoDB_E5, by = 'Gene_id', suffix = c('', '_E5')) %>%
  full_join(cov_plasmoDB_B11, by = 'Gene_id', suffix = c('', '_B11')) %>%
  rename(p5utr_Cov_A7 = p5utr_Cov, p3utr_Cov_A7 = p3utr_Cov)


load_pDB_TSS <- function(cov_pDB_file){
  col_names <- c('Chrom', 'Start', 'Stop', 'Gene_id', 'TSS_Cov')
  cov_pDB <- read_tsv(cov_pDB_file, col_names = col_names) %>%
    mutate(Gene_id = str_replace(Gene_id, '.*(PF3D7_\\d{7}).*', '\\1')) %>%
    select(Gene_id, TSS_Cov) %>%
    group_by(Gene_id) %>%
    summarize(TSS_Cov = mean(TSS_Cov))

  return(cov_pDB)
}

cov_plasmoDB_TSS_12B <- load_pDB_TSS(paste0(coverage_dir, 'plasmoDB_TSSs_sorted_coverage_1.2B.bed'))
cov_plasmoDB_TSS_10G <- load_pDB_TSS(paste0(coverage_dir, 'plasmoDB_TSSs_sorted_coverage_10G.bed'))
cov_plasmoDB_TSS_A7 <- load_pDB_TSS(paste0(coverage_dir, 'plasmoDB_TSSs_sorted_coverage_A7K9.bed'))
cov_plasmoDB_TSS_E5 <- load_pDB_TSS(paste0(coverage_dir, 'plasmoDB_TSSs_sorted_coverage_E5K9.bed'))
cov_plasmoDB_TSS_B11 <- load_pDB_TSS(paste0(coverage_dir, 'plasmoDB_TSSs_sorted_coverage_B11.bed'))

cov_pDB_TSS_df <- cov_plasmoDB_TSS_12B %>%
  full_join(cov_plasmoDB_TSS_10G, by = 'Gene_id', suffix = c('_12B', '_10G')) %>%
  full_join(cov_plasmoDB_TSS_A7, by = 'Gene_id', suffix = c('', '_A7')) %>%
  full_join(cov_plasmoDB_TSS_E5, by = 'Gene_id', suffix = c('', '_E5')) %>%
  full_join(cov_plasmoDB_TSS_B11, by = 'Gene_id', suffix = c('', '_B11')) %>%
  rename(TSS_Cov_A7 = TSS_Cov)

cov_pDB_df <- cov_pDB_df %>%
  full_join(cov_pDB_TSS_df)
#+end_src
**** Load Coverages: Many-Bin
#+begin_src R
#### Load Many-Bin coverages ####

get_bins <- function(dfin, bin_txt, outcol){
  dfout <- dfin %>% filter(grepl(bin_txt, fixed = T, Gene_id)) %>%
    mutate(Gene_id = str_replace(Gene_id, bin_txt, '')) %>%
    rename(!!outcol := Cov) %>%
    select(Gene_id, Strand, !!outcol)
}

get_manybins <- function(strain){

  fpath <- paste0(
    coverage_dir,
    'binned_5prime500_1000_1500_2000_ORF_3prime500_1000_1500_allowoverlapTrue_coverage_',
    strain, '.bed'
  )

  cov_5orf3_manybins <- read_tsv(fpath, col_names = F)%>%
    setNames(c('Chrom', 'Start', 'Stop', 'Gene_id', 'Intensity', 'Strand', 'Cov')) %>%
    select(-Intensity)

  cov_2000fp_manybins <- get_bins(cov_5orf3_manybins, '_5prime_2000', 'Cov_2000fp_manybins')
  cov_1500fp_manybins <- get_bins(cov_5orf3_manybins, '_5prime_1500', 'Cov_1500fp_manybins')
  cov_1000fp_manybins <- get_bins(cov_5orf3_manybins, '_5prime_1000', 'Cov_1000fp_manybins')
  cov_500fp_manybins <- get_bins(cov_5orf3_manybins, '_5prime_500', 'Cov_500fp_manybins')
  cov_1qorf_manybins <- get_bins(cov_5orf3_manybins, '_q1', 'Cov_1qorf_manybins')
  cov_2qorf_manybins <- get_bins(cov_5orf3_manybins, '_q2', 'Cov_2qorf_manybins')
  cov_3qorf_manybins <- get_bins(cov_5orf3_manybins, '_q3', 'Cov_3qorf_manybins')
  cov_4qorf_manybins <- get_bins(cov_5orf3_manybins, '_q4', 'Cov_4qorf_manybins')
  cov_1500tp_manybins <- get_bins(cov_5orf3_manybins, '_3prime_1500', 'Cov_1500tp_manybins')
  cov_1000tp_manybins <- get_bins(cov_5orf3_manybins, '_3prime_1000', 'Cov_1000tp_manybins')
  cov_500tp_manybins <- get_bins(cov_5orf3_manybins, '_3prime_500', 'Cov_500tp_manybins')

  join_cols <- c('Strand', 'Gene_id')
  df <- cov_2000fp_manybins %>%
    full_join(cov_1500fp_manybins, by = join_cols) %>%
    full_join(cov_1000fp_manybins, by = join_cols) %>%
    full_join(cov_500fp_manybins, by = join_cols) %>%
    full_join(cov_1qorf_manybins, by = join_cols) %>%
    full_join(cov_2qorf_manybins, by = join_cols) %>%
    full_join(cov_3qorf_manybins, by = join_cols) %>%
    full_join(cov_4qorf_manybins, by = join_cols) %>%
    full_join(cov_1500tp_manybins, by = join_cols) %>%
    full_join(cov_1000tp_manybins, by = join_cols) %>%
    full_join(cov_500tp_manybins, by = join_cols)

  return(df)
}

cov_manybins_12B <- get_manybins('1.2B')
cov_manybins_10G <- get_manybins('10G')
cov_manybins_A7 <- get_manybins('A7K9')
cov_manybins_E5 <- get_manybins('E5K9')
cov_manybins_B11 <- get_manybins('B11')


## cov_manybins_B11 %>%
##   filter(Gene_id == 'PF3D7_1130800') %>%
##   print(width = 800)


join_cols <- c('Gene_id', 'Strand')
cov_manybins <- cov_manybins_12B %>%
  full_join(cov_manybins_10G, by = join_cols, suffix = c('_12B', '_10G')) %>%
  full_join(cov_manybins_A7, by = join_cols, suffix = c('', '_A7')) %>%
  full_join(cov_manybins_E5, by = join_cols, suffix = c('', '_E5')) %>%
  full_join(cov_manybins_B11, by = join_cols, suffix = c('', '_B11')) %>%
  rename(Cov_2000fp_manybins_A7 = Cov_2000fp_manybins,
         Cov_1500fp_manybins_A7 = Cov_1500fp_manybins,
         Cov_1000fp_manybins_A7 = Cov_1000fp_manybins,
         Cov_500fp_manybins_A7 = Cov_500fp_manybins,
         Cov_1qorf_manybins_A7 = Cov_1qorf_manybins,
         Cov_2qorf_manybins_A7 = Cov_2qorf_manybins,
         Cov_3qorf_manybins_A7 = Cov_3qorf_manybins,
         Cov_4qorf_manybins_A7 = Cov_4qorf_manybins,
         Cov_1500tp_manybins_A7 = Cov_1500tp_manybins,
         Cov_1000tp_manybins_A7 = Cov_1000tp_manybins,
         Cov_500tp_manybins_A7 = Cov_500tp_manybins,
         ) %>%
  select(-Strand)

## Convert to numeric
cov_manybins <- cov_manybins %>%
  mutate(across(contains('Cov'), as.numeric))

cov_manybins %>%
  filter(!complete.cases(.))
#+end_src
**** Load Coverages: Abs ORF
#+begin_src R
#### Load Abs ORF Coverages ####
load_abs_ORF <- function(cov_abs_orf_file){
  cov_abs_ORF <- read_tsv(cov_abs_orf_file, col_names = F)
  cov_abs_ORF <- cov_abs_ORF %>%
    setNames(c('Chrom', 'Start', 'Stop', 'Gene_id', 'Intensity', 'Strand', 'Cov')) %>%
    select(-Intensity)
  ORF <- cov_abs_ORF %>%
    filter(!grepl('5prime', fixed = T, Gene_id) & !grepl('3prime', fixed = T, Gene_id))
  ORF <- ORF %>%
    rename(Cov_ORF = Cov) %>%
    mutate(Cov_ORF = as.double(Cov_ORF)) %>%
    select(Gene_id, Cov_ORF)
  return(ORF)
}

abs_ORF_500_12B <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_0_500_3prime1000_allowoverlapTrue_coverage_1.2B.bed'))
abs_ORF_500_10G <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_0_500_3prime1000_allowoverlapTrue_coverage_10G.bed'))
abs_ORF_500_A7 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_0_500_3prime1000_allowoverlapTrue_coverage_A7K9.bed'))
abs_ORF_500_E5 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_0_500_3prime1000_allowoverlapTrue_coverage_E5K9.bed'))
abs_ORF_500_B11 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_0_500_3prime1000_allowoverlapTrue_coverage_B11.bed'))

abs_ORF_1000_12B <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_500_1000_3prime1000_allowoverlapTrue_coverage_1.2B.bed'))
abs_ORF_1000_10G <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_500_1000_3prime1000_allowoverlapTrue_coverage_10G.bed'))
abs_ORF_1000_A7 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_500_1000_3prime1000_allowoverlapTrue_coverage_A7K9.bed'))
abs_ORF_1000_E5 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_500_1000_3prime1000_allowoverlapTrue_coverage_E5K9.bed'))
abs_ORF_1000_B11 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_500_1000_3prime1000_allowoverlapTrue_coverage_B11.bed'))

abs_ORF_1500_12B <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_1000_1500_3prime1000_allowoverlapTrue_coverage_1.2B.bed'))
abs_ORF_1500_10G <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_1000_1500_3prime1000_allowoverlapTrue_coverage_10G.bed'))
abs_ORF_1500_A7 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_1000_1500_3prime1000_allowoverlapTrue_coverage_A7K9.bed'))
abs_ORF_1500_E5 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_1000_1500_3prime1000_allowoverlapTrue_coverage_E5K9.bed'))
abs_ORF_1500_B11 <- load_abs_ORF(paste0(
  coverage_dir,
  'binned_5prime1000_ORF_1000_1500_3prime1000_allowoverlapTrue_coverage_B11.bed'))

join_cols = c('Gene_id')

cov_abs_ORF <- abs_ORF_500_12B %>%
  full_join(abs_ORF_500_10G, by = join_cols, suffix = c('_0_500_12B', '_0_500_10G')) %>%
  full_join(abs_ORF_500_A7, by = join_cols, suffix = c('', '_0_500_A7')) %>%
  full_join(abs_ORF_500_E5, by = join_cols, suffix = c('', '_0_500_E5')) %>%
  full_join(abs_ORF_500_B11, by = join_cols, suffix = c('', '_0_500_B11')) %>%

  full_join(abs_ORF_1000_12B, by = join_cols, suffix = c('', '_500_1000_12B')) %>%
  full_join(abs_ORF_1000_10G, by = join_cols, suffix = c('', '_500_1000_10G')) %>%
  full_join(abs_ORF_1000_A7, by = join_cols, suffix = c('', '_500_1000_A7')) %>%
  full_join(abs_ORF_1000_E5, by = join_cols, suffix = c('', '_500_1000_E5')) %>%
  full_join(abs_ORF_1000_B11, by = join_cols, suffix = c('', '_500_1000_B11')) %>%

  full_join(abs_ORF_1500_12B, by = join_cols, suffix = c('', '_1000_1500_12B')) %>%
  full_join(abs_ORF_1500_10G, by = join_cols, suffix = c('', '_1000_1500_10G')) %>%
  full_join(abs_ORF_1500_A7, by = join_cols, suffix = c('', '_1000_1500_A7')) %>%
  full_join(abs_ORF_1500_E5, by = join_cols, suffix = c('', '_1000_1500_E5')) %>%
  full_join(abs_ORF_1500_B11, by = join_cols, suffix = c('', '_1000_1500_B11')) %>%

  rename(Cov_ORF_0_500_A7 = Cov_ORF) %>%
  select(Gene_id, contains('Cov_'))
#+end_src
**** Join all Coverages
#+begin_src R
#### Join all Coverages ####
cor_cov_df <- cov_orf_abs_df %>%
  full_join(hdf, by = 'Gene_id') %>%
  full_join(cov_5orf3, by = 'Gene_id') %>%
  full_join(cov_pDB_df, by = 'Gene_id') %>%
  full_join(cov_manybins, by = 'Gene_id') %>%
  full_join(cov_abs_ORF, by = 'Gene_id')

positive_cov_df <- cor_cov_df %>%
  mutate(across(-Gene_id, ~ ifelse(.x > 0, .x, 0)))

full_df <- inner_join(cor_cov_df, trans_df)  %>%
  left_join(info_df)
#+end_src
** Create Custom Color Palette
#+begin_src R
#### Create 'fixed' color palette ####
col_factor <- factor(unique(info_df$Family_Grouped),
                     levels=c(
                       'Not CVGs',
                       'Other CVGs',
                       'FIKK',
                       'HYP',
                       'PHIST',
                       'STEVOR',
                       'RIFIN',
                       'VAR',
                       'PFMC-2TM'
                     ))

my_colors <- c('gray', scales::brewer_pal(palette = 'Set3', type = 'qual')(9))
names(my_colors) <- levels(col_factor)
my_scale <- scale_fill_manual(name = "Family_Grouped", values = my_colors)
my_scale2 <- scale_color_manual(name = "Family_Grouped", values = my_colors)
#+end_src
** Coverage PCAs
#+begin_src R
#### Coverage PCAs ####
colnames(full_df %>% select(contains('Cov')))

str_selector <- 'allorf'

cov_df <- full_df %>%
  select(Gene_id, contains(str_selector)) %>%
  filter(complete.cases(.))

noNA_df <- cov_df %>%
  select(contains('Cov'))

pca <- prcomp(t(noNA_df))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
df_pca$Strain <- sapply(colnames(cov_df %>% select(contains('Cov'))),
       function(x) gsub('Cov_1000fp_500orf_', '', x))

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point(aes(), size = 3)
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
p <- p + theme_classic()
p <- p + theme(text = element_text(size=20))
p <- p + geom_label_repel(aes(label = Strain))
p <- p + theme(legend.position = "none")
#p

ggsave(p, filename = paste0(plots_dir, 'Coverage_PCAs/', "coverage_", str_selector, '_PCA.png'), device = "png")


#+end_src
** Filtered_FC On/Off Donuts
#+begin_src R
#### FilteredFC On/Off Donut Plots ####
on_off_donut <- function(col){
  data <- finalFC_df %>%
    count(get(col)) %>%
    set_names('category', 'count')

  ## Compute percentages
  data$fraction = data$count / sum(data$count)

  ## Compute the cumulative percentages (top of each rectangle)
  data$ymax = cumsum(data$fraction)

  ## Compute the bottom of each rectangle
  data$ymin = c(0, head(data$ymax, n=-1))

  ## Compute label position
  data$labelPosition <- (data$ymax + data$ymin) / 2

  ## Compute a good label
  data$label <- paste0(data$category, "\n value: ", data$count)

  ## Make the plot
  p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category))
  p <- p +  geom_rect(color="white")
  ##p <- p + geom_label( x=4.2, aes(y=labelPosition, label=label), size=3)
  p <- p + coord_polar(theta="y") # Try to remove that to understand how the chart is built initially
  p <- p + xlim(c(2, 4)) # Try to remove that to see how to make a pie chart
  p <- p + theme_void()
  p <- p + scale_fill_viridis(discrete=TRUE)
  p
}


ggsave(paste0(plots_dir, 'on_difgenes_donut.pdf'), on_off_donut('On_trans'), device = 'pdf')
ggsave(paste0(plots_dir, 'off_difgenes_donut.pdf'), on_off_donut('Off_trans'), device = 'pdf')

#+end_src
** Correlations By Strain
*** Correlations
#+begin_src R
#### Correlations By Strain ####

get_cor_mtx <- function(df, contrast, trans_filter, difpeaks_filter){

  ##contrast <- c('12B', '10G')
  ##df <- full_df

  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')
  difpeaks_col <- paste0('Difpeaks_', contrast[1], '_', contrast[2])


  ## df %>%
  ##   select(contains('Cov_ORF_'))

  df_dif <- df %>%
  ## Absolute bp ORF
    mutate(Cov_500orf_Dif = get(paste0('Cov_500orf_', contrast[1])) - get(paste0('Cov_500orf_', contrast[2]))) %>%
    mutate(Cov_1000orf_Dif = get(paste0('Cov_1000orf_', contrast[1])) - get(paste0('Cov_1000orf_', contrast[2]))) %>%
    mutate(Cov_1500orf_Dif = get(paste0('Cov_1500orf_', contrast[1])) - get(paste0('Cov_1500orf_', contrast[2]))) %>%

  ## Absolute bp ORF, by interval
    mutate(Cov_0_500orf_Dif = get(paste0('Cov_ORF_0_500_', contrast[1])) - get(paste0('Cov_ORF_0_500_', contrast[2]))) %>%
    mutate(Cov_500_1000orf_Dif = get(paste0('Cov_ORF_500_1000_', contrast[1])) - get(paste0('Cov_ORF_500_1000_', contrast[2]))) %>%
    mutate(Cov_1000_1500orf_Dif = get(paste0('Cov_ORF_1000_1500_', contrast[1])) - get(paste0('Cov_ORF_1000_1500_', contrast[2]))) %>%

  ## 1000bp 5prime + 500bp ORF
    mutate(Cov_1000fp_500orf_Dif = get(paste0('Cov_1000fp_500orf_', contrast[1])) - get(paste0('Cov_1000fp_500orf_', contrast[2]))) %>%

  ## 1000bp 5prime/ ORF / 1000bp 3prime
    mutate(Cov_1000fp_Dif = get(paste0('Cov_1000fp_', contrast[1])) - get(paste0('Cov_1000fp_', contrast[2]))) %>%
    mutate(Cov_allorf_Dif = get(paste0('Cov_allorf_', contrast[1])) - get(paste0('Cov_allorf_', contrast[2]))) %>%
    mutate(Cov_1000tp_Dif = get(paste0('Cov_1000tp_', contrast[1])) - get(paste0('Cov_1000tp_', contrast[2]))) %>%

  ## PlsmoDB 5prime and TSS
    mutate(Cov_plasmoDB_5p_Dif = get(paste0('p5utr_Cov_', contrast[1])) - get(paste0('p5utr_Cov_', contrast[2]))) %>%
    mutate(Cov_plasmoDB_TSS_Dif = get(paste0('TSS_Cov_', contrast[1])) - get(paste0('TSS_Cov_', contrast[2]))) %>%
    mutate(Cov_plasmoDB_3p_Dif = get(paste0('p3utr_Cov_', contrast[1])) - get(paste0('p3utr_Cov_', contrast[2]))) %>%

  ## Manybins (2000, 1500, 1000, 500, 1q, 2q, 3q, 4q, 500, 1000, 1500)
    mutate(Cov_2000fp_manybins_Dif = get(paste0('Cov_2000fp_manybins_', contrast[1])) - get(paste0('Cov_2000fp_manybins_', contrast[2]))) %>%
    mutate(Cov_1500fp_manybins_Dif = get(paste0('Cov_1500fp_manybins_', contrast[1]))  - get(paste0('Cov_1500fp_manybins_', contrast[2]))) %>%
    mutate(Cov_1000fp_manybins_Dif = get(paste0('Cov_1000fp_manybins_', contrast[1])) - get(paste0('Cov_1000fp_manybins_', contrast[2]))) %>%
    mutate(Cov_500fp_manybins_Dif = get(paste0('Cov_500fp_manybins_', contrast[1]))- get(paste0('Cov_500fp_manybins_', contrast[2]))) %>%

    mutate(Cov_1qorf_manybins_Dif = get(paste0('Cov_1qorf_manybins_', contrast[1])) - get(paste0('Cov_1qorf_manybins_', contrast[2]))) %>%
    mutate(Cov_2qorf_manybins_Dif = get(paste0('Cov_2qorf_manybins_', contrast[1]))  - get(paste0('Cov_2qorf_manybins_', contrast[2]))) %>%
    mutate(Cov_3qorf_manybins_Dif = get(paste0('Cov_3qorf_manybins_', contrast[1])) - get(paste0('Cov_3qorf_manybins_', contrast[2]))) %>%
    mutate(Cov_4qorf_manybins_Dif = get(paste0('Cov_4qorf_manybins_', contrast[1]))- get(paste0('Cov_4qorf_manybins_', contrast[2]))) %>%

    mutate(Cov_1500tp_manybins_Dif = get(paste0('Cov_1500tp_manybins_', contrast[1]))  - get(paste0('Cov_1500tp_manybins_', contrast[2]))) %>%
    mutate(Cov_1000tp_manybins_Dif = get(paste0('Cov_1000tp_manybins_', contrast[1])) - get(paste0('Cov_1000tp_manybins_', contrast[2]))) %>%
    mutate(Cov_500tp_manybins_Dif = get(paste0('Cov_500tp_manybins_', contrast[1]))- get(paste0('Cov_500tp_manybins_', contrast[2]))) %>%

    filter(abs(get(trans_col)) > trans_filter) %>%
    select(Gene_id, matches(trans_col), contains('_Dif'))

  ## df_dif %>%
  ##   select(Gene_id, Cov_0_500orf_Dif, Cov_500_1000orf_Dif, Cov_1000_1500orf_Dif) %>%
  ##   summary()

  ## table(df_dif$Cov_500_1000orf_Dif)

  if (difpeaks_filter){df_dif <- df_dif %>% filter(get(difpeaks_col))}

  cormtx <- cor(df_dif %>% select(-Gene_id) %>% drop_na(), method = 'pearson')
  print(paste0('Contrast ', contrast[1], ' vs ', contrast[2]))
  print(paste0('Number of genes: ', dim(df_dif %>% select(-Gene_id) %>% drop_na())[1]))
  print(as.data.frame(cormtx[,1]))
  print('+++++++++++++++++++++++++++++')

  outdf <- as.data.frame(cormtx)
  outdf['Corr_with'] <- rownames(outdf)
  outdf <- outdf %>% select(Corr_with, everything())
  outname = paste0('corr_ALL_', contrast[1], '_', contrast[2],
                   '_transth_', trans_filter, '_difpeaks_', difpeaks_filter, '.csv')
  write_csv(outdf, file = outname)
}

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

trans_filter <- 0
difpeaks_filter <- F

for (contrast in contrasts) {get_cor_mtx(full_df, contrast, trans_filter, difpeaks_filter)}

cor_12B_10G <- get_cor_mtx(full_df, c('12B', '10G'), trans_filter, difpeaks_filter)
cor_A7_E5 <- get_cor_mtx(full_df, c('A7', 'E5'), trans_filter, difpeaks_filter)
cor_A7_B11 <- get_cor_mtx(full_df, c('A7', 'B11'), trans_filter, difpeaks_filter)
cor_B11_E5 <- get_cor_mtx(full_df, c('E5', 'B11'), trans_filter, difpeaks_filter)

all_Corr <- bind_cols(Corr_With = cor_12B_10G[-1,1],
                      Cor_12B_10G = cor_12B_10G[-1,2],
                      Cor_A7_E5 = cor_A7_E5[-1,2],
                      Cor_A7_B11 = cor_A7_B11[-1,2],
                      Cor_B11_E5 = cor_B11_E5[-1,2])

write_csv(all_Corr, file = paste0(tables_dir, 'correlations_transth_', trans_filter, '_allowoverlaps.csv'))

#+end_src
*** Correlation Plots 5p/ORF/3p
#+begin_src R
#### Correlation By Strain Plots ####

myCorPlot <- function(df, region, s1, s2, trans_th){

  df <- plot_5ORF3_df

  trans <- paste0(s1,'-',s2,'_MaxVal')
  difpeak <- paste0('Difpeaks_', s1, '_', s2)
  title_str <- paste0(s1, ' vs ', s2)
  outfile <- paste0('./Plots/corplot_', s1, '_', s2, '_', region, '.png')

  plot_df <- df %>%
    mutate(Dif_het = get(paste0('Cov_', region, '_', s1)) - get(paste0('Cov_', region, '_', s2))) %>%
    select(Gene_id, matches(trans), Dif_het, matches(difpeak)) %>%
    setNames(c('Gene_id', 'Trans', 'Het', 'Difpeak')) %>%
    filter(abs(Trans) > trans_th)

  p <- ggplot(plot_df, aes(x=Het,
                           y=Trans)) +
    scale_alpha_discrete(range = c(0.2, 1)) +
    ggtitle(title_str) +
    ylab('aMAFC') +
    xlab(paste0('Heterochromatin difference at ', region)) +
    geom_point()
  ggsave(outfile, p, device = 'png')
  print(p)
}

plot_5ORF3_df <- inner_join(cov_5ORF3_df, trans_df)  %>%
  left_join(info_df)

regions <- c('5prime', 'ORF', '3prime')

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

## ## Call corr plots for 5p/ORF/3p coverage
## for (region in regions){
##   for (contrast in contrasts){
##     s1 <- contrast[1]
##     s2 <- contrast[2]
##     trans_th <- 0
##     myCorPlot(plot_5ORF3_df, region, s1, s2, trans_th)
##   }
## }

region <- 'ORF'
s1 <- 'A7'
s2 <- 'B11'
trans_th <- 1
myCorPlot(plot_5ORF3_df, region, s1, s2, trans_th)
#+end_src
*** Correlation Plots All Coverages
#+begin_src R
#### Correlation By Strain Plots ####

myCorPlot_all <- function(df, region, s1, s2, trans_th){

  trans <- paste0(s1,'-',s2,'_MaxVal')
  difpeak <- paste0('peakFC_', s1, '_', s2)
  title_str <- paste0(s1, ' vs ', s2)
  outfile <- paste0(
    plots_dir,
    'Correlations_byStrain/corplot_',
    s1, '_', s2, '_', region,
    'transth_', trans_th,
    '.png'
  )

  plot_df <- df %>%
    mutate(Dif_het = get(paste0(region, s1)) - get(paste0(region, s2))) %>%
    select(Gene_id, matches(trans), Dif_het, matches(difpeak)) %>%
    setNames(c('Gene_id', 'Trans', 'Het', 'Difpeak')) %>%
    mutate(Difpeak = !is.na(Difpeak)) %>%
    filter(abs(Trans) > trans_th)

  p <- ggplot(plot_df, aes(x=Het,
                      y=Trans,
                      color = Difpeak,
                      alpha = Difpeak)) +
    scale_alpha_discrete(range = c(0.2, 1)) +
    ggtitle(title_str) +
    ylab('aMAFC') +
    xlab(paste0('Heterochromatin difference at ', region)) +
    geom_point()
  ggsave(outfile, p, device = 'png')
  print(p)
}

## Join transcription, coverage and difpeaks
trans_het_difpeaks_df <- full_df %>%
  left_join(sicer_df, by = 'Gene_id')


## Make plots for all strains and coverages
cnms <- str_replace(colnames(full_df %>% select(contains('Cov') & contains('12B'))), '12B', '')

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

## Plot correlations for all Coverages
for (c in cnms){
  for (contrast in contrasts){
    s1 <- contrast[1]
    s2 <- contrast[2]
    trans_th <- 1
    myCorPlot_all(trans_het_difpeaks_df, c, s1, s2, trans_th)
  }
}


region <- 'Cov_allorf_'
s1 <- 'A7'
s2 <- 'E5'
trans_th <- 1
myCorPlot_all(trans_het_difpeaks_df, region, s1, s2, trans_th)


#+end_src
** Heatmap Functions
#+begin_src R
#### Heatmap Funtions ####

myHeatmap <- function(df, family_facet){
  p <- ggplot(df, aes(x = variable, y = Label, fill = value)) +
    geom_tile(colour="snow3") +
    #geom_tile() +
    theme(
      text=element_text(size=24),

      legend.position='bottom',
      legend.title = element_blank(),

      panel.background=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank(),

      axis.title = element_blank(),
      axis.line.x = element_blank(),
      axis.ticks.x = element_blank(),
      axis.title.x = element_blank()
    )
  if (family_facet){p <- p+facet_grid(Family ~., scales = "free_y", space = "free")}
  return(p)
}
hetHeatmap <- function(df, family_facet){
  p <- myHeatmap(df, family_facet)
  p <- p + scale_fill_gradient(low = "white",
                               high = "orange",
                               na.value="grey",
                               limits = c(0,4),
                               oob=squish) +
    scale_y_discrete(position = "right") +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),

      panel.border=element_blank(),
      panel.grid.major=element_blank(),

      strip.background = element_blank(),
      strip.text.x = element_blank(),
      strip.text.y = element_blank(),
    )
  return(p)
}
hetDifHeatmap <- function(df, family_facet){
  p <- myHeatmap(df, family_facet)
  p <- p + scale_fill_gradient2(low = "chartreuse3",
                                mid = "white",
                                high = "darkred",
                                na.value="grey",
                                limits = c(-4, 4),
                                oob=squish) +
    scale_y_discrete(position = "left") +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),

      panel.border=element_blank(),
      panel.grid.major=element_blank(),

      strip.background = element_blank(),
      strip.text.x = element_blank(),
      strip.text.y = element_blank(),
    )
  return(p)
}
transHeatmap <- function(df, family_facet){
  p <- myHeatmap(df, family_facet)
  p <- p + scale_fill_gradient2(
             low = "blue",
             mid = "black",
             high = "yellow",
             na.value="grey",
             limits = c(-4, 4),
             oob=squish
           )
  p <- p + scale_y_discrete(position = "left")
  p <- p + theme(
             axis.text.y = element_blank(),
             axis.ticks.y = element_blank(),

             panel.border=element_blank(),
             panel.grid.major=element_blank(),

             strip.background = element_blank(),
             strip.text.x = element_blank(),
             strip.text.y = element_blank(),
             )
  return(p)
}

family_heatmap <- function(mdf){
  p <- myHeatmap(mdf, family_facet)
  ##p <- p + geom_text(aes(label=Label))
  p <- p + my_scale
  #p <- p + scale_y_discrete(limits=(rev(levels(mdf$Label))))
  p <- p + theme(
             axis.text.x = element_blank(),
             axis.text.y = element_blank(),
             axis.ticks.y = element_blank(),

             panel.border=element_blank(),
             panel.grid.major=element_blank(),

             strip.background = element_blank(),
             strip.text.x = element_blank(),
             strip.text.y = element_blank()
           )
  return(p)
}

info_heatmap <- function(m_df, family_facet){
  p <- myHeatmap(m_df, family_facet)
  p <- p + scale_fill_manual(
             values = c('white', 'black')
           )
  p <- p + theme(
             axis.text.y = element_blank(),
             axis.ticks.y = element_blank(),

             panel.border=element_blank(),
             panel.grid.major=element_blank(),

             strip.background = element_blank(),
             strip.text.x = element_blank(),
             strip.text.y = element_blank(),
             )
  return(p)
}
#+end_src
** Trans. and Het. Heatmaps by Strain
#+begin_src R
#### Transcription and Hetterochrom. By Strain Heatmaps ####

all_transcov_df <- finalFC_df %>%
  left_join(positive_cov_df, by = 'Gene_id') %>%
  left_join(info_df, by = 'Gene_id')

finalHeatmap <- function(
                         contrast,
                         het_col,
                         abs_trans_filter,
                         abs_het_filter,
                         family,
                         family_facet
                         ) {

  ## contrast <- c('A7', 'E5')
  ## het_col <- 'Cov_1000fp_500orf'
  ## abs_trans_filter <- 2
  ## abs_het_filter <- 0
  ## family_facet <- F
  ## family <- NA

  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')
  het_col_1 <- paste0(het_col, '_', contrast[1])
  het_col_2 <- paste0(het_col, '_', contrast[2])
  difgenes <- paste0('difs_', contrast[1], '_', contrast[2])

  subset_all <- all_transcov_df %>%
    mutate(Het_dif = get(het_col_1) - get(het_col_2)) %>%
    ## filter(abs(get(trans_col)) > abs_trans_filter &
    ##        (abs(Het_dif) > abs_het_filter | is.na(Het_dif))) %>%
    filter(Gene_id %in% get(difgenes) &
           (abs(Het_dif) >= abs_het_filter | is.na(Het_dif))) %>%
    select(Gene_id,
           matches(trans_col),
           matches(het_col_1),
           matches(het_col_2),
           Het_dif,
           Label, Name, Annot, Family, SubFamily, Gam_specific
           )

  subset_all %>% filter(Gene_id == 'PF3D7_0813300') %>%
    print(width = 999)

  ## Subset by family is needed
  if (!is.na(family)){
    subset_all <- subset_all %>%
      filter(Family == family)
  }

  ## Ordering
  if (sorting == 'clust') {
    mtx <- subset_all %>%
      select(where(is.numeric))

    ## Make hierarquical Clustering
    dmtx <- dist(scale(mtx), method = "euclidean")
    cl <- hclust(dmtx, method = 'average')
    subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$order])

  } else if (sorting == 'trans') {
    subset_all <- subset_all %>%
      arrange(desc(get(trans_col))) %>%
      mutate(Label = factor(Label, levels = Label))

  } else if (sorting == 'het') {
    subset_all <- subset_all %>%
      arrange(desc(Het_dif)) %>%
      mutate(Label = factor(Label, levels = Label))
  }

  df_name <- paste0(
    plots_dir,
    'Trans_Het_byStrain/',
    contrast[1], '_',
    contrast[2], '_',
    het_col, '_',
    'transth_', as.character(abs_trans_filter),
    '_new.csv'
  )
  sorted_df <- subset_all %>% arrange(fct_rev(Label))
  write_csv(sorted_df, df_name)

  subset_trans <- subset_all %>%
    select(Gene_id, matches(trans_col), Label, Name, Annot, Family, SubFamily, Gam_specific)

  subset_het <- subset_all %>%
    select(Gene_id, matches(het_col_1), matches(het_col_2), Label, Name, Annot, Family, SubFamily, Gam_specific)

  subset_het %>%
    print(width = 200)

  subset_hetDif <- subset_all %>%
    select(Gene_id, Het_dif, Label, Name, Annot, Family, SubFamily, Gam_specific)

  subset_info <- subset_all %>%
    select(Gene_id, Gam_specific, Label, Name, Annot, Family, SubFamily)

  melt_vars <- c('Gene_id', 'Label', 'Name', 'Annot', 'Family', 'SubFamily', 'Gam_specific')

  mdf_het <- melt(subset_het, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)
  mdf_info <- melt(subset_info, id.vars = c('Gene_id', 'Label', 'Name', 'Annot', 'Family', 'SubFamily'))

  het_plot <- hetHeatmap(mdf_het, family_facet) +
    theme(
      axis.text.y = element_text(),
      axis.ticks.y = element_line(),
      axis.text.x = element_blank()
    )
  trans_plot <- transHeatmap(mdf_trans, family_facet)
  hetDif_plot <- hetDifHeatmap(mdf_hetDif, family_facet)
  info_plot <- info_heatmap(mdf_info, family_facet)

  all_plot <- grid.arrange(
    trans_plot, hetDif_plot, het_plot, #info_plot,
    nrow = 1, widths = c(1,1,3))

  outname <- paste0(
    plots_dir,
    'Trans_Het_byStrain/',
    contrast[1], '_',
    contrast[2], '_',
    het_col, '_',
    'transth_', as.character(abs_trans_filter),
    '_new.pdf'
  )
  print(outname)
  ggsave(outname, all_plot, device = 'pdf')
}


colnames(cor_cov_df)

contrast <- c('12B', '10G')
het_col <- 'Cov_1000fp_500orf'
abs_trans_filter <- 2
abs_het_filter <- 0
family_facet <- F
family <- NA

## trans, het or clust
sorting <- 'trans'
plt <- finalHeatmap(contrast, het_col, abs_trans_filter, abs_het_filter, family, family_facet)
het_trans_12b_10g <- read_csv(paste0(
  plots_dir, 'Trans_Het_byStrain/',
  '12B_10G_Cov_1000fp_500orf_transth_2.csv'
))

cor(het_trans_12b_10g$`12B-10G_MaxVal`, het_trans_12b_10g$Het_dif)
cor.test(het_trans_12b_10g$`12B-10G_MaxVal`, het_trans_12b_10g$Het_dif)

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

for (contrast in contrasts){
  het_col <- 'Cov_1000fp_500orf'
  abs_trans_filter <- 2
  abs_het_filter <- 0
  family_facet <- F
  family <- NA
  finalHeatmap(contrast, het_col, abs_trans_filter, abs_het_filter, family, family_facet)
}


het_trans_e5_B11 <- read_csv(paste0(
  plots_dir, 'Trans_Het_byStrain/',
  'E5_B11_Cov_1000fp_500orf_transth_2_new.csv'
))

difs_E5_B11
get('difs_E5_B11')

het_trans_e5_B11$Gene_id[!het_trans_e5_B11$Gene_id %in% difs_E5_B11]
difs_E5_B11[!difs_E5_B11 %in% het_trans_e5_B11$Gene_id]


finalFC_df %>%
  filter(Gene_id == 'PF3D7_0813300') %>%
  print(width = 999)

filtered_E5_B11 %>%
  filter(Gene_id == 'PF3D7_0813300') %>%
  print(width = 999)

all_transcov_df %>%
  filter(Gene_id == 'PF3D7_0813300') %>%
  print(width = 999) %>%
  select(Gene_id, Cov_1000fp_500orf_E5, Cov_1000fp_500orf_B11) %>%
  print(width = 999)


#+end_src
** Difpeaks Analysis
#+begin_src R
#### 1.2B vs 10G SICER Peaks Heatmap ####
#+end_src
*** Load Data
#+begin_src R
## Load Data

read_cov <- function(strain){
  cov_5p <- read_tsv(
    paste0(coverage_dir,
           'binned_1000tss_0orf_allowoverlaps_False_coverage_',
           strain,
           '.bed'
           ),
    col_names = F
  ) %>%
    select(X4, X5) %>%
    set_names(c('Gene_id', 'Cov_5p'))

  cov_ORF1 <- read_tsv(
    paste0(coverage_dir,
           'binned_CDS_first_half_coverage_',
           strain,
           '.bed'
           ),
    col_names = F
  ) %>%
    select(X4, X5) %>%
    set_names(c('Gene_id', 'Cov_ORF1'))

  cov_ORF2 <- read_tsv(
    paste0(coverage_dir,
           'binned_CDS_second_half_coverage_',
           strain,
           '.bed'
           ),
    col_names = F
  ) %>%
    select(X4, X5) %>%
    set_names(c('Gene_id', 'Cov_ORF2'))

  cov_3p <- read_tsv(
    paste0(coverage_dir,
           'binned_3prime1000_allowoverlaps_False_coverage_',
           strain,
           '.bed'
           ),
    col_names = F
  ) %>%
    select(X4, X7) %>%
    set_names(c('Gene_id', 'Cov_3p'))

  sicer_cov_ <- cov_5p %>%
    left_join(cov_ORF1) %>%
    left_join(cov_ORF2) %>%
    left_join(cov_3p)
}

make_difpeaks_hetdif_df <- function(strain1, strain2){

  undotted1 <- gsub('.', '', strain1, fixed = T)
  undotted1 <- gsub('K9', '', undotted1, fixed = T)

  undotted2 <- gsub('.', '', strain2, fixed = T)
  undotted2 <- gsub('K9', '', undotted2, fixed = T)

  cov_1 <- read_cov(strain1)
  cov_2 <- read_cov(strain2)

  subtraction_cov <- tibble(cov_1[,-1] - cov_2[,-1]) %>%
    mutate(Gene_id = cov_1$Gene_id) %>%
    select(Gene_id, everything())

  x <- difpeaks_df %>%
    select(Gene_id, contains(undotted1) & contains(undotted2))

  difpeaks <- x %>%
    set_names('Gene_id', 'dp1', 'dp2') %>%
    filter(dp1 | dp2) %>%
    pull(Gene_id)

  heat_df <- subtraction_cov %>%
    filter(Gene_id %in% difpeaks) %>%
    left_join(trans_df %>%
              select(
                Gene_id,
                contains(undotted1) & contains(undotted2) & contains('MaxVal')
              ) %>%
              set_names(c('Gene_id', 'Trans'),
                        ), by = 'Gene_id') %>%
    left_join(info_df %>% select(
                            Gene_id,
                            Label,
                            contains('DuplDel') & contains(undotted1),
                            contains('DuplDel') & contains(undotted2),
                            Gam_specific,
                            Annot
                          ) %>%
              set_names(c('Gene_id', 'Label',
                          'DuplDel_1', 'DuplDel_2',
                          'Gam_Specific', 'Annot'),
                        ), by = 'Gene_id') %>%
    select(Gene_id, Trans, everything()) %>%
    arrange(-Trans) %>%
    mutate(Label = factor(Label, levels = Label))

  heat_df %>%
    select(Gene_id, Trans, Annot) %>%
    filter(is.na(Trans)) %>%
    write_csv(paste0(
      tables_dir, 'figure3_',
      undotted1, '_', undotted2,
      '_notrans.csv'))

  sicer_heat_df <- heat_df %>%
    filter(!is.na(Trans)) %>%
    filter(!DuplDel_1) %>%
    filter(!DuplDel_2) %>%
    select(-DuplDel_1, -DuplDel_2)

  return(sicer_heat_df)
}
#+end_src
*** Make Heatmap
#+begin_src R
make_difpeaks_heat <- function(df, strain1, strain2){

  undotted1 <- gsub('.', '', strain1, fixed = T)
  undotted1 <- gsub('K9', '', undotted1, fixed = T)

  undotted2 <- gsub('.', '', strain2, fixed = T)
  undotted2 <- gsub('K9', '', undotted2, fixed = T)

  mtx <- df %>%
    select(Cov_5p, Cov_ORF1)

  ## Make hierarquical Clustering
  dmtx <- dist(mtx, method = "euclidean")
  cl <- hclust(dmtx, method = 'complete')
  df$Label <- factor(df$Label, levels = df$Label[cl$order])

  sorted_df <- df %>% arrange(fct_rev(Label))
  outname <- paste0(
    plots_dir, 'Trans_Het_byStrain/',
    'difpeaks_',
    undotted1, '_', undotted2,
    '_heatmap_nonas_hc_5pORF1.csv'
  )
  write_csv(sorted_df, outname)

  x <- df %>%
    pivot_longer(c(-Gene_id, -Label, -Annot)) %>%
    mutate(name = factor(name, levels = unique(name))) %>%
    filter(grepl('Cov', name))

  y <- df %>%
    pivot_longer(c(-Gene_id, -Label, -Annot)) %>%
    mutate(name = factor(name, levels = unique(name))) %>%
    filter(grepl('Trans', name))

  z <- df %>%
    pivot_longer(c(-Gene_id, -Label, -Annot)) %>%
    mutate(name = factor(name, levels = unique(name))) %>%
    filter(grepl('Gam', name))

  p1 <- ggplot(x, aes(x = name, y = Label, fill = value))
  p1 <- p1 + geom_tile(colour="snow3")
  p1 <- p1 + scale_fill_gradient2(
               low = "chartreuse3",
               mid = "white",
               high = "darkred",
               midpoint = 0,
               limits = c(-4, 4),
               oob=squish
             )
  p1 <- p1 + theme(
               ##axis.text.x = element_blank(),
               axis.ticks.x = element_blank(),
               axis.title.y = element_blank(),
               axis.text.y = element_blank(),
               axis.ticks.y = element_blank(),
               panel.grid.major=element_blank(),
               panel.background=element_blank(),
               legend.position = 'bottom'
             )
  p1 <- p1 + labs(y = '', x = '')

  p2 <- ggplot(y, aes(x = name, y = Label, fill = value))
  p2 <- p2 + geom_tile(colour="snow3")
  p2 <- p2 + scale_fill_gradient2(
               low = "blue",
               mid = "black",
               high = "Yellow",
               midpoint = 0,
               limits = c(-4, 4),
               oob=squish
             )
  p2 <- p2 + theme(
               ##axis.text.x = element_blank(),
               axis.ticks.x = element_blank(),
               axis.text.y = element_blank(),
               axis.ticks.y = element_blank(),
               axis.title.y = element_blank(),
               panel.grid.major=element_blank(),
               panel.background=element_blank(),
               legend.position = 'bottom'
             )
  p2 <- p2 + labs(y = '', x = '')

  p3 <- ggplot(z, aes(x = name, y = Label, fill = value))
  p3 <- p3 + geom_tile(colour="snow3")
  p3 <- p3 + scale_fill_gradient(
               low = "white",
               high = "Black",
               )
  p3 <- p3 + scale_y_discrete(position = "right")
  p3 <- p3 + theme(
               ##axis.text.x = element_blank(),
               axis.ticks.x = element_blank(),
               panel.grid.major=element_blank(),
               panel.background=element_blank(),
               legend.position = 'bottom'
             )
  p3 <- p3 + labs(y = '', x = '')

  difpeaks_plot <- ggarrange(p1, p2, p3, ncol = 3, nrow = 1, widths = c(4, 1, 3))
  difpeaks_plot
  ggsave(paste0(
    plots_dir, 'Trans_Het_byStrain/',
    'difpeaks_',
    undotted1, '_', undotted2,
    '_heatmap_nonas_hc_5pORF1.pdf'),
    difpeaks_plot,
    device = 'pdf',
    ##width = 30, units = 'cm'
    )
}

## Run all heatmaps

contrasts <- list(
  c('1.2B', '10G'),
  c('A7K9', 'E5K9'),
  c('A7K9', 'B11'),
  c('E5K9', 'B11')
)

for (contrast in contrasts){
  print(contrast)
  df <- make_difpeaks_hetdif_df(contrast[1], contrast[2])
  make_difpeaks_heat(df, contrast[1], contrast[2])
}

#+end_src
** Transcription Donut Plots
#+begin_src R
#### Transcription Donut Plots ####
## Donut Plot

contrasts_donuts <- function(contrast, het_col, trans_th, df){

  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')
  het_col_1 <- paste0(het_col, '_', contrast[1])
  het_col_2 <- paste0(het_col, '_', contrast[2])

  infocols <- colnames(info_df)

  x <- df %>%
    select(Gene_id,
           Family_Grouped,
           matches(trans_col),
           matches(het_col_1),
           matches(het_col_2),
           one_of(infocols)
           ) %>%
    filter(abs(get(trans_col)) > trans_th)
  data <- as.data.frame(table(x$Family_Grouped))
  colnames(data) <- c('category', 'count')

  ## Compute percentages
  data$fraction = data$count / sum(data$count)

  ## Compute the cumulative percentages (top of each rectangle)
  data$ymax = cumsum(data$fraction)

  ## Compute the bottom of each rectangle
  data$ymin = c(0, head(data$ymax, n=-1))

  ## Compute label position
  data$labelPosition <- (data$ymax + data$ymin) / 2

  ## Compute a good label
  data$label <- paste0(data$category, "\n value: ", data$count)

  ## Make the plot
  p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
    geom_rect(color="white") +
    ##geom_label( x=4.2, aes(y=labelPosition, label=label), size=3) +
    coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
    xlim(c(2, 4)) +# Try to remove that to see how to make a pie chart
    theme_void() + my_scale#scale_fill_viridis(discrete=TRUE)

  print(p)
  outname <- paste0(
    plots_dir,
    'Transcription_Donuts_ByStrain/',
    contrast[1], '_',
    contrast[2], '_',
    'families',
    '.svg'
  )

  ggsave(outname, p, device = 'svg')
}

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
  )

het_col <- 'Cov_1000fp_500orf'
contrast <-   c('12B', '10G')
trans_th <- 2
df <- trans_het_difpeaks_df

for(contrast in contrasts){
  print(contrast)
  contrasts_donuts(contrast, het_col, trans_th, df)
}
#+end_src
** Get coverage for ON/OFF genes with sign
We always get the same sample order in the contrasts (12B vs 10G, A7 vs B11...) both regarding transcription and coverage.
#+begin_src R
#### Get coverage for ON/OFF genes with sign ####
## Select transcription cols
## Create empty DF
hetcols <- colnames(cor_cov_df %>% select(contains('12B')))
hetcols <- str_replace(hetcols, '_12B', '')

col_names <- c('Gene_id',
               paste0(hetcols, '_On'),
               paste0(hetcols, '_Off'),
               paste0(hetcols, '_Dif'))

cn <- setNames(rep('', length(col_names)), col_names)
df <- bind_rows(cn)[0,]

## Traverse max trans. df and get coverage cols

## which(tdf$Gene_id == 'PF3D7_0100300')
## i <- 63
## tdf[63,]

for (i in 1:dim(finalFC_df)[1]){

  gid <- as.character(finalFC_df$Gene_id[i])
  on <- finalFC_df$On_trans[i]
  off <- finalFC_df$Off_trans[i]

  ## Select contrast in which difference sign must be switched
  contrast <- paste0(on, '-', off)
  positive_contrasts <- c(
    '12B-10G', '12B-A7', '12B-E5', '12B-B11',
    '10G-A7', '10G-E5', '10G-B11',
    'A7-E5', 'A7-B11',
    'E5-B11'
  )

  ifelse(
    contrast %in% positive_contrasts,
    neg_dif <- FALSE,
    neg_dif <- TRUE
    )

  ## Main Loop
  if (gid %in% cor_cov_df$Gene_id & !is.na(on) & !is.na(off)){

    onvect <- cor_cov_df %>%
      filter(Gene_id == gid) %>%
      select(contains(on))

    offvect <- cor_cov_df %>%
      filter(Gene_id == gid) %>%
      select(contains(off))

    diffvect <- onvect-offvect
    if (neg_dif) {diffvect <- -diffvect}

    row <- c(gid,
             unlist(onvect, use.names = F),
             unlist(offvect, use.names = F),
             unlist(diffvect, use.names = F))
    row <- setNames(row, col_names)
    df <- df %>% add_row(bind_rows(row))
  }
}

signed_maxtrans_cov <- df %>%
  mutate(across(-Gene_id,  as.numeric)) %>%
  full_join(finalFC_df, by = 'Gene_id') %>%
  left_join(info_df)

#+end_src
** Get coverage for ON/OFF genes unsigned
We always get the same sample order in the contrasts (12B vs 10G, A7 vs B11...) both regarding transcription and coverage.
#+begin_src R
#### Get coverage for ON/OFF genes unsigned ####
## Select transcription cols
## Create empty DF
hetcols <- colnames(cor_cov_df %>% select(contains('12B')))
hetcols <- str_replace(hetcols, '_12B', '')

col_names <- c('Gene_id',
               paste0(hetcols, '_On'),
               paste0(hetcols, '_Off'),
               paste0(hetcols, '_Dif'))

cn <- setNames(rep('', length(col_names)), col_names)
df <- bind_rows(cn)[0,]

## Traverse max trans. df and get coverage cols

## which(finalFC_df$Gene_id == 'PF3D7_0100300')
## i <- 63
## finalFC_df[63,]

for (i in 1:dim(finalFC_df)[1]){

  gid <- as.character(finalFC_df$Gene_id[i])
  on <- finalFC_df$On_trans[i]
  off <- finalFC_df$Off_trans[i]

  ## Select contrast in which difference sign must be switched
  ## contrast <- paste0(on, '-', off)
  ## positive_contrasts <- c(
  ##   '12B-10G', '12B-A7', '12B-E5', '12B-B11',
  ##   '10G-A7', '10G-E5', '10G-B11',
  ##   'A7-E5', 'A7-B11',
  ##   'B11-E5'
  ## )

  ## ifelse(
  ##   contrast %in% positive_contrasts,
  ##   neg_dif <- FALSE,
  ##   neg_dif <- TRUE
  ##   )

  ## Main Loop
  if (gid %in% positive_cov_df$Gene_id & !is.na(on) & !is.na(off)){

    onvect <- positive_cov_df %>%
      filter(Gene_id == gid) %>%
      select(contains(on))

    offvect <- positive_cov_df %>%
      filter(Gene_id == gid) %>%
      select(contains(off))

    diffvect <- onvect-offvect
    #if (neg_dif) {diffvect <- -diffvect}

    row <- c(gid,
             unlist(onvect, use.names = F),
             unlist(offvect, use.names = F),
             unlist(diffvect, use.names = F))
    row <- setNames(row, col_names)
    df <- df %>% add_row(bind_rows(row))
  }
}

unsigned_maxtrans_cov <- df %>%
  mutate(across(-Gene_id,  as.numeric)) %>%
  full_join(finalFC_df, by = 'Gene_id') %>%
  mutate(Max_aMAFC = abs(Max_aMAFC)) %>%
  left_join(info_df)

genes_nocov <- unsigned_maxtrans_cov %>%
     select(Gene_id, contains('Cov_1000fp_500orf')) %>%
     filter(!complete.cases(.)) %>%
     select(Gene_id) %>% pull()

unsigned_maxtrans_cov %>%
  select(Gene_id, contains('Cov_1000fp_500orf')) %>%
  filter(!complete.cases(.)) %>%
  print(width = 400)
#+end_src
** Correlations ON/OFF genes
*** Get correlations ON/OFF genes
#+begin_src R
#### Correlations On/Off genes ####
## Get Correlations

cor_signed_maxtrans <- signed_maxtrans_cov %>%
  filter(!Is_3D7B)

## Subset column by column
clnms <- colnames(cor_signed_maxtrans %>% select(contains('_Dif')))
for (c in clnms) {
  print(c)
  cor_genes <- cor_signed_maxtrans %>%
    select(Max_aMAFC, matches(c)) %>%
    filter(abs(Max_aMAFC) > 1.5) %>%
    drop_na()

  cormtx <- cor(cor_genes, method = 'pearson')
  print(paste0('Number of genes: ', dim(cor_genes)[1]))
  print(as.data.frame(cormtx[,1]))
  print('------------------')
}

## All toghether

trans_th <- 2

cor_genes <- cor_signed_maxtrans %>%
  select(Max_aMAFC, contains('_Dif')) %>%
  filter(abs(Max_aMAFC) > trans_th) %>%
  drop_na()

cor_genes

cormtx <- cor(cor_genes, method = 'pearson')
print(paste0('Number of genes: ', dim(cor_genes)[1]))
print(as.data.frame(cormtx[,1]))

outdf <- as.data.frame(cormtx)
outdf['Corr_with'] <- rownames(outdf)
outdf <- outdf %>% select(Corr_with, everything())
outname = paste0(tables_dir, 'corr_MaxFC_', trans_th, '_allowoverlaps.csv')
write_csv(outdf, outname)

## By subsets

get_corr <- function(df){
  cor_genes <- df %>%
    select(-Gene_id) %>%
    filter(abs(Max_aMAFC) > trans_th) %>%
    drop_na()

  cormtx <- cor(cor_genes, method = 'pearson')
  print(paste0('Number of genes: ', dim(cor_genes)[1]))

  outdf <- as.data.frame(cormtx)
  outdf['Corr_with'] <- rownames(outdf)
  outdf <- outdf %>% select(Corr_with, everything())
  outdf <- as_tibble(outdf[,c(1,2)])
  print(outdf)
}

trans_th <- 2

## Abs bins
abs_bins <- cor_signed_maxtrans %>%
  select(Gene_id, Max_aMAFC,
         Cov_1500fp_manybins_Dif,
         Cov_1000fp_manybins_Dif,
         Cov_500fp_manybins_Dif,
         contains('ORF', ignore.case = F) & contains('Dif'),
         Cov_500tp_manybins_Dif,
         Cov_1000tp_manybins_Dif
         )

abs_bins_cor <- get_corr(abs_bins)

## Rel bins

rel_bins <- cor_signed_maxtrans %>%
  select(Gene_id, Max_aMAFC,
         p5utr_Cov_Dif,
         contains('qorf') & contains('Dif'),
         p3utr_Cov_Dif
         )

rel_bins_cor <- get_corr(rel_bins)

## TSS

tss_bins <- cor_signed_maxtrans %>%
  select(Gene_id, Max_aMAFC,
         TSS_Cov_Dif,
         Cov_500fp_manybins_Dif,
         p5utr_Cov_Dif
         )

tss_bins_cor <- get_corr(tss_bins)


## Plots

df <- cor_signed_maxtrans %>% filter(abs(Max_aMAFC) > trans_th)

for (c in clnms){
  p <- ggplot(df,
              aes(x = Max_aMAFC, y = get(c), color = Gam_specific)) +
    geom_point() +
    geom_label_repel(data=subset(df, get(c) > 1),
                     aes(label = Gene_id),
                     box.padding   = 0.35,
                     point.padding = 0.5,
                     segment.color = 'grey50')
  ggsave(paste0(plots_dir, 'MaxFC_Cor_Plots/cor_signed_maxFC_', c, '_allowoverlaps.png'), p, device = 'png')
}

#+end_src
*** Make correlation by bin plots STEP
#+begin_src R
#### Make correlation by bin plots STEP ####
corr_data <- as_tibble(outdf[,1:2])

corr_data %>%
  arrange(Max_aMAFC) %>%
  print(n = 40)

bins <- c(
  'Cov_2000fp_manybins_Dif',
  'Cov_1500fp_manybins_Dif',
  'Cov_1000fp_manybins_Dif',
  'Cov_500fp_manybins_Dif',
  'Cov_500orf_Dif',
  'Cov_1000orf_Dif',
  'Cov_1500orf_Dif',
  'Cov_500tp_manybins_Dif',
  'Cov_1000tp_manybins_Dif',
  'Cov_1500tp_manybins_Dif'
  )


## Geom_step approach

pos <- c(-2000, -1500, -1000, -500, 0, 500, 1000, 2500, 3000, 3500)

cor_bins <- corr_data %>%
  filter(Corr_with %in% bins) %>%
  arrange(factor(Corr_with, levels = bins)) %>%
  mutate(Pos = pos)

cor_bins

cor_bins2 <- cor_bins %>%
  add_row(Corr_with = 'start', Max_aMAFC = 0, Pos = -2500) %>%
  add_row(Corr_with = 'end_of_gene', Max_aMAFC = 0, Pos = 1500) %>%
  add_row(Corr_with = 'end', Max_aMAFC = 0, Pos = 4000) %>%
  add_row(Corr_with = 'endtail', Max_aMAFC = 0, Pos = 4500) %>%
  arrange(Pos)

xbreaks <- c(
  '',
  'ATG-2000',
  'ATG-1500',
  'ATG-1000',
  'ATG-500',
  'ATG',
  'ATG+500',
  'ATG+1000',
  'ATG+1500',
  'End',
  'End+500',
  'End+1000',
  'End+1500',
  ''
  )

p <- ggplot(cor_bins2, aes(x = Pos, y = -Max_aMAFC, group = 1)) +
  geom_step() +
  ylim(0, 1) +
  ylab('- Pearson Corr') + xlab('Region') +
  theme_minimal() +
  scale_x_continuous(breaks = cor_bins2$Pos, labels = xbreaks) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_vline(xintercept = 0, linetype = 'dashed', color = 'gray') +
  geom_vline(xintercept = 2500, linetype = 'dashed', color = 'gray')

p
ggsave(paste0(plots_dir, 'Correlations_Intervals/corr_genemodel_steps_allowoverlaps.png'), p, device = 'png')
#+end_src
*** Make correlation by bin plots BAR
#+begin_src R
#### Make correlation by bin plots BAR ####
## Geom Bar approach

cor_bins_plot <- function(df, labs, regions){
  corplot_df <- df %>%
    filter(Corr_with != 'Max_aMAFC') %>%
    mutate(Corr_with = factor(Corr_with, levels = Corr_with)) %>%
    arrange(Corr_with) %>%
    mutate(Labs = factor(labs, levels = labs)) %>%
    mutate(Region = regions)

  p <- ggplot(corplot_df, aes(x = Labs, y = -Max_aMAFC, color = Region)) +
    geom_boxplot(key_glyph = "point") +
    ylim(0, 1) +
    ylab('- Pearson Corr\n') + xlab('\nRegion') +
    theme_classic() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      text = element_text(size=30),
            legend.position = "none"
          )

  ggsave(
    paste0(plots_dir, 'Correlations_Intervals/', deparse(substitute(df)), '_allowoverlaps.pdf'),
    p, device = 'pdf')
  p
}


## Abs

labs = c(
  '-1500 to -1000',
  '-1000 to -500',
  '-500 to ATG',
  'ATG to 500',
  '500 to 1000',
  '1000 to 1500',
  'End to +500',
  '+500 to +1000'
)

regions = c(rep('5prime', 3), rep('ORF', 3), rep('3prime', 2))

cor_bins_plot(abs_bins_cor, labs, regions)

## Rel

labs = c(
  '5\'UTR',
  'ORF 1/4',
  'ORF 2/4',
  'ORF 3/4',
  'ORF 4/4',
  '3\'UTR'
)

regions = c(rep('5prime', 1), rep('ORF', 4), rep('3prime', 1))

cor_bins_plot(rel_bins_cor, labs, regions)

## TSS

labs = c(
  'TSS',
  '-500 to ATG',
  '5\'UTR'
)

regions = c(rep('5prime', 3), rep('ORF', 0), rep('3prime', 0))

cor_bins_plot(tss_bins_cor, labs, regions) + geom_boxplot(color = 'green')

#+end_src

*** Make correlation Heatmap
#+begin_src R
#### Make correlation On/Off genes Heatmap ####
trans_th <- 2

cor_signed_maxtrans

cor_genes <- cor_signed_maxtrans %>%
  select(Max_aMAFC, contains('_Dif')) %>%
  filter(abs(Max_aMAFC) > trans_th) %>%
  drop_na()

cor_genes

cormtx <- cor(cor_genes, method = 'pearson')
print(paste0('Number of genes: ', dim(cor_genes)[1]))
print(as.data.frame(cormtx[,1]))

outdf <- as.data.frame(cormtx)
outdf['Corr_with'] <- rownames(outdf)
outdf <- outdf %>% select(Corr_with, everything()) %>% as_tibble()

plotdf <- outdf %>% select(Corr_with, Max_aMAFC) %>% arrange(Max_aMAFC)
mplotdf <- melt(plotdf)
mplotdf$Corr_with <- factor(mplotdf$Corr_with, levels = mplotdf$Corr_with)

p <- ggplot(mplotdf, aes(x = variable, y = Corr_with)) +
  geom_tile(aes(fill = value)) +
  geom_text(aes(label=value)) +
  scale_fill_gradient2(low = "chartreuse3",
                       mid = "white",
                       high = "darkred",
                       na.value="grey90")

#p
ggsave(paste0(plots_dir, 'Correlations_Intervals/ranked_intervals_heatmap.png'))


#+end_src
** Gene Model Analysis
*** Load Data
#+begin_src R
#### Gene-Model Analysis: Load Data ####
## Coverage

gm_12B <- read_csv(paste0(
  genemodel_dir,
  '1.2B_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10_5binned_cov_2prevpost.csv'
))
gm_10G <- read_csv(paste0(
  genemodel_dir,
  '10G_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10_5binned_cov_2prevpost.csv'
))
gm_A7 <- read_csv(paste0(
  genemodel_dir,
  'A7K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10_5binned_cov_2prevpost.csv'
))
gm_E5 <- read_csv(paste0(
  genemodel_dir,
  'E5K9_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10_5binned_cov_2prevpost.csv'
))
gm_B11 <- read_csv(paste0(
  genemodel_dir,
  'B11_me_sort_q5_noDup_rpkm_normInput_bs10_smth200_pseudo10_5binned_cov_2prevpost.csv'
))


gm_strains <- list(
  df12B=gm_12B,
  df10G=gm_10G,
  dfA7=gm_A7,
  dfE5=gm_E5,
  dfB11=gm_B11
)

## Change dfs in a list
gm_strains <- lapply(gm_strains, function(df) {
    colnames(df)[1] <- "Gene_id"
    df
})

## Convert list into individual objects again
list2env(gm_strains, envir=.GlobalEnv)

##Create numeric non-na mtxs
nona.mtxs <- lapply(gm_strains, function(df) {
    mtx <- as.matrix(df[complete.cases(df),-1])
    rownames(mtx) <- df[complete.cases(df),1] %>% pull()
    mtx
})

nona_gm_strains <- lapply(gm_strains, function(tibble) {
  tibble %>%
    filter(complete.cases(tibble))
  tibble
})


names(nona.mtxs) <- c("mtx12B", "mtx10G", 'mtxA7', 'mtxE5', 'mtxB11')
names(nona_gm_strains) <- c('nona_12B', 'nona_10G', 'nona_A7', 'nona_E5', 'nona_B11')

## Create side-by-side matrices
#mtx_12b10g <- cbind(nona.mtxs$mtx12B, nona.mtxs$mtx10G)

mtx_all <- cbind(
  nona.mtxs$mtx12B,
  nona.mtxs$mtx10G,
  nona.mtxs$mtxA7,
  nona.mtxs$mtxE5,
  nona.mtxs$mtxB11
)

colnames(mtx_all) <- 1:dim(mtx_all)[2]

bins <- paste0('bin', c(1:23))
all_cols <- c(
  paste0(bins, '_12B'),
  paste0(bins, '_10G'),
  paste0(bins, '_A7'),
  paste0(bins, '_E5'),
  paste0(bins, '_B11')
)

gmodel_all <- gm_strains$df12B %>%
  full_join(gm_strains$df10G, by = 'Gene_id') %>%
  full_join(gm_strains$dfA7, by = 'Gene_id') %>%
  full_join(gm_strains$dfE5, by = 'Gene_id') %>%
  full_join(gm_strains$dfB11, by = 'Gene_id') %>%
  setNames(c('Gene_id', all_cols))

nona_gm_all <- gmodel_all %>%
  filter(complete.cases(gmodel_all))
#+end_src
*** PCA
#+begin_src R
#### Gene-Model Analysis: PCAs ####
## Filtered Differential Genes
gm_trans <- finalFC_df %>%
  left_join(gmodel_all) %>%
  left_join(info_df) %>%
  filter(across(contains('bin'), complete.cases))

gm_trans_mtx <- gm_trans %>%
  select(contains('bin'))

gm_trans_pca <- prcomp(gm_trans_mtx)
gm_trans_df <- as_tibble(gm_trans_pca$x[, c(1,2)])
gm_trans <- bind_cols(gm_trans_df,  gm_trans)

#### PCA plots ####
## All-genes, transcription filter
p <- ggplot(gm_trans, aes(x=PC1, y=PC2, color = Family_Grouped))
p <- p + geom_point() + my_scale2
##p
ggsave(paste0(plots_dir, 'Gene_Model/PCAs/pca_families.svg'), p, device = 'svg')

p <- ggplot(gm_trans, aes(x=PC1, y=PC2, color = Gam_specific))
p <- p + geom_point()
##p
ggsave(paste0(plots_dir, 'Gene_Model/PCAs/pca_gametocytes.svg'), p, device = 'svg')

p <- ggplot(gm_trans, aes(x=PC1, y=PC2, color = Max_aMAFC))
p <- p + geom_point()
p <- p + scale_color_gradient2(midpoint = 0, low="red", mid = "black", high="green")
##p
ggsave(paste0(plots_dir, 'Gene_Model/PCAs/pca_transcription.svg'), p, device = 'svg')

#+end_src
*** Max trans Dif. Approach
#+begin_src R
#### Gene-Model Analysis: Max. trans Dif. Approach ####
tdf <- maxDif_df %>%
  filter(!Is_tRNA) %>%
  select(Gene_id, Max_aMAFC, On_trans, Off_trans, Is_3D7B)

gmodel_all_pos <- gmodel_all %>%
  mutate(across(-Gene_id, ~ ifelse(.x > 0, .x, 0)))

## Create empty DF
hetcols <- gmodel_all %>%
  select(contains('12B') & contains('bin')) %>%
  colnames(.) %>%
  gsub('12B', '', ., fixed=TRUE)

col_names <- c('Gene_id',
               paste0(hetcols, 'On'),
               paste0(hetcols, 'Off'),
               paste0(hetcols, 'Dif'))

cn <- setNames(rep('', length(col_names)), col_names)
df <- bind_rows(cn)[0,]

## Traverse max trans. df and get coverage cols

for (i in 1:dim(tdf)[1]){

  gid <- as.character(tdf$Gene_id[i])
  on <- tdf$On_trans[i]
  off <- tdf$Off_trans[i]

  ## Select contrast in which difference sign must be switched
  ## contrast <- paste0(on, '-', off)
  ## positive_contrasts <- c(
  ##   '12B-10G', '12B-A7', '12B-E5', '12B-B11',
  ##   '10G-A7', '10G-E5', '10G-B11',
  ##   'A7-E5', 'A7-B11',
  ##   'B11-E5'
  ## )

  ## ifelse(
  ##   contrast %in% positive_contrasts,
  ##   neg_dif <- FALSE,
  ##   neg_dif <- TRUE
  ## )

  ### Main Loop
  if (gid %in% gmodel_all_pos$Gene_id & !is.na(on) & !is.na(off)){

    onvect <- gmodel_all_pos %>%
      filter(Gene_id == gid) %>%
      select(contains(on))

    offvect <- gmodel_all_pos %>%
      filter(Gene_id == gid) %>%
      select(contains(off))

    diffvect <- onvect-offvect
    #if (neg_dif) {diffvect <- -diffvect}

    row <- c(gid,
             unlist(onvect, use.names = F),
             unlist(offvect, use.names = F),
             unlist(onvect-offvect, use.names = F))
    row <- setNames(row, col_names)
    df <- df %>% add_row(bind_rows(row))
  }
}

df <- df %>%
  mutate(across(-Gene_id, as.numeric))

gm_pos_maxtrans <- df %>%
  full_join(tdf, by = 'Gene_id') %>%
  left_join(info_df) %>%
  mutate(Max_aMAFC = abs(Max_aMAFC))
#+end_src
*** K-Means Heatmap Functions
#+begin_src R
#### Gene-Model Analysis: K-Means Heatmap Functions ####
my_info_heatmap <- function(m_df, family_facet){
  p <- myHeatmap(m_df, family_facet)
  p <- p + scale_fill_manual(
             values = c('white', 'black')
           )
  p <- p + theme(
             axis.text.y = element_blank(),
             axis.ticks.y = element_blank(),

             panel.border=element_blank(),
             panel.grid.major=element_blank(),

             strip.background = element_blank(),
             strip.text.x = element_blank(),
             strip.text.y = element_blank(),
             )
  return(p)
}

test_kmeans <- function(mtx){

  ## Set max k for k analysis
  maxk <- mtx %>% distinct() %>% nrow()
  maxk <- min(maxk, 20)

  ## Elbow method, keep reducing maxk if it fails
  while (maxk > 0) {
    test <- try(
      ## elbow plot
      elbow <- fviz_nbclust(mtx, kmeans, method = "wss", k.max = maxk) +
        labs(subtitle = "Elbow method")
    , silent = T)
    ## If kmax throws an error, reduce it by 1
    if (class(test)[1] != "gg") {
      maxk <- maxk -1
    } else {
      break
    }
  }

  ## Silhouette method (if kmax works for elbow it will work for silhouette)
  silhouette <- fviz_nbclust(mtx, kmeans, method = "silhouette", k.max = maxk) +
    labs(subtitle = "Silhouette method")

  result = list(elbow = elbow, silhouette = silhouette)
}

heatMap_allstrains_kmeans <- function(df, aFC_th, fam, fam_facet, nclu, tbar, fbar, labels){

  ## set.seed(123)
  ## df <- kmeans_df
  ## aFC_th <- 2
  ## fam <- NA
  ## fam_facet <- F
  ## nclu <- 7
  ## tbar <- T
  ## fbar <- T

  ## Returns a list object with list = (df, plot)

  subset_all <- df %>%
    filter(abs(Max_aMAFC) > aFC_th)

  subset_all %>%
    select(Gene_id, Max_aMAFC)

  if (!is.na(fam)){
    subset_all <- subset_all %>%
      filter(Family == fam)
  }

  ## subset_all <- subset_all %>%
  ##   filter(across(
  ##     contains('bin'),
  ##     complete.cases
  ##   ))

  mtx <- subset_all %>%
    select(contains('bin'),
           -contains('bin1_'),
           -contains('bin2_'),
           -contains('bin3_'),
           -contains('bin4_'),
           -contains('bin20_'),
           -contains('bin21_'),
           -contains('bin22_'),
           -contains('bin23_'),
           )
    #select(contains('On'), contains('Off'))
    #select(contains('Dif'))

  ## Make K-means Clustering

  km_fit <- kmeans(mtx, nclu, iter.max = 100000)
  cl <- km_fit$cluster
  subset_all['Cluster'] <- cl
  subset_all <- subset_all %>%
    mutate(Cluster = case_when(
             Cluster == 1 ~ 1,
             Cluster == 2 ~ 7,
             Cluster == 3 ~ 2,
             Cluster == 4 ~ 4,
             Cluster == 5 ~ 6,
             Cluster == 6 ~ 3,
             Cluster == 7 ~ 5,
             )) %>%
    arrange(Cluster) %>%
    mutate(Label = factor(Label, levels = rev(Label)))
  ## We use rev() because for some reason, order gets reversed inside facets.

  ## Test optimal k's
  k_tests <- test_kmeans(mtx)
  elbow <- k_tests$elbow
  silhouette <- k_tests$silhouette

  ## Subset DF for different heatmaps

  subset_trans <- subset_all %>%
    select(Gene_id, Max_aMAFC, Label, Name, Annot, Family, SubFamily, Cluster)

  subset_het_on <- subset_all %>%
    select(Gene_id, Label,
           contains('On') & contains('bin'),
           Name, Annot, Family, SubFamily, Cluster)

  subset_het_off <- subset_all %>%
    select(Gene_id, Label,
           contains('Off') & contains('bin'),
           Name, Annot, Family, SubFamily, Cluster)

  subset_hetDif <- subset_all %>%
    select(Gene_id, contains('_Dif'), Label, Name, Annot, Family, SubFamily, Cluster)

  subset_fambar <- subset_all %>%
    select(Gene_id, Label,
           Family_Grouped,
           Name, Annot, Family, SubFamily, Cluster) %>%
    #mutate(Label = factor(Label, levels = Label)) %>%
    replace_na(list(Family_Grouped = 'Non CVGs'))

  subset_info <- subset_all %>%
    select(
      Gene_id, Gam_specific, Label, Name, Annot, Family, SubFamily, Cluster
    )

  ## Melt Data-Frames

  melt_vars <- c('Gene_id', 'Label', 'Name', 'Annot', 'Family', 'SubFamily', 'Cluster')
  mdf_het_on <- melt(subset_het_on, id.vars = melt_vars)
  mdf_het_off <- melt(subset_het_off, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)
  mdf_fambar <- melt(subset_fambar, id.vars = melt_vars)
  mdf_info <- melt(subset_info, id.vars = melt_vars)

  head(mdf_fambar)

  ## Create individual Heatmaps

  het_plot_on <- hetHeatmap(mdf_het_on, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(axis.text.x = element_blank())

  het_plot_off <- hetHeatmap(mdf_het_off, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")+
    theme(axis.text.x = element_blank())

  trans_plot <- transHeatmap(mdf_trans, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(axis.text.x = element_blank()) +
    ## scale_fill_gradient(low = "white",
    ##                     high = "blue",
    ##                     na.value="gray",
    ##                     limits = c(0,NA))
    scale_fill_gradient2(
      low = "yellow",
      mid = 'white',
      high = "blue",
      na.value="black"
    )

  hetDif_plot <- hetDifHeatmap(mdf_hetDif, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(axis.text.x = element_blank())

  fambar_plot <- family_heatmap(mdf_fambar) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")

  info_plot <- my_info_heatmap(mdf_info, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")

  ## Create fake Heatmap for Labels

  labels_df <- mdf_trans %>%
    select(Label, Family, Cluster) %>%
    mutate(value = 1, variable = 'fake_val')

  labels_plot <- hetHeatmap(labels_df, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")  +
    theme(
      axis.text.y = element_text(),
      axis.ticks.y = element_line(),
      axis.text.x = element_blank()
    )

  ## Arrange plots (with or without transcription heatmap and fambar)

  pl_wd <- tibble(
    P_names = c('trans', 'het_dif', 'het_on', 'het_off', 'fambar', 'info_plot', 'labels'),
    Plots = list(
      trans_plot,
      hetDif_plot,
      het_plot_on,
      het_plot_off,
      fambar_plot,
      info_plot,
      labels_plot),
    widths = c(0.1,1,1,1,0.1,0.1,1)
  )

  if (!tbar){pl_wd <- pl_wd %>% filter(P_names != 'trans')}
  if (!fbar){pl_wd <- pl_wd %>% filter(P_names != 'fambar')}
  if (!labels){pl_wd <- pl_wd %>% filter(P_names != 'labels')}

  all_plot <- grid.arrange(grobs = pl_wd$Plots, nrow = 1, widths = pl_wd$widths)

  ## Create output
  result <- list(df = subset_all, plot = all_plot, elbow = elbow, silhouette = silhouette)
  return(result)
}


heatMap_families_kmeans <- function(df, aFC_th, fam, fam_facet, nclu, tbar, fbar, labels){

  ## df <- gm_pos_maxtrans %>%
  ##   mutate(Label <- paste(Gene_id, SubFamily, sep <- ': '))
  ## aFC_th <- 0
  ## fam <- 'ACS'
  ## fam_facet <- F
  ## nclu <- as.numeric(fam_k[2])
  ## tbar <- T
  ## fbar <- F
  ## labels <- F

  ## Returns a list object with list = (df, plot)

  subset_all <- df %>%
    filter(abs(Max_aMAFC) > aFC_th)

  subset_all %>%
    select(Gene_id, Max_aMAFC)

  if (!is.na(fam)){
    subset_all <- subset_all %>%
      filter(Family == fam)
  }

  subset_all <- subset_all %>%
    filter(across(
      contains('bin'),
      complete.cases
    ))

  mtx <- subset_all %>%
    select(contains('bin'),
           -contains('bin1_'),
           -contains('bin2_'),
           -contains('bin3_'),
           -contains('bin4_'),
           -contains('bin20_'),
           -contains('bin21_'),
           -contains('bin22_'),
           -contains('bin23_'),
           )
    #select(contains('On'), contains('Off'))
    #select(contains('Dif'))

  ## Make K-means Clustering

  km_fit <- kmeans(mtx, nclu, iter.max = 100000)
  cl <- km_fit$cluster
  subset_all['Cluster'] <- cl
  subset_all <- subset_all %>%
    mutate(Cluster = case_when(
             Cluster == 1 ~ 1,
             Cluster == 2 ~ 7,
             Cluster == 3 ~ 2,
             Cluster == 4 ~ 4,
             Cluster == 5 ~ 6,
             Cluster == 6 ~ 3,
             Cluster == 7 ~ 5,
             )) %>%
    arrange(Cluster) %>%
    mutate(Label = factor(Label, levels = rev(Label)))
  ## We use rev() because for some reason, order gets reversed inside facets.

  ## Test optimal k's
  k_tests <- test_kmeans(mtx)
  elbow <- k_tests$elbow
  silhouette <- k_tests$silhouette

  ## Subset DF for different heatmaps

  subset_trans <- subset_all %>%
    select(Gene_id, Max_aMAFC, Label, Name, Annot, Family, SubFamily, Cluster)

  subset_het_on <- subset_all %>%
    select(Gene_id, Label,
           contains('On') & contains('bin'),
           Name, Annot, Family, SubFamily, Cluster)

  subset_het_off <- subset_all %>%
    select(Gene_id, Label,
           contains('Off') & contains('bin'),
           Name, Annot, Family, SubFamily, Cluster)

  subset_hetDif <- subset_all %>%
    select(Gene_id, contains('_Dif'), Label, Name, Annot, Family, SubFamily, Cluster)

  subset_fambar <- subset_all %>%
    select(Gene_id, Label,
           Family_Grouped,
           Name, Annot, Family, SubFamily, Cluster) %>%
    #mutate(Label = factor(Label, levels = Label)) %>%
    replace_na(list(Family_Grouped = 'Non CVGs'))

  subset_info <- subset_all %>%
    select(
      Gene_id, Gam_specific, Label, Name, Annot, Family, SubFamily, Cluster
    )

  ## Melt Data-Frames

  melt_vars <- c('Gene_id', 'Label', 'Name', 'Annot', 'Family', 'SubFamily', 'Cluster')
  mdf_het_on <- melt(subset_het_on, id.vars = melt_vars)
  mdf_het_off <- melt(subset_het_off, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)
  mdf_fambar <- melt(subset_fambar, id.vars = melt_vars)
  mdf_info <- melt(subset_info, id.vars = melt_vars)

  head(mdf_fambar)

  ## Create individual Heatmaps

  het_plot_on <- hetHeatmap(mdf_het_on, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")
    #theme(axis.text.x = element_blank(), legend.position="none")

  het_plot_off <- hetHeatmap(mdf_het_off, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")
    #theme(axis.text.x = element_blank(), legend.position="none")

  trans_plot <- transHeatmap(mdf_trans, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")
    #theme(axis.text.x = element_blank(), legend.position="none")

  hetDif_plot <- hetDifHeatmap(mdf_hetDif, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")
    #theme(axis.text.x = element_blank(), legend.position="none")

  fambar_plot <- family_heatmap(mdf_fambar) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")
    #theme(legend.position="none")

  info_plot <- my_info_heatmap(mdf_info, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")
    #theme(axis.text.x = element_blank(),legend.position="none")

  ## Create fake Heatmap for Labels

  labels_df <- mdf_trans %>%
    select(Label, Family, Cluster) %>%
    mutate(value = 1, variable = 'fake_val')

  labels_plot <- hetHeatmap(labels_df, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(
      axis.text.y = element_text(),
      axis.ticks.y = element_line(),
      axis.text.x = element_blank()
    )
    #theme(legend.position="none")

  ## Arrange plots (with or without transcription heatmap and fambar)

  pl_wd <- tibble(
    P_names = c('trans', 'het_dif', 'het_on', 'het_off', 'fambar', 'info_plot', 'labels'),
    Plots = list(
      trans_plot,
      hetDif_plot,
      het_plot_on,
      het_plot_off,
      fambar_plot,
      info_plot,
      labels_plot),
    widths = c(0.1,1,1,1,0.1,0.1,1)
  )

  if (!tbar){pl_wd <- pl_wd %>% filter(P_names != 'trans')}
  if (!fbar){pl_wd <- pl_wd %>% filter(P_names != 'fambar')}
  if (!labels){pl_wd <- pl_wd %>% filter(P_names != 'labels')}

  all_plot <- grid.arrange(grobs = pl_wd$Plots, nrow = 1, widths = pl_wd$widths)

  ## Create output
  result <- list(df = subset_all, plot = all_plot, elbow = elbow, silhouette = silhouette)
  return(result)
}


#+end_src
*** K-means clustering
#+begin_src R
#### Gene-Model Analysis: K-Means Clustering Heatmap ####
## Current Heatmap

finalFC_df %>%
  left_join(info_df, by = 'Gene_id') %>%
  count(Variant)

finalFC_df %>%
  filter(Off_trans == 'B11')

set.seed(123)

kmeans_df <- gm_pos_maxtrans %>%
  filter(Gene_id %in% finalFC_df$Gene_id)

nclu <- 7

x <- heatMap_allstrains_kmeans(
  df = kmeans_df,
  aFC_th = 2,
  fam = NA,
  fam_facet = F,
  nclu = nclu,
  tbar = T,
  fbar = T,
  labels = T
)

plot(x$plot)
x$df %>%
  select(Gene_id, Label, Cluster)

## Save resulting Heatmap and DF
ggsave(
  paste0(plots_dir, 'Gene_Model/heatmap_with_neighbors_Kmeans_filteredFC_reordered_new.pdf'),
  x$plot,
  device = 'pdf',
  height = 80, width = 60, units = 'cm'
)

all_gmodel_kmeans <- x$df

all_gmodel_kmeans %>%
  filter(Gene_id == 'PF3D7_0324800') %>%
  print(width = 999)


all_gmodel_kmeans %>%
  select(-contains('bin')) %>%
  write_tsv(paste0(
    plots_dir,
    'Gene_Model/heatmap_with_neighbors_Kmeans_filteredFC_reordered_table.csv'
  ))

## Check which genes are we loosing
plot_df <- read_tsv(paste0(
  plots_dir,
  'Gene_Model/heatmap_with_neighbors_Kmeans_filteredFC_reordered_table.csv'
))

plot_df %>%
  count(Cluster)

finalFC_df %>%
  filter(!Gene_id %in% plot_df$Gene_id) %>%
  left_join(info_df) %>%
  select(Gene_id, Is_3D7B, Is_tRNA, Annot, contains('DuplDel')) %>%
  left_join(gm_pos_maxtrans) %>%
  write_csv(paste0(tables_dir, 'gene_model_heatmap_lost_genes.csv'))



## Check output
x$elbow
x$silhouette
plot(x$plot)

#+end_src
*** K-means by family
#+begin_src R
#### Gene-Model Analysis: K-Means Heatmap by Families ####
## Plot by Family

set.seed(123)

fam_plot <- heatMap_families_kmeans(
  df = gm_pos_maxtrans %>%
    mutate(Label = paste(Gene_id, SubFamily, sep = ': ')),
  aFC_th = 0,
  fam = 'CLAG',
  fam_facet = F,
  nclu = 1,
  tbar = T,
  fbar = F,
  labels = T
)

fam_plot$elbow
fam_plot$silhouette
fam_plot$df
plot(fam_plot$plot)


ggsave(
  paste0(plots_dir, 'Gene_Model/Family_Heatmaps/CLAG', '_aMAFC_0', '_k', 1, '_withlegend.pdf'),
  fam_plot$plot, width = 60, height = 20,
  units = 'cm', device = 'pdf', limitsize = F
)

## Current famillies and k's
## fams_ks <- list(
##   c('ACS', 3),
##   c('CLAG', 2),
##   c('HYP', 3),
##   c('OTHER', 7),
##   c('PFMC-2TM', 3),
##   c('PHIST', 6),
##   c('RIFIN', 5),
##   c('STEVOR', 3),
##   c('VAR', 5)
## )

fams_ks <- list(
  c('ACS', 1),
  c('CLAG', 1),
  c('HYP', 1),
  c('OTHER', 1),
  c('PFMC-2TM', 1),
  c('PHIST', 1),
  c('RIFIN', 1),
  c('STEVOR', 1),
  c('VAR', 1)
)

for (fam_k in fams_ks){

  print(fam_k)

  nrows <- gm_pos_maxtrans %>%
    filter(Family == fam_k[1]) %>%
    count(Family) %>%
    pull(n)

  fam_plot <- heatMap_families_kmeans(
    df = gm_pos_maxtrans %>%
      mutate(Label = paste(Gene_id, SubFamily, sep = ': ')),
    aFC_th = 0,
    fam = fam_k[1],
    fam_facet = F,
    nclu = as.numeric(fam_k[2]),
    tbar = T,
    fbar = F,
    labels = F
  )

  ggsave(
    paste0(plots_dir, 'Gene_Model/Family_Heatmaps/', fam_k[1], '_aMAFC_0', '_k', fam_k[2], '_withlegend.pdf'),
    fam_plot$plot, width = 60, height = 0.7*nrows,
    units = 'cm', device = 'pdf', limitsize = F
  )
  ggsave(
    paste0(plots_dir, 'Gene_Model/Family_Heatmaps/', fam_k[1], '_elbow', '.pdf'),
    fam_plot$elbow, device = 'pdf'
  )
  ggsave(
    paste0(plots_dir, 'Gene_Model/Family_Heatmaps/', fam_k[1], '_silhouette', '.pdf'),
    fam_plot$silhouette, device = 'pdf'
  )
  write_csv(
    fam_plot$df %>% select(-contains('bin')),
    paste0(plots_dir, 'Gene_Model/Family_Heatmaps/', fam_k[1], '_table.csv')
    )
}

## Plot the "NA" Family

aMAFC_th <- 2
family_facet <- F
family <- NA
nclust <- 2
df <- gm_pos_maxtrans %>%
  filter(is.na(Family) & !Is_tRNA)
x <- heatMap_allstrains_trans(df, aMAFC_th, family, family_facet)
#+end_src
*** Cluster Tendency Plots
#+begin_src R
#### Gene-Model Analysis: Kmeans Cluster Tendency Plots ####
tendency_plot_loess <- function(df, cluster){

  max_y <- max(df %>% select(contains('_On') | contains('_Off')), na.rm = T)
  min_y <- min(df %>% select(contains('_On') | contains('_Off')), na.rm = T)

  plt_df <-  df %>%
    select(Gene_id, contains('On'), contains('Off'), Cluster) %>%
    filter(Cluster == cluster) %>%
    select(-Cluster)

  plot_mdf <- melt(plt_df)
  head(plot_mdf)

  plot_mdf['State'] <- sapply(plot_mdf$variable, function(x) str_split(x, '_')[[1]][2])
  plot_mdf <- plot_mdf %>%
    mutate(variable = as.numeric(sub("bin(\\d+).*", "\\1", variable)))

  head(plot_mdf)

  p <- ggplot(plot_mdf, aes(x = variable, y = value, group = State))
  p <- p + geom_smooth(aes(color = State), method = 'loess', level = 0.95)
  p <- p + scale_color_manual(values = c('red', 'green'))
  p <- p + ggtitle(paste0('Cluster ', cluster))
  p <- p + geom_vline(xintercept = 4.5, linetype="solid")
  p <- p + geom_vline(xintercept = 9.5, linetype="dotted")
  p <- p + geom_vline(xintercept = 14.5, linetype="dotted")
  p <- p + geom_vline(xintercept = 19.5, linetype="solid")
  p <- p + theme_classic()
  p <- p + theme(axis.title.x = element_blank())
  p <- p + ylab('H3K9me3 enrichment')
  p <- p + scale_x_continuous(
             breaks=c(2.5,4.5,7,12,17,19.5, 21.5),
             labels=c('Prev\nGenes', "ATG", "5'UTR", "CDS", "3'UTR", "END", 'Post\nGenes'),
             expand = c(0, 0)
           )
  ##p <- p + scale_y_continuous(limits = c(min_y-0.3, max_y+0.3), expand = c(0, 0))
  ##p <- p + scale_y_continuous(limits = c(-0.3, 3), expand = c(0, 0))
  p <- p + coord_cartesian(ylim = c(-0.3, 4))
  p
}

## tendency_plot_mean_sd <- function(df, cluster){

##   onoff_df <- df %>%
##     select(-contains('_Dif'))

##   mean_df <- onoff_df %>%
##     group_by(Cluster) %>%
##     summarize(across(contains('bin'), list(mean))) %>%
##     pivot_longer(!Cluster, values_to = 'mean')

##   sd_df <- onoff_df %>%
##     group_by(Cluster) %>%
##     summarize(across(contains('bin'), list(sd))) %>%
##     pivot_longer(!Cluster, values_to = 'sd')

##   plot_df <- mean_df %>%
##     full_join(sd_df, by = c('Cluster', 'name'))

##   max_y <- max(plot_df$mean + plot_df$sd)
##   min_y <- min(plot_df$mean - plot_df$sd)

##   plot_df <- plot_df %>%
##     filter(Cluster == cluster) %>%
##     select(-Cluster)

##   plot_df['State'] <- sapply(plot_df$name, function(x) str_split(x, '_')[[1]][2])
##   plot_mdf <- plot_df %>%
##     mutate(variable = as.numeric(sub("bin(\\d+).*", "\\1", name)))

##   #print(min_y)

##   p <- ggplot(plot_mdf, aes(x = variable, group = State))
##   p <- p + geom_line(aes(y = mean, color = State), size = 1)
##   p <- p + geom_ribbon(aes(y = mean, ymin = mean - sd, ymax = mean + sd, fill = State),
##                        alpha = .2)
##   p <- p + scale_color_manual(values = c('red', 'green'))
##   p <- p + ggtitle(paste0('Cluster ', cluster))
##   p <- p + geom_vline(xintercept = 4.5, linetype="solid")
##   p <- p + geom_vline(xintercept = 9.5, linetype="dotted")
##   p <- p + geom_vline(xintercept = 14.5, linetype="dotted")
##   p <- p + geom_vline(xintercept = 19.5, linetype="solid")
##   p <- p + theme_classic()
##   p <- p + theme(axis.title.x = element_blank())
##   p <- p + ylab('H3K9me3 enrichment')
##   p <- p + scale_x_continuous(
##              breaks=c(2.5,4.5,7,12,17,19.5, 21.5),
##              labels=c('Prev\nGenes', "ATG", "5'UTR", "CDS", "3'UTR", "END", 'Post\nGenes'),
##              expand = c(0, 0)
##            )
##   p <- p + scale_y_continuous(limits = c(min_y, max_y), expand = c(0, 0))
##   p
## }


## 1 cluster plots
tendency_plot_loess(all_gmodel_kmeans, 6)
##tendency_plot_mean_sd(all_gmodel_kmeans, 6)


## All cluster plots, overlapped
## K-means loess
plots <- lapply(1:nclu, function(x) tendency_plot_loess(all_gmodel_kmeans, x))
clusters_plot <- grid.arrange(grobs = plots, nrow = length(plots), ncol = 1)

ggsave(
  paste0(plots_dir, 'Gene_Model/clusters_plot_overlapped_with_neighbors_kmeans_new.pdf'),
  clusters_plot,
  height = 80, width = 15, units = 'cm',
  device = 'pdf'
)

## ## K-means means +- sd
## plots <- lapply(1:nclust, function(x) tendency_plot_mean_sd(all_gmodel_kmeans, x))
## clusters_plot <- grid.arrange(grobs = plots, nrow = length(plots), ncol = 1)

## ggsave(
##   paste0(plots_dir, 'Gene_Model/clusters_plot_overlapped_with_neighbors_kmeans_means_sd.pdf'),
##   clusters_plot,
##   height = 80, width = 15, units = 'cm',
##   device = 'pdf'
## )


#+end_src
*** Box and whiskers Plots
#+begin_src R
#### Gene-Model Analysis: K-Means Box and whiskers Plots ####
box_df <- all_gmodel_kmeans %>%
  select(Gene_id, Max_aMAFC, Cluster)

p <- ggplot(all_gmodel_kmeans, aes(x = as.character(Cluster), y= Max_aMAFC))
p <- p + stat_boxplot(geom = "errorbar", width = 0.5) #add perpendicular whiskers
p <- p + geom_boxplot(outlier.colour="red")
p <- p + theme_classic()
p <- p + xlab('Cluster')
p <- p + ylab('Level of expression (aMAFC)')
p

ggsave(paste0(plots_dir, 'Gene_Model/cluster_boxplots.pdf'), p, device = 'pdf')

#+end_src
*** Cluster Donuts
#+begin_src R
#### Gene-Model Analysis: K-Means Cluster Donuts ####
## Donut Plot

donut_plot <- function(df, cluster) {
    x <- df %>%
      filter(Cluster == cluster)

    data <- as.data.frame(table(x$Family_Grouped))
    colnames(data) <- c('category', 'count')

    count(info_df, Family)

    ## Compute percentages
    data$fraction = data$count / sum(data$count)

    ## Compute the cumulative percentages (top of each rectangle)
    data$ymax = cumsum(data$fraction)

    ## Compute the bottom of each rectangle
    data$ymin = c(0, head(data$ymax, n=-1))

    ## Compute label position
    data$labelPosition <- (data$ymax + data$ymin) / 2

    ## Compute a good label
    data$label <- paste0(data$category, "\n value: ", data$count)

    ## Make the plot
    p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
      geom_rect(color="white") +
      #geom_label( x=4.2, aes(y=labelPosition, label=label), size=3) +
      coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
      xlim(c(2, 4)) +# Try to remove that to see how to make a pie chart
      theme_void() + my_scale

    outname <- paste0('./Plots/Donuts/gmodel_hetmap_cluster_',
                      as.character(cluster),
                      '.svg')
    #ggsave(outname, p, device = 'svg')
    p
}

count(all_gmodel_kmeans, Cluster)

p1 <- donut_plot(all_gmodel_kmeans, 1)
p2 <- donut_plot(all_gmodel_kmeans, 2)
p3 <- donut_plot(all_gmodel_kmeans, 3)
p4 <- donut_plot(all_gmodel_kmeans, 4)
p5 <- donut_plot(all_gmodel_kmeans, 5)
p6 <- donut_plot(all_gmodel_kmeans, 6)
p7 <- donut_plot(all_gmodel_kmeans, 7)

all_donuts <- grid.arrange(p1, p2, p3, p4, p5, p6, p7,  nrow = 7, ncol = 1)
ggsave(paste0(plots_dir, 'Gene_Model/gmodel_heatmap_alldonuts.svg'), all_donuts, device = 'svg')


## Plot all genes to get legend
## all_genes_donut <- info_df %>%
##   mutate(Family_Dount = case_when(
##            Family %in% col_factor ~ Family,
##            Family == 'OTHER' ~ 'Other CVGs',
##            is.na(Family) ~ 'Not CVGs'))


data <- as.data.frame(table(info_df$Family_Grouped))
colnames(data) <- c('category', 'count')

count(info_df, Family)

## Compute percentages
data$fraction = data$count / sum(data$count)

## Compute the cumulative percentages (top of each rectangle)
data$ymax = cumsum(data$fraction)

## Compute the bottom of each rectangle
data$ymin = c(0, head(data$ymax, n=-1))

## Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

## Compute a good label
data$label <- paste0(data$category, "\n value: ", data$count)

## Make the plot
p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
  geom_rect(color="white") +
                                        #geom_label( x=4.2, aes(y=labelPosition, label=label), size=3) +
  coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
  xlim(c(2, 4)) +# Try to remove that to see how to make a pie chart
  theme_void() + my_scale

ggsave(paste0(plots_dir, 'families_donut_for_legend.svg'), p, device = 'svg')
##p

#+end_src
** Gene State analysis
#+begin_src R
#### Gene State Tables Analysis ####
#+end_src
*** Load Gene State tables
#+begin_src R
## Check for which genes we have a strain in an active state and a strain in a silenced state
## Load whole gene state tables
state_old_whole <- read_tsv('/mnt/Disc4T/Projects/Active_gene_list/Results_Tables/state_df_old_arrays_rna25_red_up50_red_dw25_reddw15_areaFC1_areaFCbig3_redpcntdif30_maxtime1_dupldel_filtered.csv') %>%
  select(-Variant, -Gene_name, -Annot)

state_new_whole <- read_tsv('/mnt/Disc4T/Projects/Active_gene_list/New_Arrays_Results/state_df_new_arrays__rna25_red_up50_red_dw25_reddw15_areaFC1_areaFCbig3_redpcntdif30_maxtime1_dupldel_filtered.csv') %>%
  select(
    -Variant, -Gene_name, -Annot,
    -Chrom, -Start, -Stop, -Type, -Strand, -Name,
    -Is_tRNA, -Family, -SubFamily, -Label,
    -Family_Grouped, -Gam_specific,
    -Difpeaks_12B_10G, -Difpeaks_A7_E5, -Difpeaks_A7_B11, -Difpeaks_E5_B11
  )


state_whole <- state_old_whole %>%
  full_join(state_new_whole, by = 'Gene_id', suffix = c('_old', '_new'))


## ## Different state in 3D7B and A7/E5/B11
myMax <- function(x){
  if (all(is.na(x))){
    out <- NA
  } else {
    out <- max(x, na.rm=T)
  }
  return(out)
}

myMin <- function(x){
  if (all(is.na(x))){
    out <- NA
  } else {
    out <- min(x, na.rm=T)
  }
  return(out)
}

## Load gene expression tables
genexp_old <- read_csv(paste0(microarrays_dir, 'Old_Arrays/R_results_OldArrays_Variantome/geneLevel_exp.csv')) %>%
  select(Gene_id, contains('tp'))

genexp_old <- genexp_old %>%
  mutate(MaxExp_12B = apply(select(., contains('12B')), 1, myMax)) %>%
  mutate(MaxExp_10G = apply(select(., contains('10G')), 1, myMax)) %>%
  mutate(MaxExp_3D7B = apply(select(., contains('3D7B')), 1, myMax)) %>%
  mutate(MaxExp_old = apply(select(., contains('MaxExp')), 1, myMax)) %>%
  mutate(MinExp_old = apply(select(., contains('MaxExp')), 1, myMin))

genexp_new <- read_csv(paste0(microarrays_dir, 'New_Arrays/R_results_NewArray/geneLevel_exp.csv')) %>%
  select(Gene_id, contains('tp'))

genexp_new <- genexp_new %>%
  mutate(MaxExp_A7 = apply(select(., contains('A7')), 1, myMax)) %>%
  mutate(MaxExp_E5 = apply(select(., contains('E5')), 1, myMax)) %>%
  mutate(MaxExp_B11 = apply(select(., contains('B11')), 1, myMax)) %>%
  mutate(MaxExp_new = apply(select(., contains('MaxExp')), 1, myMax)) %>%
  mutate(MinExp_new = apply(select(., contains('MaxExp')), 1, myMin))

genexp_df <- genexp_old %>% select(Gene_id, contains('Max'), contains('Min')) %>%
  full_join(genexp_new %>% select(Gene_id, contains('Max'), contains('Min')), by = 'Gene_id')

genexp_df

state_exp <- state_whole %>%
  left_join(genexp_df, by = 'Gene_id')
#+end_src
*** Extra filters for genes with dif states in 3D7B and A7/E5/B11
#+begin_src R
## Genes in which 3D7B is in a different state than A7/E5/B11
## Repressed in 3D7B but active in A7/E5/B11
bigLogDif_dw <- 3

## Filter
inactive_A7 <- state_exp %>%
  filter(category_3D7B == 'CVG_Silenced') %>%
  filter(category_A7 == 'CVG_Active') %>%
  filter((MaxExp_old - MaxExp_A7) > bigLogDif_dw) %>%
  select(Gene_id) %>%
  pull()

inactive_E5 <- state_exp %>%
  filter(category_3D7B == 'CVG_Silenced') %>%
  filter(category_E5 == 'CVG_Active') %>%
  filter((MaxExp_old - MaxExp_E5) > bigLogDif_dw) %>%
  select(Gene_id) %>%
  pull()

inactive_B11 <- state_exp %>%
  filter(category_3D7B == 'CVG_Silenced') %>%
  filter(category_B11 == 'CVG_Active') %>%
  filter((MaxExp_old - MaxExp_B11) > bigLogDif_dw) %>%
  select(Gene_id) %>%
  pull()

## Replace
state_exp <- state_exp %>%
  mutate(state_A7 = ifelse(
           Gene_id %in% inactive_A7,
           gsub('Active', 'Undetermined', state_A7),
           state_A7
         )) %>%
  mutate(category_A7 = ifelse(
           Gene_id %in% inactive_A7,
           gsub('Active', 'Undetermined', category_A7),
           category_A7
         ))

state_exp <- state_exp %>%
  mutate(state_E5 = ifelse(
           Gene_id %in% inactive_E5,
           gsub('Active', 'Undetermined', state_E5),
           state_E5
         )) %>%
  mutate(category_E5 = ifelse(
           Gene_id %in% inactive_E5,
           gsub('Active', 'Undetermined', category_E5),
           category_E5
         ))

state_exp <- state_exp %>%
  mutate(state_B11 = ifelse(
           Gene_id %in% inactive_B11,
           gsub('Active', 'Undetermined', state_B11),
           state_B11
         )) %>%
  mutate(category_B11 = ifelse(
           Gene_id %in% inactive_B11,
           gsub('Active', 'Undetermined', category_B11),
           category_B11
         ))


## Actius a 3D7B i inactius a A7/E5/B11
## Per soca: actius a 3D7B per√≤ inactiu (1.2B/10G) molt m√©s baix que A7/E5/B11
## Treure nom√©s els 'positius'
## bigLogDif_up <- 3

## ## Filter
## active_A7 <- state_exp %>%
##   filter(category_3D7B == 'CVG_Active') %>%
##   filter(category_A7 == 'CVG_Repressed') %>%
##   filter((MaxExp_A7 - MinExp_old) > bigLogDif_up) %>%
##   select(Gene_id) %>%
##   pull()

## active_E5 <- state_exp %>%
##   filter(category_3D7B == 'CVG_Active') %>%
##   filter(category_E5 == 'CVG_Repressed') %>%
##   filter((MaxExp_E5 - MinExp_old) > bigLogDif_up) %>%
##   select(Gene_id) %>%
##   pull()

## active_B11 <- state_exp %>%
##   filter(category_3D7B == 'CVG_Active') %>%
##   filter(category_B11 == 'CVG_Repressed') %>%
##   filter((MaxExp_B11 - MinExp_old) > bigLogDif_up) %>%
##   select(Gene_id) %>%
##   pull()


## state_exp %>%
##   select(Gene_id, MaxExp_old, MinExp_old, MaxExp_A7) %>%
##   filter(Gene_id == 'PF3D7_0424900')


## state_exp


## Replace

## Replace
## state_exp <- state_exp %>%
##   mutate(state_A7 = ifelse(
##            Gene_id %in% active_A7,
##            gsub('Repressed', 'Undetermined', state_A7),
##            state_A7
##          )) %>%
##   mutate(category_A7 = ifelse(
##            Gene_id %in% active_A7,
##            gsub('Repressed', 'Undetermined', category_A7),
##            category_A7
##          ))

## state_exp <- state_exp %>%
##   mutate(state_E5 = ifelse(
##            Gene_id %in% active_E5,
##            gsub('Repressed', 'Undetermined', state_E5),
##            state_E5
##          )) %>%
##   mutate(category_E5 = ifelse(
##            Gene_id %in% active_E5,
##            gsub('Repressed', 'Undetermined', category_E5),
##            category_E5
##          ))

## state_exp <- state_exp %>%
##   mutate(state_B11 = ifelse(
##            Gene_id %in% active_B11,
##            gsub('Repressed', 'Undetermined', state_B11),
##            state_B11
##          )) %>%
##   mutate(category_B11 = ifelse(
##            Gene_id %in% active_B11,
##            gsub('Repressed', 'Undetermined', category_B11),
##            category_B11
##          ))

#+end_src
*** Create Final DF
#+begin_src R
## Load gene state tables
my_difstate_filter <- function(state_vect){
  active <- any(grepl('Active', state_vect))
  silenced <- any(grepl('CVG_Silenced', state_vect)) | any(grepl('Inactive', state_vect))
  return(active & silenced)
}

state_exp %>%
  select(contains('category'))

colnames(state_exp)

state_final <- state_exp %>%
  select(-contains('3D7B')) %>%
  rename_with(~ gsub('category_', 'Gene_State_', .x)) %>%
  mutate(Gene_id = ifelse(Gene_id == 'PF3D7_0935400_as', 'PF3D7_0935390', Gene_id)) %>%
  mutate(DifState = apply(select(., contains('State')), 1, my_difstate_filter)) %>%
  filter(Gene_id %in% info_df$Gene_id) %>%
  left_join(info_df, by = 'Gene_id') %>%
  mutate(Gene_State_12B = case_when(
           is.na(Gene_State_12B) & !Variant ~ 'Undetermined',
           is.na(Gene_State_12B) & Variant ~ 'CVG_Undetermined',
           TRUE ~ Gene_State_12B
         )) %>%
  mutate(Gene_State_10G = case_when(
           is.na(Gene_State_10G) & !Variant ~ 'Undetermined',
           is.na(Gene_State_10G) & Variant ~ 'CVG_Undetermined',
           TRUE ~ Gene_State_10G
         )) %>%
  mutate(Gene_State_A7 = case_when(
           is.na(Gene_State_A7) & !Variant ~ 'Undetermined',
           is.na(Gene_State_A7) & Variant ~ 'CVG_Undetermined',
           TRUE ~ Gene_State_A7
         )) %>%
  mutate(Gene_State_E5 = case_when(
           is.na(Gene_State_E5) & !Variant ~ 'Undetermined',
           is.na(Gene_State_E5) & Variant ~ 'CVG_Undetermined',
           TRUE ~ Gene_State_E5
         )) %>%
  mutate(Gene_State_B11 = case_when(
           is.na(Gene_State_B11) & !Variant ~ 'Undetermined',
           is.na(Gene_State_B11) & Variant ~ 'CVG_Undetermined',
           TRUE ~ Gene_State_B11
         ))

state_final %>%
  write_tsv(paste0(tables_dir, 'join_gene_states.tsv'))

## Parse for supplementary
colnames(state_final)

supp_state <- state_final %>%
  select(Gene_id, contains('Gene_State'), Variant, Annot, everything()) %>%
  rename(CVG = Variant) %>%
  write_tsv(paste0(tables_dir, 'join_gene_states_for_supp.tsv'))

colnames(supp_state)


colnames(state_final)

stinfo_df <- state_final %>%
  left_join(info_df) %>%
  filter(DifState) %>%
  select(Gene_id, contains('State'), Variant, Annot) %>%
  print(width = 200)

stinfo_df %>%
  filter(DifState) %>%
  count(Variant)

vars <- stinfo_df %>%
  filter(DifState) %>%
  filter(Variant) %>%
  select(Gene_id, contains('State'), Annot) %>%
  print(width = 200)

novars <- stinfo_df %>%
  filter(DifState) %>%
  filter(!Variant) %>%
  select(Gene_id, contains('State'), Annot) %>%
  print(width = 200)

vh <- gm_pos_maxtrans %>%
  filter(Gene_id %in% vars$Gene_id)

nvh <- gm_pos_maxtrans %>%
  filter(Gene_id %in% novars$Gene_id)

x <- heatMap_allstrains_kmeans(
  df = vh,
  aFC_th = 0,
  fam = NA,
  fam_facet = F,
  nclu = 6,
  tbar = F,
  fbar = T,
  labels = T
)

x$silhouette

ggsave(
  paste0(plots_dir, 'Gene_Model/heatmap_dif_gene_states_variant.pdf'),
  x$plot,
  device = 'pdf',
  height = 80, width = 60, units = 'cm'
)

#+end_src
*** ON/OFF difs heatmaps
#+begin_src R
## Genereate empty df for each out df (on/off/diff)
hetcols <- gmodel_all %>%
  select(contains('12B') & contains('bin')) %>%
  colnames(.) %>%
  gsub('12B', '', ., fixed=TRUE)

col_names <- c(
  'Gene_id',
  'Strain',
  paste0(hetcols, 'Cov')
  )

cn <- setNames(rep('', length(col_names)), col_names)
df <- bind_rows(cn)[0,]

df_on <- df
df_off <- df
df_diff <- df

vars

for (i in 1:dim(vars)[1]){
  #i <- 1
  gid <- as.character(vars$Gene_id[i])
  states <- vars[i,] %>% select(-Gene_id)
  on_cols <- colnames(states[which(states == 'CVG_Active')])
  off_cols <- colnames(states[which(states == 'CVG_Silenced')])
  on_strains <- gsub('Gene_State_', '', on_cols)
  off_strains <- gsub('Gene_State_', '', off_cols)

  ## Get Gene-model bins data
  ## On_df
  for (strain in on_strains){

    vect <- gmodel_all %>%
      filter(Gene_id == gid) %>%
      select(contains(strain))

    row <- c(
      gid,
      strain,
      unlist(vect, use.names = F)
      )

    row <- setNames(row, col_names)
    df_on <- df_on %>% add_row(bind_rows(row))
  }
  ## Off_df
  for (strain in off_strains){

    vect <- gmodel_all %>%
      filter(Gene_id == gid) %>%
      select(contains(strain))

    row <- c(
      gid,
      strain,
      unlist(vect, use.names = F)
      )

    row <- setNames(row, col_names)
    df_off <- df_off %>% add_row(bind_rows(row))
  }
}
## Convert to numeric
df_on <- df_on %>% mutate(across(contains('bin'), as.numeric))
df_off <- df_off %>% mutate(across(contains('bin'), as.numeric))


## target <- 'PF3D7_1301500'

## df_off %>%
##   filter(Gene_id == target) %>%
##   print(width = 90000)

## vars %>%
##   filter(Gene_id == target) %>%
##   print(width = 90000)

## trans_df %>%
##   filter(Gene_id == target) %>%
##   select(Gene_id, contains('MaxVal')) %>%
##   print(width = 90000)


## Filter out genes with only one ON / OFF strain
repeated_on <- df_on %>%
  group_by(Gene_id) %>%
  summarise(N_strains = n()) %>%
  filter(N_strains > 1) %>%
  select(Gene_id) %>%
  pull()

repeated_off <- df_off %>%
  group_by(Gene_id) %>%
  summarise(N_strains = n()) %>%
  filter(N_strains > 1) %>%
  select(Gene_id) %>%
  pull()


## Calculate means and substract
on_means <- df_on %>%
  group_by(Gene_id) %>%
  summarise(
    across(contains('bin'), ~ mean(.x, na.rn = T))
  )

off_means <- df_off %>%
  group_by(Gene_id) %>%
  summarise(
    across(contains('bin'), ~ mean(.x, na.rn = T))
  )

onoff_means <- bind_cols(
  on_means %>% select(Gene_id),
  on_means %>% select(-Gene_id) - off_means %>% select(-Gene_id)
)

onmean_mtx <- df_on %>%
  left_join(on_means, by = 'Gene_id', suffix = c('', '_mean')) %>%
  select(contains('mean'))

on_mtx <- df_on %>%
  select(contains('bin'))

offmean_mtx <- df_off %>%
  left_join(off_means, by = 'Gene_id', suffix = c('', '_mean')) %>%
  select(contains('mean'))

off_mtx <- df_off %>%
  select(contains('bin'))

## Create mean subtracted DFs and remove rows with a single strain per gene
onmean_df <- bind_cols(df_on %>% select(-contains('bin')), on_mtx - onmean_mtx) %>%
  filter(Gene_id %in% repeated_on)

offmean_df <- bind_cols(df_off %>% select(-contains('bin')), off_mtx - offmean_mtx) %>%
  filter(Gene_id %in% repeated_off)

#+end_src
*** Make Heatmaps
#+begin_src R
## Make Heatmaps

my_difmean_heat <- function(df){

  df_heat <- df %>%
    mutate(N_id = row_number()) %>%
    left_join(info_df) %>%
    mutate(N_id = paste0(N_id, ': ', Label)) %>%
    select(
      -contains('bin1_'),
      -contains('bin2_'),
      -contains('bin3_'),
      -contains('bin4_'),
      -contains('bin20_'),
      -contains('bin21_'),
      -contains('bin22_'),
      -contains('bin23_'),
      )

  bin_cols <- df_heat %>%
    select(contains('bin')) %>%
    colnames

  nids <- df_heat$N_id

  write_csv(
    df_heat,
    paste0(
      plots_dir,
      'Gene_Model/States_OnOff/',
      deparse(substitute(df)),
      '.csv'
    )
  )

  mdf <- df_heat %>%
    pivot_longer(contains('bin'), names_to = 'variable', values_to = 'value') %>%
    mutate(variable = factor(variable, levels = bin_cols)) %>%
    mutate(N_id = factor(N_id, levels = rev(nids)))

  p <- ggplot(mdf, aes(x = variable, y = N_id, fill = value))
  p <- p + geom_tile(colour="snow3")
  p <- p + theme(
             #axis.text.y = element_blank(),
             #axis.ticks.y = element_blank(),

             axis.title = element_blank(),
             axis.line.x = element_blank(),
             axis.text.x = element_blank(),
             axis.ticks.x = element_blank(),
             axis.title.x = element_blank(),


             plot.background=element_blank(),

             panel.border=element_blank(),
             panel.grid.major=element_blank(),
             panel.grid.minor=element_blank(),
             panel.background=element_blank(),

             strip.background = element_blank(),
             strip.text.x = element_blank(),
             strip.text.y = element_blank(),

             text=element_text(size=24),

             legend.position='bottom',
             legend.title = element_blank()
             )
  p <- p + scale_fill_gradient2(
             low = "chartreuse3",
             mid = "white",
             high = "darkred",
             na.value="grey90",
             limits = c(-3,3)
           )
  p
}


pon <- my_difmean_heat(onmean_df)
poff <- my_difmean_heat(offmean_df)
ponoff <- my_difmean_heat(onoff_means)

pon
poff
ponoff

ggsave(
  paste0(plots_dir, 'Gene_Model/States_OnOff/genes_on_meandif_withnegatives.pdf'),
  pon, device = 'pdf', height = 80, width = 60, units = 'cm'
)
ggsave(
  paste0(plots_dir, 'Gene_Model/States_OnOff/genes_off_meandif_withnegatives.pdf'),
  poff, device = 'pdf', height = 80, width = 60, units = 'cm'
)
ggsave(
  paste0(plots_dir, 'Gene_Model/States_OnOff/genes_on_minus_ff_withnegatives.pdf'),
  ponoff, device = 'pdf', height = 80, width = 60, units = 'cm'
)

my_difmean_heat(df_on) +
  scale_fill_gradient(
    low = "white",
    high = "darkred",
    na.value="grey90"
  )
my_difmean_heat(df_off) +
  scale_fill_gradient(
    low = "white",
    high = "darkred",
    na.value="grey90"
  )

#+end_src
*** Make Boxplots with correlations
#+begin_src R
## Make Correlation Boxplots

table(unique(df_on$Gene_id) == unique(df_off$Gene_id))

## In ON/OFF states, get correlation between gene-model coverage
## of the same gene in all the different strains that share a state
get_cors <- function(df) {
  cors_out <- c()
  for (gid in unique(df$Gene_id)) {
    mtx <- df %>%
      filter(Gene_id == gid) %>%
      select(contains('bin')) %>%
      select(
        -contains('bin1_'),
        -contains('bin2_'),
        -contains('bin3_'),
        -contains('bin4_'),
        -contains('bin20_'),
        -contains('bin21_'),
        -contains('bin22_'),
        -contains('bin23_'),
        ) %>%
      t()

    cors <-cor(mtx)
    cors[col(cors)==row(cors)] <- NA
    mean_cor <- mean(c(cors), na.rm = T)
    cors_out <- c(cors_out, mean_cor)
  }
  return(cors_out)
}

on_cors <- get_cors(df_on)
off_cors <- get_cors(df_off)

## For the same genes, get correlation between the gene-model mean coverage
## between active and silenced state

on_means_noneighbors <- on_means %>%
  select(contains('bin')) %>%
  select(
    -contains('bin1_'),
    -contains('bin2_'),
    -contains('bin3_'),
    -contains('bin4_'),
    -contains('bin20_'),
    -contains('bin21_'),
    -contains('bin22_'),
    -contains('bin23_'),
    )

off_means_noneighbors <- off_means %>%
  select(contains('bin')) %>%
  select(
    -contains('bin1_'),
    -contains('bin2_'),
    -contains('bin3_'),
    -contains('bin4_'),
    -contains('bin20_'),
    -contains('bin21_'),
    -contains('bin22_'),
    -contains('bin23_'),
    )


onoff_cors <- c()
for (i in 1:dim(on_means_noneighbors)[1]){
  x <- on_means_noneighbors[i,] %>% t()
  y <- off_means_noneighbors[i,] %>% t()
  c <- cor(x, y)
  onoff_cors <- c(onoff_cors, c)
}
onoff_cors

### Make graphic

mean(on_cors, na.rm = T)
mean(off_cors, na.rm = T)
mean(onoff_cors)

length(on_cors)
length(off_cors)
length(onoff_cors)

cor_df <- tibble(
  On_Cors = on_cors,
  Off_Cors = off_cors,
  OnOff_Cors = onoff_cors
)

mean(cor_df$On_Cors, na.rm = T)
mean(cor_df$Off_Cors, na.rm = T)
mean(cor_df$OnOff_Cors, na.rm = T)


cor_mdf <- melt(cor_df)

p <- ggplot(cor_mdf, aes(x = variable, y = value))
p <- p + geom_boxplot(outlier.shape = NA, aes(ymax = quantile(value, 0.95, na.rm = T),
                                              ymin = quantile(value, 0.05, na.rm = T)))
p <- p + geom_jitter()
p <- p + coord_cartesian(ylim = c(0.7, 1))
p
ggsave(
  paste0(plots_dir, 'similarity_on_off_boxplot.pdf'),
  device = 'pdf'
)
#+end_src
*** Heatmap of highly DE genes
#+begin_src R
#### MaxTransDif filtered genes, same state genes vs difstate genes ####
set.seed(123)

table(finalFC_df$Is_3D7B)
table(finalFC_df$Is_tRNA)
table(finalFC_df$PassMaxtime)
colnames(finalFC_df)


variant <- info_df %>%
  filter(Variant) %>%
  select(Gene_id) %>%
  pull()

## Subset DFs of interest
difgenes_states <- state_final %>%
  select(Gene_id, contains('Gene_State')) %>%
  filter(Gene_id %in% finalFC_df$Gene_id) %>%
  filter(Gene_id %in% variant)

## Remove "neighboring" genes
het_bins <- gmodel_all_pos %>%
  select(
    -contains('bin1_'),
    -contains('bin2_'),
    -contains('bin3_'),
    -contains('bin4_'),
    -contains('bin20_'),
    -contains('bin21_'),
    -contains('bin22_'),
    -contains('bin23_'),
    )

## Create empty DF for result
col_names <- c(
  'Original_Row',
  'Gene_id',
  'Same_Strain_1',
  'Same_Strain_2',
  'Dif_Strain',
  paste0('SameState_', c(1:15)),
  paste0('DifState_', c(1:15))
)
cn <- setNames(rep('', length(col_names)), col_names)
df <- bind_rows(cn)[0,]

## Main "for loop"
for (i in 1:dim(difgenes_states)[1]){

  gid <- difgenes_states[i, 'Gene_id'] %>% pull()

  off <- difgenes_states[i,] %>%
    pivot_longer(-Gene_id) %>%
    filter(grepl('Silenced', value, fixed = T) | grepl('Inactive', value, fixed = T)) %>%
    select(name) %>%
    pull()

  on <- difgenes_states[i,] %>%
    pivot_longer(-Gene_id) %>%
    filter(grepl('Active', value, fixed = T)) %>%
    select(name) %>%
    pull()

  off <- gsub('Gene_State_', '', off)
  on <- gsub('Gene_State_', '', on)

  if (length(off) == 0) {off <- NA}
  if (length(on) == 0) {on <- NA}

  if (any(!is.na(on)) & any(!is.na(off)) & length(c(on, off)) >= 3){

    if (length(on) >= length(off)){
      nodif <- 'on'
    } else {
      nodif <- 'off'
    }

    if (nodif == 'on'){
      on_strains <- sample(on, 2)
      off_strain <- sample(off, 1)

      onvect1 <- het_bins %>%
        filter(Gene_id == gid) %>%
        select(contains(on_strains[1]))

      onvect2 <- het_bins %>%
        filter(Gene_id == gid) %>%
        select(contains(on_strains[2]))

      offvect <- het_bins %>%
        filter(Gene_id == gid) %>%
        select(contains(off_strain))

      nodif_vect <- onvect1 - onvect2
      difvect <- onvect1 - offvect
      same_strains <- on_strains
      difstrain <- off_strain
    } else {
      off_strains <- sample(off, 2)
      on_strain <- sample(on, 1)

      offvect1 <- het_bins %>%
        filter(Gene_id == gid) %>%
        select(contains(off_strains[1]))

      offvect2 <- het_bins %>%
        filter(Gene_id == gid) %>%
        select(contains(off_strains[2]))

      onvect <- het_bins %>%
        filter(Gene_id == gid) %>%
        select(contains(on_strain))

      nodif_vect <- offvect1 - offvect2
      difvect <- onvect - offvect1
      same_strains <- off_strains
      difstrain <- on_strain
    }

    row <- c(
      i,
      gid,
      same_strains[1],
      same_strains[2],
      difstrain,
      unlist(nodif_vect, use.names = F),
      unlist(difvect, use.names = F)
    )
    row <- setNames(row, col_names)
    df <- df %>% add_row(bind_rows(row))
  }
}


## Convert to numeric
same_state_df <- df %>%
  mutate(across(contains('State'), as.numeric)) %>%
  left_join(info_df)

same_state_df %>%
  select(-Original_Row) %>%
  left_join(difgenes_states) %>%
  select(-Is_tRNA) %>%
  select(Gene_id, contains('Gene_State'), everything()) %>%
  rename(CVG = Variant) %>%
  write_csv(paste0(tables_dir, 'same_sate_vs_different_state_new_new.csv'))

## Make Heatmap
ss <- same_state_df %>%
  select(
    Gene_id,
    contains('SameState'),
    contains('DifState'),
    Gam_specific,
  ) %>%
  pivot_longer(-Gene_id) %>%
  mutate(name = factor(name, levels = unique(name))) %>%
  mutate(Gene_id = factor(Gene_id, levels = rev(unique(Gene_id))))


x <- ss %>%
  filter(grepl('State', name)) %>%
  mutate(
    SameState = ifelse(grepl('SameState', name), 'Same State', 'Different State')
  ) %>%
  mutate(SameState = factor(SameState, levels=(c('Same State', 'Different State'))))

y <- ss %>%
  filter(name == 'Gam_specific')

p <- ggplot(x, aes(x = name, y = Gene_id, fill = value))
p <- p + geom_tile(colour="snow3")
p <- p + scale_fill_gradient2(
           low = "limegreen",
           mid = "white",
           high = "red",
           midpoint = 0
         )
p <- p + facet_grid(cols = vars(x$SameState), scales = "free", space="free_y")
p <- p + theme(
           axis.text.x = element_blank(),
           axis.ticks.x = element_blank(),
           axis.title.y = element_blank(),
           #axis.text.y = element_blank(),
           axis.ticks.y = element_blank(),
           panel.grid.major=element_blank(),
           panel.background=element_blank(),
           legend.position = 'bottom'
           )
p <- p + labs(y = '', x = '')

p2 <- ggplot(y, aes(x = name, y = Gene_id, fill = value))
p2 <- p2 + geom_tile(colour="snow3")
p2 <- p2 + scale_fill_gradient(
             low = "white",
             high = "Orange",
             )
p2 <- p2 + facet_grid(cols = vars(y$name), scales = "free", space="free_y")
p2 <- p2 + scale_y_discrete(position = "right")
p2 <- p2 + theme(
             axis.text.x = element_blank(),
             axis.ticks.x = element_blank(),
             axis.title.y = element_blank(),
             axis.text.y = element_blank(),
             axis.ticks.y = element_blank(),
             panel.grid.major=element_blank(),
             panel.background=element_blank(),
             legend.position = 'bottom'
           )
p2 <- p2 + labs(y = '', x = '')

same_state_heat <- ggarrange(p, p2, nrow = 1, widths = c(10,1))
same_state_heat

ggsave(
  paste0(plots_dir, 'same_dif_state_filteredFC_onlyvariant_on_minus_off.pdf'),
  same_state_heat, device = 'pdf'
)


## Make tendency Plots

same <- ss %>%
  filter(grepl('SameState', name)) %>%
  mutate(State = 'same') %>%
  mutate(value = abs(value))%>%
  ggplot(aes(x = name, y = value, group = State))

same <- same + geom_smooth(aes(color = State), method = 'loess', level = 0.95)
same <- same + theme_classic()
same <- same + coord_cartesian(ylim = c(0,2))
#same <- same + scale_y_continuous(limits = c(0,5), expand = c(0, 0))

dif <- ss %>%
  filter(grepl('DifState', name)) %>%
  mutate(State = 'dif') %>%
  mutate(value = abs(value)) %>%
  ggplot(aes(x = name, y = value, group = State))
dif <- dif + geom_smooth(aes(color = State), method = 'loess', level = 0.95)
dif <- dif + theme_classic()
dif <- dif + coord_cartesian(ylim = c(0,2))
#dif <- dif + scale_y_continuous(limits = c(0,5), expand = c(0, 0))
dif
same_dif_states_tendency <- ggarrange(same, dif, nrow = 1)

ggsave(
  paste0(plots_dir, 'same_dif_state_filteredFC_onlyvariant_tendencies_absval.pdf'),
  device = 'pdf'
  )
#+end_src
** Metilation and Acetylation Analysis (1000fp 500orf)
#+begin_src R
#### Metilation and Acetilation Analysis ####
#+end_src
*** Load Me and Ac Data
First we need to load the data. On one hand we have the data on the gene states (target) and on the other the H3K9me3/H3K9ac status (features).
#+begin_src R
## Load Me and Ac Data

read_ac <- function(strain) {
  strain_dotless = gsub('.', '', strain, fixed = T)

  cov_ac_5p <- read_tsv(paste0(
    coverage_dir,
    'binned_1000tss_0orf_allowoverlaps_False_coverage_acetylation_', strain, '.bed'
  ), col_names = F) %>%
    select(X4, X5) %>%
    set_names(c('Gene_id', 'Ac_5p')) %>%
    mutate(Strain = strain_dotless)

  cov_ac_orf <- read_tsv(paste0(
    coverage_dir,
    'binned_0tss_500orf_allowoverlaps_True_coverage_acetylation_', strain, '.bed'
  ), col_names = F) %>%
    select(X4, X5) %>%
    set_names(c('Gene_id', 'Ac_ORF')) %>%
    mutate(Strain = strain_dotless)

  cov_ac_3p <- read_tsv(paste0(
    coverage_dir,
    'binned_3prime1000_allowoverlaps_False_coverage_acetylation_', strain, '.bed'
  ), col_names = F) %>%
    select(X4, X7) %>%
    set_names(c('Gene_id', 'Ac_3p')) %>%
    mutate(Strain = strain_dotless)

  outdf <- cov_ac_5p %>%
    full_join(cov_ac_orf, join_cols = c('Gene_id', 'Strain')) %>%
    full_join(cov_ac_3p, join_cols = c('Gene_id', 'Strain')) %>%
    select(Gene_id, Strain, everything())

  return(outdf)
}

read_me <- function(strain) {
  strain_dotless = gsub('.', '', strain, fixed = T)

  cov_me_5p <- read_tsv(paste0(
    coverage_dir,
    'binned_1000tss_0orf_allowoverlaps_False_coverage_', strain, '.bed'
  ), col_names = F) %>%
    select(X4, X5) %>%
    set_names(c('Gene_id', 'Me_5p')) %>%
    mutate(Strain = strain_dotless)

  cov_me_orf <- read_tsv(paste0(
    coverage_dir,
    'binned_0tss_500orf_allowoverlaps_True_coverage_', strain, '.bed'
  ), col_names = F) %>%
    select(X4, X5) %>%
    set_names(c('Gene_id', 'Me_ORF')) %>%
    mutate(Strain = strain_dotless)

  cov_me_3p <- read_tsv(paste0(
    coverage_dir,
    'binned_3prime1000_allowoverlaps_False_coverage_', strain, '.bed'
  ), col_names = F) %>%
    select(X4, X7) %>%
    set_names(c('Gene_id', 'Me_3p')) %>%
    mutate(Strain = strain_dotless)

  outdf <- cov_me_5p %>%
    full_join(cov_me_orf, join_cols = c('Gene_id', 'Strain')) %>%
    full_join(cov_me_3p, join_cols = c('Gene_id', 'Strain')) %>%
    select(Gene_id, Strain, everything())

  return(outdf)
}

cov_12b_me <- read_me('1.2B')
cov_10g_me <- read_me('10G')
cov_b11_me <- read_me('B11')

cov_12b_ac <- read_ac('1.2B')
cov_10g_ac <- read_ac('10G')
cov_b11_ac <- read_ac('B11')

me_df <- bind_rows(cov_12b_me, cov_10g_me, cov_b11_me)
ac_df <- bind_rows(cov_12b_ac, cov_10g_ac, cov_b11_ac)
me_ac_df <- me_df %>%
  full_join(ac_df, by = c('Gene_id', 'Strain'))

## Load Gene States table (response/target variable)

labels_df <- state_exp %>%
  select(Gene_id, category_12B, category_10G, category_A7, category_E5, category_B11)

## Table for further analysis

labels_df <- labels_df %>%
  pivot_longer(!Gene_id) %>%
  rename(Label = value) %>%
  mutate(Strain = gsub('category_', '', name, fixed=T)) %>%
  select(-name)

## Join Both

final_df <- me_ac_df %>%
  right_join(labels_df, by=c('Gene_id'='Gene_id', 'Strain'='Strain'))

## Filter out unlabbeled genes and add alpha depending on "Label" (for plots)


final_df <- final_df %>%
  filter(Label != 'No_Category') %>%
  filter(Label != 'Not_Settable') %>%
  filter(Label != 'CVG_Semiactive') %>%
  filter(Label != 'CVG_Undetermined') %>%
  mutate(Alpha = case_when(
           Label == 'Active' ~ 0.1,
           Label == 'Inactive' ~ 0.5,
           TRUE ~ 1
         ))

final_df %>%
  count(Label)

write_tsv(final_df, paste0(tables_dir, 'met_ac_states_df.tsv'))
#+end_src
*** Create DFs
#+begin_src R
## Remove rows that represent a gene in the same "state" in different strains (keep first)

final_df <- final_df %>%
  mutate(Label = factor(Label, levels = c('Active', 'Inactive', 'CVG_Active', 'CVG_Silenced')))

unique_df <- final_df %>%
  group_by(Gene_id, Label) %>%
  filter(row_number()==1) %>%
  ungroup()

# Check it worked
unique_df %>%
  group_by(Gene_id, Label) %>%
  count() %>%
  filter(n > 1)

unique_df %>%
  count(Label)

write_tsv(unique_df, paste0(tables_dir, './met_ac_unique_state.tsv'))

## Remove API and mal_mito genes

unique_noApi <- unique_df %>%
  filter(!grepl('API', Gene_id)) %>%
  filter(!grepl('mal_', Gene_id))

write_csv(unique_noApi, paste0(tables_dir, 'unique_noApi.csv'))
#+end_src

*** Make PCAs
#+begin_src R
## PCAs

set.seed(123)
my_colors = c('#ddb310', '#4053d3',  '#00b25d', '#b51d14')#,  '#fb49b0')
## blue, yellow, red, green, pink

make_pca <- function(df){
  nona_df <- df %>%
    filter(complete.cases(.))

  mtx <- nona_df %>% select(matches('Ac|Me'))
  mtx <- as.matrix(mtx)
  rownames(mtx) <- paste(nona_df$Gene_id, nona_df$Strain, sep = '_')
  pca <- prcomp(mtx)
  pca_df <- tibble(as.data.frame(pca$x)) %>%
    mutate(
      Gid = paste(nona_df$Gene_id, nona_df$Strain, sep = '_'),
      Label = nona_df$Label,
      Alpha = nona_df$Alpha
    ) %>%
    select(Gid, Label, everything())

  cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
  cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

  p <- ggplot(pca_df, aes(x=PC1,y=PC2, col = Label, group = Label))
  p <- p + geom_point(alpha = pca_df$Alpha)
  p <- p + labs(x=paste0("PC1: ", cmp1, "%"), y=paste0("PC2: ", cmp2, "%"))
  p <- p + scale_color_manual(values=my_colors)
  #p <- p + theme_minimal() + guides(alpha='none')
  p <- p + theme_bw() + guides(alpha='none')
  p <- p + theme(
             axis.text.x=element_blank(),
             axis.ticks.x=element_blank(),
             axis.text.y=element_blank(),
             axis.ticks.y=element_blank(),
             panel.grid.major = element_blank(),
             panel.grid.minor = element_blank()
           )
  return(list(df = pca_df, plot = p))
}

## PCA full dataset

full_pca <- make_pca(final_df)

full_pca$plot
ggsave(paste0(plots_dir, 'Met_Ac/PCAs/full_df_pca.pdf'), full_pca$plot)

full_pca$df %>%
  filter(PC2 < -10) %>%
  select(Gid) %>%
  print(n=200)

## PCA unique genes/states dataset

unique_pca <- make_pca(unique_df)
unique_pca$plot
ggsave(paste0(plots_dir, 'Met_Ac/PCAs/unique_df_pca.pdf'), full_pca$plot)

## PCA compact (5'/ORF/3') DFs
unique_noApi_pca <- unique_noApi %>%
  make_pca()

unique_noApi_pca$plot
ggsave(paste0(plots_dir, 'Met_Ac/PCAs/unique_noApi_df_pca.pdf'), full_pca$plot)
#+end_src
*** Scatterplots: 3'/ORF/5'
#+begin_src R
## Make Scatterplots

colnames(unique_df)

y_max <- unique_noApi %>%
  select(matches('Ac|Me')) %>%
  max(na.rm = T)

y_min <- unique_noApi %>%
  select(matches('Ac|Me')) %>%
  min(na.rm = T)


my_scatter <- function(df, ac_col, me_col, outname){
  dfname <- deparse(substitute(df))
  p <- ggplot(df, aes_string(x=ac_col, y=me_col, col = 'Label', alpha = 'Alpha'))
  p <- p + scale_color_manual(values=my_colors)
  #p <- p + theme_minimal() + guides(alpha='none')
  p <- p + theme_bw() + guides(alpha='none')
  p <- p + theme(
             #axis.title.x=element_blank(),
             #axis.text.x=element_blank(),
             #axis.ticks.x=element_blank(),
             panel.grid.major = element_blank(),
             panel.grid.minor = element_blank()
           )
  p <- p + geom_point()
  ## p <- p + ylim(y_min, y_max)
  ## p <- p + xlim(y_min, y_max)
  p <- p + coord_cartesian(ylim = c(y_min, y_max))
  ggsave(
    paste0(
      plots_dir,
      sprintf(
        'Met_Ac/Scatterplots/%s_%s_%s_scatter_new.pdf',
        dfname, ac_col, me_col
      )))
  return(p)
}

sc_5p <- my_scatter(unique_noApi, 'Ac_5p', 'Me_5p')
sc_orf <- my_scatter(unique_noApi, 'Ac_ORF', 'Me_ORF')
sc_3p <- my_scatter(unique_noApi, 'Ac_3p', 'Me_3p')
#my_scatter(unique_noApi, 'Ac_5p', 'Me_ORF')
sc_5p
ggarrange(sc_5p, sc_orf, sc_3p,
          labels = c("5p", "ORF", "3p"),
          common.legend = TRUE,
          ncol = 3, nrow = 1) %>%
  ggexport(filename = paste0(plots_dir, 'Met_Ac/Scatterplots/join_scatter_new.pdf'))
#+end_src
*** BoxPlots
#+begin_src R
## Plot boxplots for each interval

y_max <- unique_noApi %>%
  select(matches('Ac|Me')) %>%
  max(na.rm = T)

y_min <- unique_noApi %>%
  select(matches('Ac|Me')) %>%
  min(na.rm = T)

my_comparisons <- list(
  c("Active", "Inactive"),
  c("Active", "CVG_Active"),
  c("Active", "CVG_Silenced"),
  c("Inactive", "CVG_Active"),
  c("Inactive", "CVG_Silenced"),
  c("CVG_Active", "CVG_Silenced")
)

my_boxplot <- function(df, column, yaxis){
  dfname <- deparse(substitute(df))
  p <- ggplot(unique_noApi, aes_string(x='Label', y=column, fill='Label'))
  p <- p + geom_boxplot(aes(ymax = quantile(eval(parse(text = column)), 0.95, na.rm = T),
                            ymin = quantile(eval(parse(text = column)), 0.05, na.rm = T)),
                        ##outlier.shape = NA
                        )
  p <- p + coord_cartesian(ylim = yaxis)
  p <- p + scale_fill_manual(values=my_colors)
  p <- p + theme_bw() + guides(alpha='none')
  p <- p + theme(
             axis.title.x=element_blank(),
             axis.text.x=element_blank(),
             axis.ticks.x=element_blank(),
             panel.grid.major = element_blank(),
             panel.grid.minor = element_blank()
           )
  ## p <- p + stat_compare_means(
  ##            label = 'p.format',
  ##            method = 't.test',
  ##            comparisons = my_comparisons
  ##          )

  ggsave(
    paste0(
      plots_dir,
      sprintf('Met_Ac/Boxplots/%s_%s_boxplot.pdf', dfname, column))
    )
  return(p)
}

bx_ac_5p <- my_boxplot(unique_noApi, 'Ac_5p', c(-4, 4))
bx_ac_ORF <- my_boxplot(unique_noApi, 'Ac_ORF', c(-4, 4))
bx_ac_3p <- my_boxplot(unique_noApi, 'Ac_3p', c(-4, 4))

fm = aov(lm(unique_noApi$Ac_ORF ~ unique_noApi$Label))
summary(fm)
intervals = TukeyHSD(fm)
intervals
plot(intervals)

bx_me_5p <- my_boxplot(unique_noApi, 'Me_5p', c(-5,5))
bx_me_ORF <- my_boxplot(unique_noApi, 'Me_ORF', c(-5,5))
bx_me_3p <- my_boxplot(unique_noApi, 'Me_3p', c(-5,5))


ggarrange(bx_ac_5p, bx_ac_ORF, bx_ac_3p,
          bx_me_5p, bx_me_ORF, bx_me_3p,
          labels = c("Ac_5p", "Ac_ORF", "Ac_3p", "Me_5p", "Me_ORF", "Me_3p"),
          common.legend = TRUE,
          ncol = 3, nrow = 2) %>%
  ggexport(filename = paste0(plots_dir, 'Met_Ac/Boxplots/join_boxplot.pdf'))
#+end_src
*** Check genes with "weird values-labels"
#+begin_src R
df <- unique_df %>%
  left_join(info_df, by='Gene_id') %>%
  select(-contains('Difpeaks'))

df %>%
  select(Gene_id, Ac_ORF, Me_ORF, Variant, Annot) %>%
  filter(Me_ORF > 0) %>%
  filter(!Variant) %>%
  arrange(-Me_ORF) %>%
  print(n = 100)
#+end_src
** Telomeres analysis
#+begin_src R
#### Telomere Analysis ####
#+end_src
*** Coverage Analysis
#+begin_src R
## Coverage Analysis

read_telomeres <- function(strain){

  #strain <- '1.2B'
  suffix <- gsub('.', '', strain, fixed=T)
  suffix <- gsub('K9', '', suffix, fixed=T)

  df_ <- read_tsv(
    paste0(telomeres_dir, 'cov_telomeres_', strain, '.bed'),
    col_names = F
  ) %>%
    set_names(c('Chrom', 'Start', 'Stop', 'Cov'))

  tl_l <- df_ %>%
    filter(Start == 1) %>%
    select(Chrom, Cov) %>%
    rename(Cov_Left = Cov)

  tl_r <- df_ %>%
    filter(Start != 1) %>%
    select(Chrom, Cov) %>%
    rename(Cov_Right = Cov)

  tel_df <- tl_l %>%
    full_join(tl_r, by = 'Chrom') %>%
    set_names('Chrom', paste0('Cov_Left_', suffix), paste0('Cov_Right_', suffix))

  return(tel_df)
}

tel_heatmap <- function(df, side, meancenter, logit){

  #df <- tel_df

  tel_df <- df %>%
    select(Chrom, contains(side))

  ## Get row means and subtract from each val
  tel_df_meancentered <- tel_df %>%
    pivot_longer(cols=-Chrom) %>%
    group_by(Chrom)%>%
    mutate(MeanCov = mean(value)) %>%
    pivot_wider(names_from=name, values_from=value)  %>%
    ungroup %>%
    mutate(
      across(
        .cols = contains('Cov_'),
        .fns = function(x) x - MeanCov
      )
    ) %>%
    select(-MeanCov)


  ## Make Matrix for heatmap
  if (meancenter) {
    corr_mtx <- tel_df_meancentered %>%
      select(-Chrom) %>%
      as.matrix()
    rownames(corr_mtx) <- tel_df_meancentered$Chrom
  } else {
    corr_mtx <- tel_df %>%
      select(-Chrom) %>%
      as.matrix()
    rownames(corr_mtx) <- tel_df$Chrom
  }

  ## Log if necessary
  if (logit) {
    corr_mtx <- log2(corr_mtx)
  }

  ## Order Matrix (with clustering)
  ## set.seed(123)
  ## dmtx <- dist(t(corr_mtx), method = "euclidean")
  ## dendo <- hclust(dmtx)
  ## order <- hclust(dmtx)$order
  ## ordered_mtx <- corr_mtx[,order]
  ordered_mtx <- corr_mtx

  out_df <- as_tibble(ordered_mtx) %>%
    mutate(Chrom = rownames(ordered_mtx)) %>%
    select(Chrom, everything())

  ## Plot
  ordered_mtx_m <- melt(ordered_mtx)
  plt_df <- tibble(ordered_mtx_m) %>%
    mutate(Var1 = factor(Var1, levels = rev(tel_df$Chrom)))

  p <- ggplot(plt_df, aes(x=Var2, y=Var1, fill=value))
  p <- p + geom_tile()
  p <- p + theme(

             axis.title.x=element_blank(),
             axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
             axis.title.y=element_blank(),
             legend.position="top"
           )
  p <- p + scale_fill_gradient(
             low = "white",
             high = "orange",
             limits = c(min(corr_mtx), max(corr_mtx)),
             name = 'Coverage'
           )

  return(list(plot = p, df = out_df))
}

strains <- c('NF54', 'P63', '3D7imp', '1.2B', '10G', 'B11', 'A7K9', 'E5K9', 'E5HA')
tels <- lapply(strains, read_telomeres)

tel_df <- bind_cols(tels) %>%
  rename(Chrom = Chrom...1) %>%
  select(-contains('...')) %>%
  select(Chrom, contains('Left'), contains('Right'))

## Set deleted regions to NA ##
tel_df <- tel_df %>%
  mutate(Cov_Left_12B = case_when(
           Chrom == 'Pf3D7_02_v3' ~ NA_real_,
           Chrom == 'Pf3D7_03_v3' ~ NA_real_,
           Chrom == 'Pf3D7_08_v3' ~ NA_real_,
           TRUE ~ Cov_Left_12B
         )) %>%
  mutate(Cov_Left_10G = case_when(
           Chrom == 'Pf3D7_02_v3' ~ NA_real_,
           Chrom == 'Pf3D7_03_v3' ~ NA_real_,
           Chrom == 'Pf3D7_08_v3' ~ NA_real_,
           Chrom == 'Pf3D7_11_v3' ~ NA_real_,
           TRUE ~ Cov_Left_10G
         )) %>%
  mutate(Cov_Left_B11 = case_when(
           Chrom == 'Pf3D7_03_v3' ~ NA_real_,
           Chrom == 'Pf3D7_12_v3' ~ NA_real_,
           TRUE ~ Cov_Left_B11
         )) %>%
  mutate(Cov_Right_12B = case_when(
           Chrom == 'Pf3D7_04_v3' ~ NA_real_,
           TRUE ~ Cov_Right_12B
         )) %>%
  mutate(Cov_Right_10G = case_when(
           Chrom == 'Pf3D7_04_v3' ~ NA_real_,
           TRUE ~ Cov_Right_10G
         )) %>%
  mutate(Cov_Right_B11 = case_when(
           Chrom == 'Pf3D7_08_v3' ~ NA_real_,
           Chrom == 'Pf3D7_12_v3' ~ NA_real_,
           TRUE ~ Cov_Right_B11
         ))

tel_df[tel_df$Chrom == 'Pf3D7_05_v3', grepl('Left', colnames(tel_df))] <- NA_real_
tel_df[tel_df$Chrom == 'Pf3D7_13_v3', grepl('Left', colnames(tel_df))] <- NA_real_

tel_l <- tel_heatmap(
  df <- tel_df,
  side <- 'Left',
  meancentered <- F,
  logit <- F
)

tel_l$plot

tel_r <- tel_heatmap(
  df <- tel_df,
  side <- 'Right',
  meancentered <- F,
  logit <- F
)

tel_l$plot
plot(tel_l$dendo)
tel_l$df

tel_r_plot <- tel_r$plot +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )

whole_p <- ggarrange(tel_l$plot, tel_r_plot, nrow = 1, ncol = 2)
ggsave(paste0(plots_dir, 'telomeres_heatmap_new.pdf'), whole_p, device = 'pdf')

#+end_src
*** Deletions/Duplications Analysis
#+begin_src R
## Deletions/Duplications Analysis

tel_dels <- read_csv(paste0(telomeres_dir, '../manual_deletions_table.csv'))

df <- tel_dels %>%
  select(Chrom, contains('left'))

tel_dupl_del_heatmap <- function(side){

  df <- tel_dels %>%
    select(Chrom, contains(side))

  ## Make Matrix for heatmap
  mtx_ <- df %>%
    select(-Chrom) %>%
    as.matrix()

  rownames(mtx_) <- df$Chrom

  ## Order Matrix (by clustering)
  ## set.seed(123)
  ## dmtx <- dist(t(mtx_), method = "euclidean")
  ## dendo <- hclust(dmtx)
  ##plot(dendo)
  ##order <- hclust(dmtx)$order
  ##ordered_mtx <- mtx_[,order]
  ordered_mtx <- mtx_


  ## Plot
  ordered_mtx_m <- melt(ordered_mtx)
  plt_df <- tibble(ordered_mtx_m) %>%
    mutate(Var1 = factor(Var1, levels = rev(df$Chrom)))

  p <- ggplot(plt_df, aes(x=Var2, y=Var1, fill=value))
  p <- p + geom_tile(colour="snow3", size=0.25)
  p <- p + theme(
             panel.background=element_blank(),
             ##panel.grid.minor=element_blank(),
             plot.background=element_blank(),
             axis.title.x=element_blank(),
             axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),
             axis.title.y=element_blank(),
             legend.position="top"
           )
  p <- p + scale_fill_gradient2(
             mid = 0,
             name = 'Coverage'
           )
  return(p)
}


pl_l <- tel_dupl_del_heatmap('left')
pl_r <- tel_dupl_del_heatmap('right') +
  theme(
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank()
  )

whole_p <- ggarrange(pl_l, pl_r, nrow = 1, ncol = 2)
whole_p
ggsave(paste0(plots_dir, 'telomeres_dupl_del_heatmap_new.pdf'), whole_p, device = 'pdf')


#+end_src
** Save/load environtment
#+begin_src R
#### Save/load environtment ####
##save.image('paper_analysis_070722.RData')
##setwd('/mnt/Disc4T/Projects/PhD_Project/Paper/Paper_Analysis/')
##load('paper_analysis_070722.RData')
#+end_src
